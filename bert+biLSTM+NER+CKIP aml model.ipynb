{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://cloud.tencent.com/developer/article/1454904\n",
    "#https://zhuanlan.zhihu.com/p/82850698\n",
    "#https://blog.csdn.net/weixin_42598761/article/details/104592171"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Lambda, Bidirectional, LSTM, Dense\n",
    "from keras_bert import load_trained_model_from_checkpoint\n",
    "from keras_contrib.layers import CRF\n",
    "from keras_contrib.losses import crf_loss\n",
    "from keras_contrib.metrics import crf_accuracy\n",
    "from keras_bert import Tokenizer\n",
    "from keras_bert import AdamWarmup, calc_train_steps\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "import keras.callbacks\n",
    "import re\n",
    "import codecs\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ckiptagger import WS, POS, NER\n",
    "ckip_path = r'C:\\Users\\Jasonhsu\\Desktop\\esun\\data'\n",
    "ws = WS(ckip_path, disable_cuda=False) #斷詞\n",
    "pos = POS(ckip_path, disable_cuda=False) #詞性標注\n",
    "ner = NER(ckip_path, disable_cuda=False) #實體辨識"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import codecs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "bert_dir = r'C:\\Users\\Jasonhsu\\Desktop\\esun\\chinese_L-12_H-768_A-12'\n",
    "config_path = os.path.join(bert_dir, 'bert_config.json')\n",
    "checkpoint_path = os.path.join(bert_dir, 'bert_model.ckpt')\n",
    "dict_path = os.path.join(bert_dir, 'vocab.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 載入資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\Jasonhsu\\Desktop\\esun\\0620\\content_df_0620.csv')\n",
    "data = data[data[\"status\"]==\"ok\"].drop([\"url\",\"context\",\"raw_content\",\"status\", \"content_status\"],axis = 1)\n",
    "data['aml_label'] = data['name'].apply(lambda x: 0 if x == '[]' else 1)\n",
    "data['name'] = data['name'].apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content'] = data['content'].apply(lambda x: re.sub('<[^>]*>|【[^】]*】|（[^）]*）|〔[^〕]*〕', '', x))\n",
    "data['content'] = data['content'].apply(lambda x: x.replace('記者', '＜')\n",
    "                                                   .replace('報導', '＞')\n",
    "                                                   .replace('▲', '')\\\n",
    "                                                   .replace('。　', '。')\\\n",
    "                                                   .replace('\b', '')\\\n",
    "                                                   .replace('.', '')\\\n",
    "                                                   .replace(' ', '')\\\n",
    "                                                   .replace('“', '「')\\\n",
    "                                                   .replace('”', '」'))\n",
    "data['content'] = data['content'].apply(lambda x: re.sub('＜[^＞]*＞', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test =  train_test_split(data, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 建立 aml 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_tokenizer(dict_path):\n",
    "    \n",
    "    token_dict = {}\n",
    "    with codecs.open(dict_path, 'r', 'utf8') as reader:\n",
    "        for line in reader:\n",
    "            token = line.strip()\n",
    "            token_dict[token] = len(token_dict)\n",
    "            \n",
    "    return token_dict\n",
    "\n",
    "def transfer(i):\n",
    "    \n",
    "    if i != 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def encoded(tokenizer, data, maxlen):\n",
    "    \n",
    "    x, y, z = [], [], []\n",
    "    if 'content' in data.columns:\n",
    "        for content in data['content']:\n",
    "            x1, x2 = tokenizer.encode(content, max_len=maxlen)\n",
    "            x3 = [transfer(i) for i in x1]\n",
    "            x.append(x1)\n",
    "            y.append(x2)\n",
    "            z.append(x3)\n",
    "    elif 'Sentence' in data.columns:\n",
    "        for content in data['Sentence']:\n",
    "            x1, x2 = tokenizer.encode(content, max_len=maxlen)\n",
    "            x3 = [transfer(i) for i in x1]\n",
    "            x.append(x1)\n",
    "            y.append(x2)\n",
    "            z.append(x3)\n",
    "            \n",
    "    return x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_dict = create_tokenizer(dict_path)\n",
    "tokenizer = Tokenizer(token_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 256\n",
    "batch_size = 8\n",
    "epochs = 3\n",
    "input_shape = (maxlen, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.asarray(train['aml_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_id, segment_id, mask_input = encoded(tokenizer, train, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_LSTM_model():\n",
    "    \n",
    "    model = load_trained_model_from_checkpoint(config_path, checkpoint_path, training=True, seq_len=maxlen)\n",
    "    sequence_output = model.layers[-9].output\n",
    "    #sequence_output = Lambda(lambda x: x[:, 0])(sequence_output)\n",
    "    sequence_output = Bidirectional(LSTM(128, return_sequences=False))(sequence_output)\n",
    "    output = Dense(1, activation='sigmoid')(sequence_output)\n",
    "    model = Model(model.input, output)\n",
    "    \n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    model.layers[-1].trainable = True\n",
    "    model.layers[-2].trainable = True\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = bert_LSTM_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入模型\n",
    "#model.load_weights('aml_model_weight.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_steps, warmup_steps = calc_train_steps(\n",
    "    num_example=train.shape[0],\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    warmup_proportion=0.1,\n",
    ")\n",
    "\n",
    "optimizer = AdamWarmup(total_steps, warmup_steps, lr=1e-3, min_lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_list = [\n",
    "                 keras.callbacks.EarlyStopping(monitor='val_acc', patience=1)\n",
    "                 #,ModelCheckpoint(filepath='AML_bert.h5', monitor='val_loss', save_best_only=True)\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3495 samples, validate on 389 samples\n",
      "Epoch 1/3\n",
      "3495/3495 [==============================] - 165s 47ms/step - loss: 0.1026 - acc: 0.9588 - val_loss: 0.0254 - val_acc: 0.9871\n",
      "Epoch 2/3\n",
      "3495/3495 [==============================] - 159s 46ms/step - loss: 0.0231 - acc: 0.9914 - val_loss: 0.0272 - val_acc: 0.9846\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x18b740e1f88>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.fit([input_id, segment_id, mask_input],\n",
    "          label,\n",
    "          epochs=epochs,\n",
    "          batch_size=batch_size,\n",
    "          validation_split=0.1,\n",
    "          callbacks=callback_list\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 建立 NER 模型\n",
    "### transfer_NER 要跑 1.5 小時，訓練模型要跑 17mins/epoch，所以load weight就好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把大於512的新聞以句點分段 (bert最多只能吃512)\n",
    "def split_content(data):\n",
    "    data_more_split = pd.DataFrame()\n",
    "    for i, row in data.iterrows():\n",
    "        if (len(row['content']) > 512) & (len(row['content']) <= 1024):\n",
    "\n",
    "            s = row['content']\n",
    "            s_split = [(i, abs(len(s)//2 - s.find(x)), x) for i, x in enumerate(s.split('。'))]\n",
    "            idx_left = min(s_split, key=lambda x: x[1])[0]\n",
    "            first = \"。\".join([s_split[i][2] for i in range(idx_left)])\n",
    "            second = \"。\".join([s_split[i][2] for i in range(idx_left, len(s_split))])    \n",
    "            contents = [first, second]\n",
    "\n",
    "            for content in contents:\n",
    "                data_more_split = data_more_split.append(pd.DataFrame({'news_id':row['news_id'], 'content':content}, index=[66]), ignore_index=True)\n",
    "\n",
    "        elif len(row['content']) > 1024:\n",
    "\n",
    "            s = row['content']\n",
    "            s_split1 = [(i, abs(len(s)//3 - s.find(x)), x) for i, x in enumerate(s.split('。'))]\n",
    "            s_split2 = [(i, abs(len(s)*2//3 - s.find(x)), x) for i, x in enumerate(s.split('。'))]\n",
    "            idx_left1 = min(s_split1, key=lambda x: x[1])[0]\n",
    "            idx_left2 = min(s_split2, key=lambda x: x[1])[0]\n",
    "            first = \"。\".join([s_split1[i][2] for i in range(idx_left1)])\n",
    "            second = \"。\".join([s_split1[i][2] for i in range(idx_left1, idx_left2)])\n",
    "            third = \"。\".join([s_split1[i][2] for i in range(idx_left2, len(s_split1))])\n",
    "            contents = [first, second, third]\n",
    "\n",
    "            for content in contents:\n",
    "                data_more_split = data_more_split.append(pd.DataFrame({'news_id':row['news_id'], 'content':content}, index=[66]), ignore_index=True)\n",
    "    \n",
    "    return data_more_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen_ner = 512\n",
    "batch_size = 8\n",
    "epochs = 3\n",
    "input_shape = (maxlen_ner, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取得 NER input array (陳水扁貪汙 -> CKIP(陳水扁) -> 1 2 2 0 0)\n",
    "def transfer_NER(data, tokenizer, maxlen):\n",
    "    people_list = []\n",
    "    first_name = ['申', '龔', '馮', '昌', '劉', '習', '陽', '顧', '鍾', '胡', '許', '魏',    '傅', '季', '扶', '柳', '狄', '焦', '封', '李', '羿', '刁', '和', '邴',    '陸', '王', '杜', '能', '侯', '伍', '平', '竺', '樂', '繆', '欒', '湛',    '道', '花', '賴', '浦', '萬', '章', '宮', '勾', '邵', '印', '夏', '杭',    '溥', '左', '池', '公', '閻', '符', '奚', '臧', '羅', '空', '璩', '巴',    '酈', '范', '談', '金', '顏', '慎', '郭', '僪', '聞', '車', '闞', '相',    '童', '雙', '方', '莊', '容', '姚', '田', '薛', '閔', '翟', '簡',    '蔚', '茹', '淩', '戴', '余', '鞏', '房', '富', '牛', '饒', '計', '居',    '後', '舒', '席', '翁', '祝', '鬱', '訾', '隆', '匡', '弘', '曆', '範',    '越', '趙', '卻', '岑', '隗', '冷', '張', '山', '松', '柯', '嵇', '韓',    '蕭', '褚', '殳', '滕', '滿', '洪', '荀', '庾', '廖', '盧', '危', '竇',    '曾', '郎', '遊', '穀', '慕', '禹', '凌', '廉', '邢', '梁', '葉',    '郝', '終', '齊', '藺', '曹', '全', '高', '樊', '史', '桂', '廣', '段',    '江', '餘', '袁', '弓', '牧', '魚', '儲', '尚', '逄', '尹', '通', '懷',    '皮', '何', '倪', '包', '晁', '涂', '蓬', '屠', '巫', '須', '巢', '卞',    '楊', '成', '孟', '楚', '呂', '古', '毋', '伊', '賁', '喻', '糜',    '蔔', '艾', '藍', '龐', '諸', '別', '任', '管', '冀', '壽', '惠', '梅',    '孫', '從', '康', '常', '駱', '鞠', '沈', '黨', '沙', '鳳', '郁', '邊',    '仰', '溫', '路', '逮', '賀', '雷', '鈄', '明', '裴', '滑', '毛', '費',    '關', '時', '步', '麴', '裘', '蒲', '司', '查', '錢', '盛', '霍', '鮑',    '彭', '龍', '沃', '單', '勞', '秋', '祖', '殷', '茅', '敖', '郗', '石',    '鐘', '嚴', '畢', '燕', '姜', '經', '程', '厙', '柏', '汪', '婁', '胥',    '聶', '邰', '桑', '辛', '扈', '穆', '仲', '紅', '項', '師', '桓', '黃',    '堵', '貢', '詹', '朱', '蔡', '戈', '于', '甄', '束', '屈', '索', '晏',    '阮', '魯', '虞', '歐', '濮', '俞', '黎', '文', '應', '姬', '貝', '籍',    '莘', '戚', '鄭', '郜', '景', '宋', '宗', '昝', '卓', '蒯', '馬', '顔',    '蘇', '衛', '東', '瞿', '蒼', '莫', '邱', '潘', '家', '林', '芮', '麻',    '元', '武', '強', '鈕', '陳', '井', '於', '游', '耿', '柴', '荊', '韶',    '易', '宿', '施', '鹹', '秦', '班', '甯', '汲', '酆', '暴', '尤',    '祿', '苗', '權', '仇', '都', '羊', '榮', '陶', '支', '賈', '白', '葛',    '暨', '解', '靳', '伏', '唐', '華', '吉', '融', '豐', '安', '衡', '那',    '闕', '俄', '盍', '鄔', '蒙', '利', '鄂', '謝', '宓', '湯', '喬', '孔',    '養', '紀', '幹', '牟', '連', '宰', '蔣', '雍', '益', '寇', '祁', '熊',    '崔', '丁', '薊', '譚', '吳', '烏', '周', '農', '徐', '充', '向', '宦',    '董', '甘', '冉', '韋', '米', '鄒', '鄧', '戎', '水']\n",
    "    label = np.zeros([len(data), maxlen])\n",
    "    \n",
    "    # 用CKIP抓出每個新聞的名字\n",
    "    for index, (_, row) in enumerate(data.iterrows()):\n",
    "        \n",
    "        if index % 100 == 0:\n",
    "            print(index)\n",
    "        \n",
    "        token = tokenizer.tokenize(row['content'][0:maxlen])\n",
    "\n",
    "        if len(token) > maxlen:\n",
    "            token = token[0:maxlen-1]\n",
    "            token.append('[SEP]')\n",
    "\n",
    "        y = np.zeros([maxlen])\n",
    "        content = ''.join(token)\n",
    "        \n",
    "        #CKIP\n",
    "        word_sentence_list = ws([content],\n",
    "                    sentence_segmentation=True,\n",
    "                    segment_delimiter_set={'?', '？', '!', '！', '。', ',', '，', ';', ':', '、'})\n",
    "        pos_sentence_list = pos(word_sentence_list)\n",
    "        entity_sentence_list = ner(word_sentence_list, pos_sentence_list)\n",
    "        \n",
    "        people = [people for people in list(entity_sentence_list[0]) if (people[2] == 'PERSON') & (people[1] < maxlen)]\n",
    "        people = [people for people in people if ((len(people[3]) < 5) & (people[3][0] in first_name)) | ((len(people[3]) >= 5) & ('#' not in people[3]))]\n",
    "        people.sort()\n",
    "        people_list.append(people)\n",
    "        \n",
    "        #轉換成input array\n",
    "        j = 0\n",
    "        for person in people: \n",
    "            for i, _ in enumerate(token):        \n",
    "                if token[i:i+len(person[3])] == list(person[3]):\n",
    "                    if len(person) == 1:\n",
    "                        y[i+j] = 1\n",
    "                        token = token[i+1:]\n",
    "                        j = i+j+1\n",
    "                        break\n",
    "\n",
    "                    y[i+j] = 1\n",
    "                    y[i+j+1:i+j+len(person[3])] = 2\n",
    "                    token = token[i+len(person[3]):]\n",
    "                    j = i+j+len(person[3])\n",
    "                    break\n",
    "        label[index, :] = y\n",
    "    \n",
    "    #用不到 people_list，只是檢查用\n",
    "    return people_list, label.reshape([label.shape[0], label.shape[1], 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分句\n",
    "train_ner = train.drop(['name', 'aml_label'], axis=1)\n",
    "data_less = train_ner[train_ner['content'].str.len() <= 512]\n",
    "data_more = train_ner[train_ner['content'].str.len() > 512]\n",
    "data_more_split = split_content(data_more)\n",
    "train_ner = train_ner.append(data_more_split)\n",
    "train_ner = train_ner.reset_index().drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "people_list, label = transfer_NER(train_ner, tokenizer, maxlen=maxlen_ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_id, segment_id, mask_input = encoded(tokenizer, train_ner, maxlen=maxlen_ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_BiLSTM_CRF_model():\n",
    "    \n",
    "    ner_model = load_trained_model_from_checkpoint(config_path, checkpoint_path, training=True, seq_len=maxlen_ner)\n",
    "    bert_output = ner_model.layers[-9].output\n",
    "    X = Lambda(lambda x: x[:, 0: input_shape[0]])(bert_output)\n",
    "    X = Bidirectional(LSTM(128, return_sequences=True))(X)\n",
    "    #X = TimeDistributed(Dense(len(y_token_dict), activation='relu'))(X)\n",
    "    output = CRF(3, sparse_target = True)(X)    \n",
    "    ner_model = Model(ner_model.input, output)\n",
    "    \n",
    "    for layer in ner_model.layers:\n",
    "        layer.trainable = False\n",
    "    ner_model.layers[-1].trainable = True\n",
    "    ner_model.layers[-2].trainable = True\n",
    "    \n",
    "    return ner_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ner_model = bert_BiLSTM_CRF_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer_NER 要跑 1.5 小時，訓練模型要跑 17mins/epoch，所以load weight就好\n",
    "ner_model.load_weights('ner_model_weight.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_steps, warmup_steps = calc_train_steps(\n",
    "    num_example=data.shape[0],\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    warmup_proportion=0.1,\n",
    ")\n",
    "\n",
    "optimizer = AdamWarmup(total_steps, warmup_steps, lr=1e-3, min_lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_list = [\n",
    "                 keras.callbacks.EarlyStopping(monitor='val_crf_accuracy', patience=1)\n",
    "                 #,ModelCheckpoint(filepath='AML_bert.h5', monitor='val_loss', save_best_only=True)\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9064 samples, validate on 1008 samples\n",
      "Epoch 1/3\n",
      "9064/9064 [==============================] - 1081s 119ms/step - loss: 0.0065 - crf_accuracy: 0.9975 - val_loss: 0.0045 - val_crf_accuracy: 0.9980\n",
      "Epoch 2/3\n",
      "9064/9064 [==============================] - 1077s 119ms/step - loss: 0.0040 - crf_accuracy: 0.9982 - val_loss: 0.0041 - val_crf_accuracy: 0.9982\n",
      "Epoch 3/3\n",
      "9064/9064 [==============================] - 1078s 119ms/step - loss: 0.0035 - crf_accuracy: 0.9984 - val_loss: 0.0040 - val_crf_accuracy: 0.9983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x18bfefb8748>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_model.compile(optimizer=optimizer,\n",
    "                  loss=crf_loss,\n",
    "                  metrics=[crf_accuracy])\n",
    "\n",
    "ner_model.fit([input_id, segment_id, mask_input],\n",
    "          label,\n",
    "          epochs=epochs,\n",
    "          batch_size=batch_size,\n",
    "          validation_split=0.1,\n",
    "          callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取得名字 (預測結果為onehot的狀態)\n",
    "def get_name(input_id, y_pred):\n",
    "    \n",
    "    label_list = []\n",
    "    word_dict = {v: k for k, v in token_dict.items()}\n",
    "    \n",
    "    for input_data, y in zip(input_id, y_pred):\n",
    "        people_index = ''.join([str(a) for a in list(y)])\n",
    "        j = 0\n",
    "        name_list = []\n",
    "        split_index = re.findall('[12]2*', people_index)\n",
    "        name = ''.join([word_dict.get(input_data[index]) for index, value in enumerate(y) if value != 0])\n",
    "        \n",
    "        # [UNK], [PAD]會被算成 5 個字元，避免轉換成文字的index因長度不同對不上，故用 1 個字元的其他符號替代\n",
    "        # 王春甡 -> 王春[UNK] -> 王春?\n",
    "        name = name.replace('[UNK]','?')\n",
    "        name = name.replace('[PAD]','!')\n",
    "        \n",
    "        for i in split_index:\n",
    "            name_list.append(name[0+j:len(i)+j])\n",
    "            j = len(i) + j\n",
    "            \n",
    "        name_list = [name for name in name_list]\n",
    "        label_list.append(list(set(name_list)))\n",
    "    \n",
    "    return label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_aml(model, test, aml_threshold):\n",
    "    \n",
    "    #第一階段預測，大於aml_threshold者為疑似aml文章\n",
    "    input_id, segment_id, mask_input = encoded(tokenizer, test, maxlen=maxlen)\n",
    "    prediction = model.predict([input_id, segment_id, mask_input])\n",
    "    prediction[prediction >= aml_threshold] = 1\n",
    "    prediction[prediction < aml_threshold] = 0\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentences(test, people_list, stick, threshold, tokenizer=tokenizer, maxlen=maxlen):\n",
    "    \n",
    "    time = datetime.now()\n",
    "    \n",
    "    AML = pd.DataFrame(columns=['news_id', 'Name', 'Sentence'])\n",
    "    aml_highrisk = np.asarray(test['content'][test['prediction'] == 1])\n",
    "    news_ids = np.asarray(test['news_id'][test['prediction'] == 1])\n",
    "    \n",
    "    for k, (news_id, y_news) in enumerate(zip(news_ids ,aml_highrisk)): \n",
    "        # 用，。？！切分句子\n",
    "        news = re.split('，|。|？|！', y_news)\n",
    "\n",
    "        for i in range(len(people_list[k])):\n",
    "            # 找出人名存在的 news index\n",
    "            index = [index for index, _ in enumerate(news) if people_list[k][i] in _]                           \n",
    "            \n",
    "            # 刪除前後句中有出現其他姓名的句子 (XX，陳水扁貪汙，吳淑珍也是 -> XX，陳水扁貪汙，也是)\n",
    "            # 刪除同一句中有出現其他姓名的字 (XX，陳致中是陳水扁的兒子，XX -> XX，是陳水扁的兒子，XX)\n",
    "            for j in index:\n",
    "                \n",
    "                name = [name for name in people_list[k] if name != people_list[k][i]]\n",
    "                new_news = re.sub('|'.join(name), '', news[j])\n",
    "                \n",
    "                if j == 0:\n",
    "                    new_news2 = re.sub('|'.join(name), '', news[j+1])    \n",
    "                    sentences = new_news + '，' + new_news2\n",
    "            \n",
    "                elif j+1 == len(news):\n",
    "                    new_news3 = re.sub('|'.join(name), '', news[j-1]) \n",
    "                    sentences = new_news3 + '，' + new_news\n",
    "            \n",
    "                else:\n",
    "                    new_news2 = re.sub('|'.join(name), '', news[j+1]) \n",
    "                    new_news3 = re.sub('|'.join(name), '', news[j-1]) \n",
    "                    sentences = new_news3 + '，' + new_news + '，' + new_news2\n",
    "\n",
    "            \n",
    "                    \n",
    "                AML = AML.append(pd.DataFrame([[news_ids[k] ,people_list[k][i], sentences]], columns=AML.columns))\n",
    "                \n",
    "    print('1.提取句子', datetime.now() - time)\n",
    "    time = datetime.now()\n",
    "    \n",
    "    #若 stick==True 則把多筆同姓名句子以逗點合併 (效果不好)\n",
    "    if stick:\n",
    "        AML = AML.groupby(['news_id', 'Name'])['Sentence'].apply('，'.join).reset_index()\n",
    "    \n",
    "    #姓氏表\n",
    "    first_name = [\n",
    "        '申', '龔', '馮', '昌', '劉', '習', '陽', '顧', '鍾', '胡', '許', '魏',\n",
    "        '傅', '季', '扶', '柳', '狄', '焦', '封', '李', '羿', '刁', '和', '邴',\n",
    "        '陸', '王', '杜', '能', '侯', '伍', '平', '竺', '樂', '繆', '欒', '湛',\n",
    "        '道', '花', '賴', '浦', '萬', '章', '宮', '勾', '邵', '印', '夏', '杭',\n",
    "        '溥', '左', '池', '公', '閻', '符', '奚', '臧', '羅', '空', '璩', '巴',\n",
    "        '酈', '范', '談', '金', '顏', '慎', '郭', '僪', '聞', '車', '闞', '相',\n",
    "        '童', '雙', '方', '莊', '容', '姚', '田', '薛', '閔', '翟', '簡',\n",
    "        '蔚', '茹', '淩', '戴', '余', '鞏', '房', '富', '牛', '饒', '計', '居',\n",
    "        '後', '舒', '席', '翁', '祝', '鬱', '訾', '隆', '匡', '弘', '曆', '範',\n",
    "        '越', '趙', '卻', '岑', '隗', '冷', '張', '山', '松', '柯', '嵇', '韓',\n",
    "        '蕭', '褚', '殳', '滕', '滿', '洪', '荀', '庾', '廖', '盧', '危', '竇',\n",
    "        '曾', '郎', '遊', '穀', '慕', '禹', '凌', '廉', '邢', '梁', '葉',\n",
    "        '郝', '終', '齊', '藺', '曹', '全', '高', '樊', '史', '桂', '廣', '段',\n",
    "        '江', '餘', '袁', '弓', '牧', '魚', '儲', '尚', '逄', '尹', '通', '懷',\n",
    "        '皮', '何', '倪', '包', '晁', '涂', '蓬', '屠', '巫', '須', '巢', '卞',\n",
    "        '楊', '成', '孟', '楚', '呂', '古', '毋', '伊', '賁', '喻', '糜',\n",
    "        '蔔', '艾', '藍', '龐', '諸', '別', '任', '管', '冀', '壽', '惠', '梅',\n",
    "        '孫', '從', '康', '常', '駱', '鞠', '沈', '黨', '沙', '鳳', '郁', '邊',\n",
    "        '仰', '溫', '路', '逮', '賀', '雷', '鈄', '明', '裴', '滑', '毛', '費',\n",
    "        '關', '時', '步', '麴', '裘', '蒲', '司', '查', '錢', '盛', '霍', '鮑',\n",
    "        '彭', '龍', '沃', '單', '勞', '秋', '祖', '殷', '茅', '敖', '郗', '石',\n",
    "        '鐘', '嚴', '畢', '燕', '姜', '經', '程', '厙', '柏', '汪', '婁', '胥',\n",
    "        '聶', '邰', '桑', '辛', '扈', '穆', '仲', '紅', '項', '師', '桓', '黃',\n",
    "        '堵', '貢', '詹', '朱', '蔡', '戈', '于', '甄', '束', '屈', '索', '晏',\n",
    "        '阮', '魯', '虞', '歐', '濮', '俞', '黎', '文', '應', '姬', '貝', '籍',\n",
    "        '莘', '戚', '鄭', '郜', '景', '宋', '宗', '昝', '卓', '蒯', '馬', '顔',\n",
    "        '蘇', '衛', '東', '瞿', '蒼', '莫', '邱', '潘', '家', '林', '芮', '麻',\n",
    "        '元', '武', '強', '鈕', '陳', '井', '於', '游', '耿', '柴', '荊', '韶',\n",
    "        '易', '宿', '施', '鹹', '秦', '班', '甯', '汲', '酆', '暴', '尤',\n",
    "        '祿', '苗', '權', '仇', '都', '羊', '榮', '陶', '支', '賈', '白', '葛',\n",
    "        '暨', '解', '靳', '伏', '唐', '華', '吉', '融', '豐', '安', '衡', '那',\n",
    "        '闕', '俄', '盍', '鄔', '蒙', '利', '鄂', '謝', '宓', '湯', '喬', '孔',\n",
    "        '養', '紀', '幹', '牟', '連', '宰', '蔣', '雍', '益', '寇', '祁', '熊',\n",
    "        '崔', '丁', '薊', '譚', '吳', '烏', '周', '農', '徐', '充', '向', '宦',\n",
    "        '董', '甘', '冉', '韋', '米', '鄒', '鄧', '戎', '水'\n",
    "    ]\n",
    "    \n",
    "    # 把指向同一人的姓名改成一樣（陳男 -> 陳水扁），若指向多人則不改（陳男 -> 陳致中、陳水扁）\n",
    "    # 將預測不完整的名字回填（王音 -> 王音之）\n",
    "    name_list = []\n",
    "    for ids in AML['news_id'].unique():\n",
    "        full_name = [name for name in AML[(AML['news_id'] == ids)]['Name']]\n",
    "        full_3name = [name for name in AML[(AML['news_id'] == ids)]['Name'] if len(name) == 3]\n",
    "        \n",
    "        a = Counter([name[0] for name in full_3name])\n",
    "        keep = [k for k,v in a.items() if v == 1]\n",
    "        full_3name_filter = [name for name in full_3name if name[0] in keep]\n",
    "        name_dict = dict((name[0], name) for name in full_3name_filter)   # ex: {'陳' : '陳水扁'}\n",
    "\n",
    "        name_dict_2 = dict(zip([name[0:2] for name in full_3name], full_3name))  # ex: {'王音': '王音之'}\n",
    "        \n",
    "        for name in full_name:\n",
    "            if (name[0] in name_dict.keys()) & (len(name) == 1):\n",
    "                name_list.append(name_dict.get(name[0]))\n",
    "            elif (name[0] in name_dict.keys()) & (len(name) == 2) & (name[-1] in ['男', '嫌', '婦', '夫', '某', '女', '妻',\\\n",
    "                                                                                  '員', '稱', '家', '哥', '媽', '生', '處',\\\n",
    "                                                                                  '和', '揆', '要', '再', '董', '涉', '母',\\\n",
    "                                                                                  '辱', '公', '少', '為', '指', '翁', '粉',\\\n",
    "                                                                                  '趁', '仔', '依', '氏', '父']):\n",
    "                name_list.append(name_dict.get(name[0]))\n",
    "            elif (name in name_dict_2.keys()) & (len(name) == 2):\n",
    "                name_list.append(name_dict_2.get(name))\n",
    "            else:\n",
    "                name_list.append(name)\n",
    "                \n",
    "    print('2.整理名字', datetime.now() - time)\n",
    "    time = datetime.now()\n",
    "    \n",
    "    # 排除重複資料、排除一字、兩字簡稱、兩字三字四字姓不在姓氏表中的人\n",
    "    AML['Name'] = name_list\n",
    "    AML = AML.drop_duplicates()\n",
    "    AML = AML[AML['Name'].apply(lambda x: (len(x) > 1) )]\n",
    "    AML = AML[~AML['Name'].apply(lambda x: (len(x) == 2) & (x[1] in ['男', '嫌', '婦', '夫', '某', '女', '妻',\\\n",
    "                                                                     '員', '稱', '家', '哥', '媽', '生', '處',\\\n",
    "                                                                     '和', '揆', '要', '再', '董', '涉', '母',\\\n",
    "                                                                     '辱', '公', '少', '為', '指', '翁', '粉',\\\n",
    "                                                                     '趁', '仔', '依', '氏', '父']))]\n",
    "    AML = AML[AML['Name'].apply(lambda x: (len(x) > 2) | ((len(x) < 3) & (x[0] in first_name)))]\n",
    "    AML = AML[~AML['Name'].apply(lambda x: (x[0] not in first_name) & (len(x) in (4,3,2)) )]\n",
    "\n",
    "    print('3.刪除名字', datetime.now() - time)\n",
    "    time = datetime.now()\n",
    "    \n",
    "    # 第二階段 預測句子\n",
    "    input_id, segment_id, mask_input = encoded(tokenizer, AML, maxlen=256)\n",
    "    prediction = model.predict([input_id, segment_id, mask_input])\n",
    "    AML['prediction'] = np.round(prediction, 3) \n",
    "    \n",
    "    # 同一人只要有一筆資料大於閥值（max），則預測為 aml 人物；若新聞中無人大於閥值，則為非 aml 新聞\n",
    "    AML['prediction'] = AML['prediction'].apply(lambda x: 0 if x < threshold else 1)\n",
    "    AML = AML.groupby(['news_id', 'Name'])['prediction'].max().reset_index()\n",
    "    AML = AML[AML['prediction'] == 1]\n",
    "    AML = AML.groupby(['news_id','prediction'])['Name'].apply(list).reset_index()\n",
    "    \n",
    "    print('4.預測名字', datetime.now() - time)\n",
    "    \n",
    "    return AML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(a, b):\n",
    "    \n",
    "    if (len(a) != 0) & (len(b) != 0):\n",
    "        recall = float(len(set(a) & set(b)) / len(a))\n",
    "        pecision = float(len(set(a) & set(b)) / len(b))\n",
    "        score = 2 / (np.reciprocal(recall) + np.reciprocal(pecision))\n",
    "        return score\n",
    "    elif (len(a) == 0) & (len(b) == 0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 網格搜索"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1 [NER法]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GridSearch_ner(df, model, test, aml_threshold, stick, threshold):\n",
    "    \n",
    "    time = datetime.now()\n",
    "    \n",
    "    # 1. 預測是否疑似 aml\n",
    "    prediction = predict_aml(model, test=test, aml_threshold=aml_threshold)\n",
    "    test['prediction'] = prediction\n",
    "    aml_highrisk = test[test['prediction'] == 1]\n",
    "    \n",
    "    # 2. 將超過 512 的句子以句點拆成多句分段預測\n",
    "    test_ner = aml_highrisk.drop(['name'], axis=1)\n",
    "    data_less = test_ner[test_ner['content'].str.len() <= 512]\n",
    "    data_more = test_ner[test_ner['content'].str.len() > 512]\n",
    "    data_more_split = split_content(data_more)\n",
    "    test_ner = test_ner.append(data_more_split)\n",
    "    test_ner = test_ner.reset_index().drop(['index'], axis=1)\n",
    "    \n",
    "    # 3. NER 預測人名\n",
    "    input_id, segment_id, mask_input = encoded(tokenizer, test_ner, maxlen=maxlen_ner)\n",
    "    prediction = ner_model.predict([input_id, segment_id, mask_input])\n",
    "    y_pred = np.argmax(prediction, axis=-1)\n",
    "    people_list = get_name(input_id, y_pred)\n",
    "    \n",
    "    \n",
    "    # 4. 將拆開的句子組合回去\n",
    "    test_ner['people_list'] = people_list\n",
    "    content = test_ner[['news_id', 'content', 'aml_label', 'prediction']]\n",
    "    content = content.groupby(['news_id', 'aml_label', 'prediction'])['content'].apply(lambda x : '。'.join(x)).reset_index()\n",
    "    people = test_ner[['news_id', 'aml_label', 'prediction', 'people_list']]\n",
    "    people = people.groupby(['news_id', 'aml_label', 'prediction'])['people_list'].agg(sum).reset_index()\n",
    "    people['people_list'] = [list(set(people)) for people in people['people_list']]\n",
    "    test_ner = pd.merge(content, people, on=['news_id', 'aml_label', 'prediction'], how='left')\n",
    "    \n",
    "    # 5. 將 [UNK], [PAD] 轉換回來 (王春? -> 王春甡)\n",
    "    for _, row in test_ner.iterrows():\n",
    "        for i, name in enumerate(row['people_list']):\n",
    "            if ('?' in name) | ('!' in name):\n",
    "                reexp = name.replace('?', '.').replace('!', '.')\n",
    "                row['people_list'][i] = re.search(reexp, row['content']).group()\n",
    "    \n",
    "    \n",
    "    print('0.CKIP', datetime.now() - time)\n",
    "    \n",
    "    # 6. 判斷名字前後句使是否為 aml\n",
    "    AML = predict_sentences(test_ner, list(test_ner['people_list']), tokenizer=tokenizer, maxlen=maxlen, stick=stick, threshold=threshold)\n",
    "    \n",
    "    test_prediction = pd.merge(test, AML[['news_id', 'Name']], on='news_id', how='left')\n",
    "    test_prediction['Name'] = test_prediction['Name'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "    test_prediction['text_prediction'] = test_prediction['Name'].apply(lambda x: 0 if x == [] else 1)\n",
    "    test_prediction = test_prediction.drop(['content'],axis = 1)\n",
    "    test_prediction.columns = ['news_id', 'name', 'label', 'AML_prediction', 'Name_prediction', 'text_prediction']\n",
    "    \n",
    "    # 7. 算分數\n",
    "    score = []\n",
    "    for i in range(len(test_prediction)):\n",
    "        temp = f1_score(test_prediction['name'][i], test_prediction['Name_prediction'][i])\n",
    "        score.append(temp)\n",
    "        \n",
    "    test_prediction['f1_score'] = score    \n",
    "    total_score = sum(score)\n",
    "    aml_score = sum(test_prediction[test_prediction['label'] == 1]['f1_score'])    \n",
    "    \n",
    "    df = df.append(pd.DataFrame([[aml_threshold, threshold, stick, total_score, aml_score]], columns=df.columns))\n",
    "    \n",
    "    print('aml_threshold =', aml_threshold, 'stick =', stick, 'threshold =', threshold, 'total_score =', total_score, 'aml_score =', aml_score)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['aml_threshold', 'threshold', 'stick', 'total_score', 'aml_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jasonhsu\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.CKIP 0:00:23.768912\n",
      "1.提取句子 0:00:01.388930\n",
      "2.整理名字 0:00:00.059773\n",
      "3.刪除名字 0:00:00.004590\n",
      "4.預測名字 0:00:09.479925\n",
      "aml_threshold = 0.2 stick = False threshold = 0.3 total_score = 956.7968253968252 aml_score = 60.796825396825376\n",
      "0.CKIP 0:00:21.562784\n",
      "1.提取句子 0:00:01.310155\n",
      "2.整理名字 0:00:00.060914\n",
      "3.刪除名字 0:00:00.006980\n",
      "4.預測名字 0:00:09.480315\n",
      "aml_threshold = 0.2 stick = False threshold = 0.4 total_score = 956.6788766788766 aml_score = 60.678876678876655\n",
      "0.CKIP 0:00:21.580583\n",
      "1.提取句子 0:00:01.318838\n",
      "2.整理名字 0:00:00.060882\n",
      "3.刪除名字 0:00:00.006982\n",
      "4.預測名字 0:00:09.494191\n",
      "aml_threshold = 0.2 stick = False threshold = 0.5 total_score = 957.01221001221 aml_score = 60.01221001220999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jasonhsu\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.CKIP 0:00:21.568695\n",
      "1.提取句子 0:00:01.323399\n",
      "2.整理名字 0:00:00.059878\n",
      "3.刪除名字 0:00:00.006982\n",
      "4.預測名字 0:00:09.483897\n",
      "aml_threshold = 0.2 stick = False threshold = 0.6 total_score = 957.171335200747 aml_score = 60.171335200746945\n",
      "0.CKIP 0:00:21.039716\n",
      "1.提取句子 0:00:01.275818\n",
      "2.整理名字 0:00:00.057968\n",
      "3.刪除名字 0:00:00.007980\n",
      "4.預測名字 0:00:08.994437\n",
      "aml_threshold = 0.3 stick = False threshold = 0.3 total_score = 958.0468253968252 aml_score = 60.046825396825376\n",
      "0.CKIP 0:00:21.011572\n",
      "1.提取句子 0:00:01.260113\n",
      "2.整理名字 0:00:00.056714\n",
      "3.刪除名字 0:00:00.007978\n",
      "4.預測名字 0:00:08.980761\n",
      "aml_threshold = 0.3 stick = False threshold = 0.4 total_score = 957.9288766788766 aml_score = 59.928876678876655\n",
      "0.CKIP 0:00:21.074110\n",
      "1.提取句子 0:00:01.260015\n",
      "2.整理名字 0:00:00.057352\n",
      "3.刪除名字 0:00:00.006981\n",
      "4.預測名字 0:00:09.002558\n",
      "aml_threshold = 0.3 stick = False threshold = 0.5 total_score = 957.26221001221 aml_score = 59.26221001220999\n",
      "0.CKIP 0:00:21.023408\n",
      "1.提取句子 0:00:01.280817\n",
      "2.整理名字 0:00:00.056821\n",
      "3.刪除名字 0:00:00.006981\n",
      "4.預測名字 0:00:09.004458\n",
      "aml_threshold = 0.3 stick = False threshold = 0.6 total_score = 957.421335200747 aml_score = 59.421335200746945\n",
      "0.CKIP 0:00:21.008065\n",
      "1.提取句子 0:00:01.259630\n",
      "2.整理名字 0:00:00.056937\n",
      "3.刪除名字 0:00:00.007974\n",
      "4.預測名字 0:00:08.993757\n",
      "aml_threshold = 0.4 stick = False threshold = 0.3 total_score = 958.0468253968252 aml_score = 60.046825396825376\n",
      "0.CKIP 0:00:21.004994\n",
      "1.提取句子 0:00:01.263570\n",
      "2.整理名字 0:00:00.057844\n",
      "3.刪除名字 0:00:00.006981\n",
      "4.預測名字 0:00:08.989120\n",
      "aml_threshold = 0.4 stick = False threshold = 0.4 total_score = 957.9288766788766 aml_score = 59.928876678876655\n",
      "0.CKIP 0:00:21.006989\n",
      "1.提取句子 0:00:01.275906\n",
      "2.整理名字 0:00:00.056844\n",
      "3.刪除名字 0:00:00.007978\n",
      "4.預測名字 0:00:09.000912\n",
      "aml_threshold = 0.4 stick = False threshold = 0.5 total_score = 957.26221001221 aml_score = 59.26221001220999\n",
      "0.CKIP 0:00:20.991477\n",
      "1.提取句子 0:00:01.257956\n",
      "2.整理名字 0:00:00.055847\n",
      "3.刪除名字 0:00:00.006981\n",
      "4.預測名字 0:00:08.972064\n",
      "aml_threshold = 0.4 stick = False threshold = 0.6 total_score = 957.421335200747 aml_score = 59.421335200746945\n",
      "0.CKIP 0:00:20.816071\n",
      "1.提取句子 0:00:01.212247\n",
      "2.整理名字 0:00:00.054845\n",
      "3.刪除名字 0:00:00.006988\n",
      "4.預測名字 0:00:08.827375\n",
      "aml_threshold = 0.5 stick = False threshold = 0.3 total_score = 957.0468253968252 aml_score = 59.046825396825376\n",
      "0.CKIP 0:00:20.803142\n",
      "1.提取句子 0:00:01.208982\n",
      "2.整理名字 0:00:00.054922\n",
      "3.刪除名字 0:00:00.006984\n",
      "4.預測名字 0:00:08.810224\n",
      "aml_threshold = 0.5 stick = False threshold = 0.4 total_score = 956.9288766788766 aml_score = 58.928876678876655\n",
      "0.CKIP 0:00:20.832392\n",
      "1.提取句子 0:00:01.202211\n",
      "2.整理名字 0:00:00.053856\n",
      "3.刪除名字 0:00:00.006981\n",
      "4.預測名字 0:00:08.816507\n",
      "aml_threshold = 0.5 stick = False threshold = 0.5 total_score = 956.26221001221 aml_score = 58.26221001220999\n",
      "0.CKIP 0:00:20.802359\n",
      "1.提取句子 0:00:01.211035\n",
      "2.整理名字 0:00:00.053874\n",
      "3.刪除名字 0:00:00.006981\n",
      "4.預測名字 0:00:08.806274\n",
      "aml_threshold = 0.5 stick = False threshold = 0.6 total_score = 956.421335200747 aml_score = 58.421335200746945\n"
     ]
    }
   ],
   "source": [
    "for aml_threshold in [0.2, 0.3, 0.4, 0.5]:\n",
    "    for threshold in [0.3, 0.4, 0.5, 0.6]:\n",
    "        for stick in [False]:        \n",
    "            df = GridSearch_ner(df, model, test, aml_threshold=aml_threshold, stick=stick, threshold=threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2 [CKIP法]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ckip(test):\n",
    "    \n",
    "    people_list = []\n",
    "    for aml_news in test['content']:\n",
    "        \n",
    "        # 分詞\n",
    "        word_sentence_list = ws([aml_news],\n",
    "                    sentence_segmentation=True,\n",
    "                    segment_delimiter_set={'?', '？', '!', '！', '。', ',', '，', ';', ':', '、'})\n",
    "        pos_sentence_list = pos(word_sentence_list)\n",
    "        entity_sentence_list = ner(word_sentence_list, pos_sentence_list)\n",
    "        \n",
    "        # 只取人名\n",
    "        people = [people for people in list(entity_sentence_list[0]) if (people[2] == 'PERSON')]\n",
    "        people = [person for person in [person[3] for person in people] if (len(person) < 5) | ('．' in person)]\n",
    "        people = list(set(people))\n",
    "        people_list.append(people)\n",
    "        \n",
    "    return people_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GridSearch(df2, model, test, aml_threshold, stick, threshold):\n",
    "    time = datetime.now()\n",
    "    \n",
    "    # 1. 預測是否疑似 aml\n",
    "    prediction = predict_aml(model, test, aml_threshold=aml_threshold)\n",
    "    test['prediction'] = prediction\n",
    "    aml_highrisk = test[test['prediction'] == 1]\n",
    "    \n",
    "    # 2. CKIP 預測人名\n",
    "    people_list = ckip(aml_highrisk)\n",
    "    \n",
    "    print('0.CKIP', datetime.now() - time)\n",
    "    \n",
    "    # 3. 判斷名字前後句使是否為 aml\n",
    "    AML = predict_sentences(test, people_list, tokenizer=tokenizer, maxlen=maxlen, stick=stick, threshold=threshold)\n",
    "    \n",
    "    test_prediction = pd.merge(test, AML[['news_id', 'Name']], on='news_id', how='left')\n",
    "    test_prediction['Name'] = test_prediction['Name'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "    test_prediction['text_prediction'] = test_prediction['Name'].apply(lambda x: 0 if x == [] else 1)\n",
    "    test_prediction = test_prediction.drop(['content'],axis = 1)\n",
    "    test_prediction.columns = ['news_id', 'name', 'label', 'AML_prediction', 'Name_prediction', 'text_prediction']\n",
    "    \n",
    "    # 4. 算分數\n",
    "    score = []\n",
    "    for i in range(len(test_prediction)):\n",
    "        temp = f1_score(test_prediction['name'][i], test_prediction['Name_prediction'][i])\n",
    "        score.append(temp)\n",
    "        \n",
    "    test_prediction['f1_score'] = score    \n",
    "    total_score = sum(score)\n",
    "    aml_score = sum(test_prediction[test_prediction['label'] == 1]['f1_score'])    \n",
    "\n",
    "    \n",
    "    df2 = df2.append(pd.DataFrame([[aml_threshold, threshold, stick, total_score, aml_score]], columns=df.columns))\n",
    "    print('aml_threshold =', aml_threshold, 'stick =', stick, 'threshold =', threshold, 'total_score =', total_score, 'aml_score =', aml_score)\n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(columns=['aml_threshold', 'threshold', 'stick', 'total_score', 'aml_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jasonhsu\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.CKIP 0:01:16.723094\n",
      "1.提取句子 0:00:01.714970\n",
      "2.整理名字 0:00:00.061341\n",
      "3.刪除名字 0:00:00.008976\n",
      "4.預測名字 0:00:11.913243\n",
      "aml_threshold = 0.2 stick = False threshold = 0.3 total_score = 955.5583743842362 aml_score = 61.55837438423644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jasonhsu\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.CKIP 0:01:16.823463\n",
      "1.提取句子 0:00:01.624652\n",
      "2.整理名字 0:00:00.060837\n",
      "3.刪除名字 0:00:00.009973\n",
      "4.預測名字 0:00:11.918961\n",
      "aml_threshold = 0.2 stick = False threshold = 0.4 total_score = 955.616183242045 aml_score = 61.61618324204529\n",
      "0.CKIP 0:01:16.584803\n",
      "1.提取句子 0:00:01.623785\n",
      "2.整理名字 0:00:00.060649\n",
      "3.刪除名字 0:00:00.002099\n",
      "4.預測名字 0:00:11.908833\n",
      "aml_threshold = 0.2 stick = False threshold = 0.5 total_score = 955.1495165753785 aml_score = 61.14951657537863\n",
      "0.CKIP 0:01:16.720413\n",
      "1.提取句子 0:00:01.651036\n",
      "2.整理名字 0:00:00.061956\n",
      "3.刪除名字 0:00:00.010002\n",
      "4.預測名字 0:00:11.911002\n",
      "aml_threshold = 0.2 stick = False threshold = 0.6 total_score = 955.3605898158636 aml_score = 61.36058981586363\n",
      "0.CKIP 0:01:12.089171\n",
      "1.提取句子 0:00:01.557338\n",
      "2.整理名字 0:00:00.058842\n",
      "3.刪除名字 0:00:00.008982\n",
      "4.預測名字 0:00:11.099192\n",
      "aml_threshold = 0.3 stick = False threshold = 0.3 total_score = 955.6694854953473 aml_score = 60.66948549534755\n",
      "0.CKIP 0:01:12.637532\n",
      "1.提取句子 0:00:01.561191\n",
      "2.整理名字 0:00:00.058873\n",
      "3.刪除名字 0:00:00.004768\n",
      "4.預測名字 0:00:11.097317\n",
      "aml_threshold = 0.3 stick = False threshold = 0.4 total_score = 955.7272943531561 aml_score = 60.7272943531564\n",
      "0.CKIP 0:01:12.221262\n",
      "1.提取句子 0:00:01.555188\n",
      "2.整理名字 0:00:00.058842\n",
      "3.刪除名字 0:00:00.009974\n",
      "4.預測名字 0:00:11.075563\n",
      "aml_threshold = 0.3 stick = False threshold = 0.5 total_score = 955.2606276864896 aml_score = 60.26062768648974\n",
      "0.CKIP 0:01:12.269914\n",
      "1.提取句子 0:00:01.566228\n",
      "2.整理名字 0:00:00.053622\n",
      "3.刪除名字 0:00:00.009967\n",
      "4.預測名字 0:00:11.102701\n",
      "aml_threshold = 0.3 stick = False threshold = 0.6 total_score = 955.4717009269747 aml_score = 60.47170092697474\n",
      "0.CKIP 0:01:11.845308\n",
      "1.提取句子 0:00:01.531528\n",
      "2.整理名字 0:00:00.058492\n",
      "3.刪除名字 0:00:00.005119\n",
      "4.預測名字 0:00:11.110197\n",
      "aml_threshold = 0.4 stick = False threshold = 0.3 total_score = 955.6694854953473 aml_score = 60.66948549534755\n",
      "0.CKIP 0:01:12.122938\n",
      "1.提取句子 0:00:01.537478\n",
      "2.整理名字 0:00:00.058009\n",
      "3.刪除名字 0:00:00.010006\n",
      "4.預測名字 0:00:11.084164\n",
      "aml_threshold = 0.4 stick = False threshold = 0.4 total_score = 955.7272943531561 aml_score = 60.7272943531564\n",
      "0.CKIP 0:01:12.044339\n",
      "1.提取句子 0:00:01.550356\n",
      "2.整理名字 0:00:00.060104\n",
      "3.刪除名字 0:00:00.009772\n",
      "4.預測名字 0:00:11.090320\n",
      "aml_threshold = 0.4 stick = False threshold = 0.5 total_score = 955.2606276864896 aml_score = 60.26062768648974\n",
      "0.CKIP 0:01:12.088463\n",
      "1.提取句子 0:00:01.531846\n",
      "2.整理名字 0:00:00.057850\n",
      "3.刪除名字 0:00:00.009974\n",
      "4.預測名字 0:00:11.108226\n",
      "aml_threshold = 0.4 stick = False threshold = 0.6 total_score = 955.4717009269747 aml_score = 60.47170092697474\n",
      "0.CKIP 0:01:09.193653\n",
      "1.提取句子 0:00:01.462286\n",
      "2.整理名字 0:00:00.055934\n",
      "3.刪除名字 0:00:00.008892\n",
      "4.預測名字 0:00:10.599222\n",
      "aml_threshold = 0.5 stick = False threshold = 0.3 total_score = 956.6694854953473 aml_score = 59.66948549534755\n",
      "0.CKIP 0:01:08.852906\n",
      "1.提取句子 0:00:01.467575\n",
      "2.整理名字 0:00:00.056903\n",
      "3.刪除名字 0:00:00.008974\n",
      "4.預測名字 0:00:10.581259\n",
      "aml_threshold = 0.5 stick = False threshold = 0.4 total_score = 956.7272943531561 aml_score = 59.7272943531564\n",
      "0.CKIP 0:01:09.212650\n",
      "1.提取句子 0:00:01.469041\n",
      "2.整理名字 0:00:00.055906\n",
      "3.刪除名字 0:00:00.008974\n",
      "4.預測名字 0:00:10.604056\n",
      "aml_threshold = 0.5 stick = False threshold = 0.5 total_score = 956.2606276864896 aml_score = 59.26062768648974\n",
      "0.CKIP 0:01:08.975247\n",
      "1.提取句子 0:00:01.467458\n",
      "2.整理名字 0:00:00.053711\n",
      "3.刪除名字 0:00:00.009639\n",
      "4.預測名字 0:00:10.592732\n",
      "aml_threshold = 0.5 stick = False threshold = 0.6 total_score = 956.4717009269747 aml_score = 59.47170092697474\n"
     ]
    }
   ],
   "source": [
    "for aml_threshold in [0.2, 0.3, 0.4, 0.5]:\n",
    "    for threshold in [0.3, 0.4, 0.5, 0.6]:\n",
    "        for stick in [False]:        \n",
    "            df2 = GridSearch(df2, model, test, aml_threshold=aml_threshold, stick=stick, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aml_threshold</th>\n",
       "      <th>threshold</th>\n",
       "      <th>stick</th>\n",
       "      <th>total_score</th>\n",
       "      <th>aml_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>False</td>\n",
       "      <td>956.796825</td>\n",
       "      <td>60.796825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>False</td>\n",
       "      <td>956.678877</td>\n",
       "      <td>60.678877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>957.012210</td>\n",
       "      <td>60.012210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>False</td>\n",
       "      <td>957.171335</td>\n",
       "      <td>60.171335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>False</td>\n",
       "      <td>958.046825</td>\n",
       "      <td>60.046825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>False</td>\n",
       "      <td>957.928877</td>\n",
       "      <td>59.928877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>957.262210</td>\n",
       "      <td>59.262210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>False</td>\n",
       "      <td>957.421335</td>\n",
       "      <td>59.421335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>False</td>\n",
       "      <td>958.046825</td>\n",
       "      <td>60.046825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>False</td>\n",
       "      <td>957.928877</td>\n",
       "      <td>59.928877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>957.262210</td>\n",
       "      <td>59.262210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>False</td>\n",
       "      <td>957.421335</td>\n",
       "      <td>59.421335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>False</td>\n",
       "      <td>957.046825</td>\n",
       "      <td>59.046825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>False</td>\n",
       "      <td>956.928877</td>\n",
       "      <td>58.928877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>956.262210</td>\n",
       "      <td>58.262210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>False</td>\n",
       "      <td>956.421335</td>\n",
       "      <td>58.421335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   aml_threshold  threshold  stick  total_score  aml_score\n",
       "0            0.2        0.3  False   956.796825  60.796825\n",
       "0            0.2        0.4  False   956.678877  60.678877\n",
       "0            0.2        0.5  False   957.012210  60.012210\n",
       "0            0.2        0.6  False   957.171335  60.171335\n",
       "0            0.3        0.3  False   958.046825  60.046825\n",
       "0            0.3        0.4  False   957.928877  59.928877\n",
       "0            0.3        0.5  False   957.262210  59.262210\n",
       "0            0.3        0.6  False   957.421335  59.421335\n",
       "0            0.4        0.3  False   958.046825  60.046825\n",
       "0            0.4        0.4  False   957.928877  59.928877\n",
       "0            0.4        0.5  False   957.262210  59.262210\n",
       "0            0.4        0.6  False   957.421335  59.421335\n",
       "0            0.5        0.3  False   957.046825  59.046825\n",
       "0            0.5        0.4  False   956.928877  58.928877\n",
       "0            0.5        0.5  False   956.262210  58.262210\n",
       "0            0.5        0.6  False   956.421335  58.421335"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aml_threshold</th>\n",
       "      <th>threshold</th>\n",
       "      <th>stick</th>\n",
       "      <th>total_score</th>\n",
       "      <th>aml_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>False</td>\n",
       "      <td>955.558374</td>\n",
       "      <td>61.558374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>False</td>\n",
       "      <td>955.616183</td>\n",
       "      <td>61.616183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>955.149517</td>\n",
       "      <td>61.149517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>False</td>\n",
       "      <td>955.360590</td>\n",
       "      <td>61.360590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>False</td>\n",
       "      <td>955.669485</td>\n",
       "      <td>60.669485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>False</td>\n",
       "      <td>955.727294</td>\n",
       "      <td>60.727294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>955.260628</td>\n",
       "      <td>60.260628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>False</td>\n",
       "      <td>955.471701</td>\n",
       "      <td>60.471701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>False</td>\n",
       "      <td>955.669485</td>\n",
       "      <td>60.669485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>False</td>\n",
       "      <td>955.727294</td>\n",
       "      <td>60.727294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>955.260628</td>\n",
       "      <td>60.260628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>False</td>\n",
       "      <td>955.471701</td>\n",
       "      <td>60.471701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>False</td>\n",
       "      <td>956.669485</td>\n",
       "      <td>59.669485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>False</td>\n",
       "      <td>956.727294</td>\n",
       "      <td>59.727294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>956.260628</td>\n",
       "      <td>59.260628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>False</td>\n",
       "      <td>956.471701</td>\n",
       "      <td>59.471701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   aml_threshold  threshold  stick  total_score  aml_score\n",
       "0            0.2        0.3  False   955.558374  61.558374\n",
       "0            0.2        0.4  False   955.616183  61.616183\n",
       "0            0.2        0.5  False   955.149517  61.149517\n",
       "0            0.2        0.6  False   955.360590  61.360590\n",
       "0            0.3        0.3  False   955.669485  60.669485\n",
       "0            0.3        0.4  False   955.727294  60.727294\n",
       "0            0.3        0.5  False   955.260628  60.260628\n",
       "0            0.3        0.6  False   955.471701  60.471701\n",
       "0            0.4        0.3  False   955.669485  60.669485\n",
       "0            0.4        0.4  False   955.727294  60.727294\n",
       "0            0.4        0.5  False   955.260628  60.260628\n",
       "0            0.4        0.6  False   955.471701  60.471701\n",
       "0            0.5        0.3  False   956.669485  59.669485\n",
       "0            0.5        0.4  False   956.727294  59.727294\n",
       "0            0.5        0.5  False   956.260628  59.260628\n",
       "0            0.5        0.6  False   956.471701  59.471701"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aml_threshold</th>\n",
       "      <th>threshold</th>\n",
       "      <th>stick</th>\n",
       "      <th>total_score_x</th>\n",
       "      <th>aml_score_x</th>\n",
       "      <th>total_score_y</th>\n",
       "      <th>aml_score_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>False</td>\n",
       "      <td>956.796825</td>\n",
       "      <td>60.796825</td>\n",
       "      <td>955.558374</td>\n",
       "      <td>61.558374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>False</td>\n",
       "      <td>956.678877</td>\n",
       "      <td>60.678877</td>\n",
       "      <td>955.616183</td>\n",
       "      <td>61.616183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>957.012210</td>\n",
       "      <td>60.012210</td>\n",
       "      <td>955.149517</td>\n",
       "      <td>61.149517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>False</td>\n",
       "      <td>957.171335</td>\n",
       "      <td>60.171335</td>\n",
       "      <td>955.360590</td>\n",
       "      <td>61.360590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>False</td>\n",
       "      <td>958.046825</td>\n",
       "      <td>60.046825</td>\n",
       "      <td>955.669485</td>\n",
       "      <td>60.669485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>False</td>\n",
       "      <td>957.928877</td>\n",
       "      <td>59.928877</td>\n",
       "      <td>955.727294</td>\n",
       "      <td>60.727294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>957.262210</td>\n",
       "      <td>59.262210</td>\n",
       "      <td>955.260628</td>\n",
       "      <td>60.260628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>False</td>\n",
       "      <td>957.421335</td>\n",
       "      <td>59.421335</td>\n",
       "      <td>955.471701</td>\n",
       "      <td>60.471701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>False</td>\n",
       "      <td>958.046825</td>\n",
       "      <td>60.046825</td>\n",
       "      <td>955.669485</td>\n",
       "      <td>60.669485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>False</td>\n",
       "      <td>957.928877</td>\n",
       "      <td>59.928877</td>\n",
       "      <td>955.727294</td>\n",
       "      <td>60.727294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>957.262210</td>\n",
       "      <td>59.262210</td>\n",
       "      <td>955.260628</td>\n",
       "      <td>60.260628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>False</td>\n",
       "      <td>957.421335</td>\n",
       "      <td>59.421335</td>\n",
       "      <td>955.471701</td>\n",
       "      <td>60.471701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>False</td>\n",
       "      <td>957.046825</td>\n",
       "      <td>59.046825</td>\n",
       "      <td>956.669485</td>\n",
       "      <td>59.669485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>False</td>\n",
       "      <td>956.928877</td>\n",
       "      <td>58.928877</td>\n",
       "      <td>956.727294</td>\n",
       "      <td>59.727294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>956.262210</td>\n",
       "      <td>58.262210</td>\n",
       "      <td>956.260628</td>\n",
       "      <td>59.260628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>False</td>\n",
       "      <td>956.421335</td>\n",
       "      <td>58.421335</td>\n",
       "      <td>956.471701</td>\n",
       "      <td>59.471701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    aml_threshold  threshold  stick  total_score_x  aml_score_x  \\\n",
       "0             0.2        0.3  False     956.796825    60.796825   \n",
       "1             0.2        0.4  False     956.678877    60.678877   \n",
       "2             0.2        0.5  False     957.012210    60.012210   \n",
       "3             0.2        0.6  False     957.171335    60.171335   \n",
       "4             0.3        0.3  False     958.046825    60.046825   \n",
       "5             0.3        0.4  False     957.928877    59.928877   \n",
       "6             0.3        0.5  False     957.262210    59.262210   \n",
       "7             0.3        0.6  False     957.421335    59.421335   \n",
       "8             0.4        0.3  False     958.046825    60.046825   \n",
       "9             0.4        0.4  False     957.928877    59.928877   \n",
       "10            0.4        0.5  False     957.262210    59.262210   \n",
       "11            0.4        0.6  False     957.421335    59.421335   \n",
       "12            0.5        0.3  False     957.046825    59.046825   \n",
       "13            0.5        0.4  False     956.928877    58.928877   \n",
       "14            0.5        0.5  False     956.262210    58.262210   \n",
       "15            0.5        0.6  False     956.421335    58.421335   \n",
       "\n",
       "    total_score_y  aml_score_y  \n",
       "0      955.558374    61.558374  \n",
       "1      955.616183    61.616183  \n",
       "2      955.149517    61.149517  \n",
       "3      955.360590    61.360590  \n",
       "4      955.669485    60.669485  \n",
       "5      955.727294    60.727294  \n",
       "6      955.260628    60.260628  \n",
       "7      955.471701    60.471701  \n",
       "8      955.669485    60.669485  \n",
       "9      955.727294    60.727294  \n",
       "10     955.260628    60.260628  \n",
       "11     955.471701    60.471701  \n",
       "12     956.669485    59.669485  \n",
       "13     956.727294    59.727294  \n",
       "14     956.260628    59.260628  \n",
       "15     956.471701    59.471701  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df, df2, on=['aml_threshold', 'threshold', 'stick'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. NER, CKIP比較 (待整理)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jasonhsu\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Jasonhsu\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:163: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "C:\\Users\\Jasonhsu\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:176: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Jasonhsu\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# 預測是否疑似aml\n",
    "prediction = predict_aml(model, test, aml_threshold=0.4)\n",
    "test['prediction'] = prediction\n",
    "aml_highrisk = test[test['prediction'] == 1]\n",
    "\n",
    "# 將超過512的句子拆成多句分段預測\n",
    "test_ner = aml_highrisk.drop(['name'], axis=1)\n",
    "data_less = test_ner[test_ner['content'].str.len() <= 512]\n",
    "data_more = test_ner[test_ner['content'].str.len() > 512]\n",
    "data_more_split = split_content(data_more)\n",
    "test_ner = test_ner.append(data_more_split)\n",
    "test_ner = test_ner.reset_index().drop(['index'], axis=1)\n",
    "\n",
    "# 預測人名\n",
    "input_id, segment_id, mask_input = encoded(tokenizer, test_ner, maxlen=maxlen_ner)\n",
    "prediction = ner_model.predict([input_id, segment_id, mask_input])\n",
    "y_pred = np.argmax(prediction, axis=-1)\n",
    "people_list = get_name(input_id, y_pred)\n",
    "\n",
    "# 將拆開的句子組合回去\n",
    "test_ner['people_list'] = people_list\n",
    "content = test_ner[['news_id', 'content', 'aml_label', 'prediction']]\n",
    "content = content.groupby(['news_id', 'aml_label', 'prediction'])['content'].apply(lambda x : '。'.join(x)).reset_index()\n",
    "people = test_ner[['news_id', 'aml_label', 'prediction', 'people_list']]\n",
    "people = people.groupby(['news_id', 'aml_label', 'prediction'])['people_list'].agg(sum).reset_index()\n",
    "people['people_list'] = [list(set(people)) for people in people['people_list']]\n",
    "test_ner = pd.merge(content, people, on=['news_id', 'aml_label', 'prediction'], how='left')\n",
    "\n",
    "# 將 [UNK], [PAD] 轉換回來\n",
    "for _, row in test_ner.iterrows():\n",
    "    for i, name in enumerate(row['people_list']):\n",
    "        if ('?' in name) | ('!' in name):\n",
    "            reexp = name.replace('?', '.').replace('!', '.')\n",
    "            row['people_list'][i] = re.search(reexp, row['content']).group()\n",
    "            \n",
    "AML = pd.DataFrame(columns=['news_id', 'Name', 'Sentence'])\n",
    "aml_highrisk = np.asarray(test['content'][test['prediction'] == 1])\n",
    "news_ids = np.asarray(test['news_id'][test['prediction'] == 1])\n",
    "\n",
    "for k, (news_id, y_news) in enumerate(zip(news_ids ,aml_highrisk)): \n",
    "    #用，。？切分句子\n",
    "    news = re.split('，|。|？|！', y_news)\n",
    "\n",
    "    for i in range(len(people_list[k])):\n",
    "        #找出人名存在的news index\n",
    "        index = [index for index, _ in enumerate(news) if people_list[k][i] in _]                           \n",
    "\n",
    "        #刪除前後句中有出現其他姓名的句子 (XX，陳水扁貪汙，吳淑珍也是 -> XX，陳水扁貪汙，也是)\n",
    "\n",
    "        for j in index:\n",
    "\n",
    "            name = [name for name in people_list[k] if name != people_list[k][i]]\n",
    "            new_news = re.sub('|'.join(name), '', news[j])\n",
    "\n",
    "            if j == 0:\n",
    "                new_news2 = re.sub('|'.join(name), '', news[j+1])    \n",
    "                sentences = new_news + '，' + new_news2\n",
    "\n",
    "            elif j+1 == len(news):\n",
    "                new_news3 = re.sub('|'.join(name), '', news[j-1]) \n",
    "                sentences = new_news3 + '，' + new_news\n",
    "\n",
    "            else:\n",
    "                new_news2 = re.sub('|'.join(name), '', news[j+1]) \n",
    "                new_news3 = re.sub('|'.join(name), '', news[j-1]) \n",
    "                sentences = new_news3 + '，' + new_news + '，' + new_news2\n",
    "\n",
    "\n",
    "\n",
    "            AML = AML.append(pd.DataFrame([[news_ids[k] ,people_list[k][i], sentences]], columns=AML.columns))\n",
    "\n",
    "\n",
    "#若 stick==True 則把多筆同姓名句子以逗點合併\n",
    "if stick:\n",
    "    AML = AML.groupby(['news_id', 'Name'])['Sentence'].apply('，'.join).reset_index()\n",
    "\n",
    "#姓氏表\n",
    "first_name = [\n",
    "    '申', '龔', '馮', '昌', '劉', '習', '陽', '顧', '鍾', '胡', '許', '魏',\n",
    "    '傅', '季', '扶', '柳', '狄', '焦', '封', '李', '羿', '刁', '和', '邴',\n",
    "    '陸', '王', '杜', '能', '侯', '伍', '平', '竺', '樂', '繆', '欒', '湛',\n",
    "    '道', '花', '賴', '浦', '萬', '章', '宮', '勾', '邵', '印', '夏', '杭',\n",
    "    '溥', '左', '池', '公', '閻', '符', '奚', '臧', '羅', '空', '璩', '巴',\n",
    "    '酈', '范', '談', '金', '顏', '慎', '郭', '僪', '聞', '車', '闞', '相',\n",
    "    '童', '雙', '方', '莊', '容', '姚', '田', '薛', '閔', '翟', '簡',\n",
    "    '蔚', '茹', '淩', '戴', '余', '鞏', '房', '富', '牛', '饒', '計', '居',\n",
    "    '後', '舒', '席', '翁', '祝', '鬱', '訾', '隆', '匡', '弘', '曆', '範',\n",
    "    '越', '趙', '卻', '岑', '隗', '冷', '張', '山', '松', '柯', '嵇', '韓',\n",
    "    '蕭', '褚', '殳', '滕', '滿', '洪', '荀', '庾', '廖', '盧', '危', '竇',\n",
    "    '曾', '郎', '遊', '穀', '慕', '禹', '凌', '廉', '邢', '梁', '葉',\n",
    "    '郝', '終', '齊', '藺', '曹', '全', '高', '樊', '史', '桂', '廣', '段',\n",
    "    '江', '餘', '袁', '弓', '牧', '魚', '儲', '尚', '逄', '尹', '通', '懷',\n",
    "    '皮', '何', '倪', '包', '晁', '涂', '蓬', '屠', '巫', '須', '巢', '卞',\n",
    "    '楊', '成', '孟', '楚', '呂', '古', '毋', '伊', '賁', '喻', '糜',\n",
    "    '蔔', '艾', '藍', '龐', '諸', '別', '任', '管', '冀', '壽', '惠', '梅',\n",
    "    '孫', '從', '康', '常', '駱', '鞠', '沈', '黨', '沙', '鳳', '郁', '邊',\n",
    "    '仰', '溫', '路', '逮', '賀', '雷', '鈄', '明', '裴', '滑', '毛', '費',\n",
    "    '關', '時', '步', '麴', '裘', '蒲', '司', '查', '錢', '盛', '霍', '鮑',\n",
    "    '彭', '龍', '沃', '單', '勞', '秋', '祖', '殷', '茅', '敖', '郗', '石',\n",
    "    '鐘', '嚴', '畢', '燕', '姜', '經', '程', '厙', '柏', '汪', '婁', '胥',\n",
    "    '聶', '邰', '桑', '辛', '扈', '穆', '仲', '紅', '項', '師', '桓', '黃',\n",
    "    '堵', '貢', '詹', '朱', '蔡', '戈', '于', '甄', '束', '屈', '索', '晏',\n",
    "    '阮', '魯', '虞', '歐', '濮', '俞', '黎', '文', '應', '姬', '貝', '籍',\n",
    "    '莘', '戚', '鄭', '郜', '景', '宋', '宗', '昝', '卓', '蒯', '馬', '顔',\n",
    "    '蘇', '衛', '東', '瞿', '蒼', '莫', '邱', '潘', '家', '林', '芮', '麻',\n",
    "    '元', '武', '強', '鈕', '陳', '井', '於', '游', '耿', '柴', '荊', '韶',\n",
    "    '易', '宿', '施', '鹹', '秦', '班', '甯', '汲', '酆', '暴', '尤',\n",
    "    '祿', '苗', '權', '仇', '都', '羊', '榮', '陶', '支', '賈', '白', '葛',\n",
    "    '暨', '解', '靳', '伏', '唐', '華', '吉', '融', '豐', '安', '衡', '那',\n",
    "    '闕', '俄', '盍', '鄔', '蒙', '利', '鄂', '謝', '宓', '湯', '喬', '孔',\n",
    "    '養', '紀', '幹', '牟', '連', '宰', '蔣', '雍', '益', '寇', '祁', '熊',\n",
    "    '崔', '丁', '薊', '譚', '吳', '烏', '周', '農', '徐', '充', '向', '宦',\n",
    "    '董', '甘', '冉', '韋', '米', '鄒', '鄧', '戎', '水'\n",
    "]\n",
    "\n",
    "#把指向同一人的姓名改成一樣（陳男 -> 陳水扁），若指向多人則不改（陳男 -> 陳致中、陳水扁）\n",
    "name_list = []\n",
    "for ids in AML['news_id'].unique():\n",
    "    full_name = [name for name in AML[(AML['news_id'] == ids)]['Name']]\n",
    "    full_3name = [name for name in AML[(AML['news_id'] == ids)]['Name'] if len(name) == 3]\n",
    "\n",
    "    a = Counter([name[0] for name in full_3name])\n",
    "    keep = [k for k,v in a.items() if v == 1]\n",
    "    full_3name_filter = [name for name in full_3name if name[0] in keep]\n",
    "    name_dict = dict((name[0], name) for name in full_3name_filter)   # '陳' : '陳水扁'\n",
    "\n",
    "    name_dict_2 = dict(zip([name[0:2] for name in full_3name], full_3name))  # '王音': '王音之'\n",
    "\n",
    "    for name in full_name:\n",
    "        if (name[0] in name_dict.keys()) & (len(name) == 1):\n",
    "            name_list.append(name_dict.get(name[0]))\n",
    "        elif (name[0] in name_dict.keys()) & (len(name) == 2) & (name[-1] in ['男', '嫌', '婦', '夫', '某', '女', '妻',\\\n",
    "                                                                              '員', '稱', '家', '哥', '媽', '生', '處',\\\n",
    "                                                                              '和', '揆', '要', '再', '董', '涉', '母',\\\n",
    "                                                                              '辱', '公', '少', '為', '指', '翁', '粉',\\\n",
    "                                                                              '趁', '仔', '依', '氏', '父']):\n",
    "            name_list.append(name_dict.get(name[0]))\n",
    "        elif (name in name_dict_2.keys()) & (len(name) == 2):\n",
    "            name_list.append(name_dict_2.get(name))\n",
    "        else:\n",
    "            name_list.append(name)\n",
    "\n",
    "#排除重複資料、排除一字、兩字簡稱、兩字三字四字姓不在姓氏表中的人\n",
    "AML['Name'] = name_list\n",
    "AML = AML.drop_duplicates()\n",
    "AML = AML[AML['Name'].apply(lambda x: (len(x) > 1) )]\n",
    "AML = AML[~AML['Name'].apply(lambda x: (len(x) == 2) & (x[1] in ['男', '嫌', '婦', '夫', '某', '女', '妻',\\\n",
    "                                                                 '員', '稱', '家', '哥', '媽', '生', '處',\\\n",
    "                                                                 '和', '揆', '要', '再', '董', '涉', '母',\\\n",
    "                                                                 '辱', '公', '少', '為', '指', '翁', '粉',\\\n",
    "                                                                 '趁', '仔', '依', '氏', '父']))]\n",
    "AML = AML[AML['Name'].apply(lambda x: (len(x) > 2) | ((len(x) < 3) & (x[0] in first_name)))]\n",
    "AML = AML[~AML['Name'].apply(lambda x: (x[0] not in first_name) & (len(x) in (4,3,2)) )]\n",
    "\n",
    "\n",
    "#第二階段 預測句子\n",
    "input_id, segment_id, mask_input = encoded(tokenizer, AML, maxlen=maxlen)\n",
    "prediction = model.predict([input_id, segment_id, mask_input])\n",
    "AML['raw_prediction'] = np.round(prediction, 3)\n",
    "\n",
    "\n",
    "AML['prediction'] = AML['raw_prediction'].apply(lambda x: 0 if x < 0.7 else 1)\n",
    "AML = AML.groupby(['news_id', 'Name'])['raw_prediction', 'prediction'].max().reset_index()\n",
    "AML = AML[AML['prediction'] == 1]\n",
    "AMLName = AML.groupby(['news_id','prediction'])['Name'].apply(list).reset_index()\n",
    "AMLPrediction = AML.groupby(['news_id'])['raw_prediction'].apply(list).apply(lambda x: np.round(x,2)).reset_index()\n",
    "AMLloss = pd.merge(AMLName, AMLPrediction, how='left', on = 'news_id')\n",
    "AML = pd.merge(test, AMLloss, how='left', on='news_id').drop(['content', 'prediction_y'], axis=1)\n",
    "\n",
    "final2 = AML[AML['aml_label'] == 1]\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "compare = pd.merge(final2, test_ner[['news_id', 'people_list']], on='news_id', how='left')\n",
    "prediction = predict_aml(model, test=test, aml_threshold=aml_threshold)\n",
    "test['prediction'] = prediction\n",
    "aml_highrisk = test[test['prediction'] == 1]\n",
    "people_list = ckip(aml_highrisk)\n",
    "aml_highrisk['ckip_prediction'] = people_list\n",
    "final = pd.merge(compare, aml_highrisk[['news_id', 'ckip_prediction']], on='news_id', how='left')\n",
    "final.columns = ['news_id', 'label_name', 'aml_label', 'prediction', 'Ner_prediction', 'name_score', 'Ner_raw', 'ckip_raw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_id</th>\n",
       "      <th>label_name</th>\n",
       "      <th>aml_label</th>\n",
       "      <th>prediction</th>\n",
       "      <th>Ner_prediction</th>\n",
       "      <th>name_score</th>\n",
       "      <th>Ner_raw</th>\n",
       "      <th>ckip_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4056</td>\n",
       "      <td>[林霙璋, 蔡景德, 齊德清]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[蔡景德, 齊德清]</td>\n",
       "      <td>[0.98, 0.97]</td>\n",
       "      <td>[蔡, 蔡員, 林員, 齊德清, 林, 蔡景德, 齊員, 齊從輕, 林霙璋]</td>\n",
       "      <td>[蔡, 蔡員, 齊德清, 除齊, 林, 齊員處, 齊員, 蔡景德, 林員處, 蔡員處, 林霙璋]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4101</td>\n",
       "      <td>[陳志遇, 林玉華, 陳威廷, 陳富榮, 劉欣燕]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[劉欣燕, 林玉華, 陳威廷, 陳富榮, 陳志遇]</td>\n",
       "      <td>[0.9, 1.0, 1.0, 0.99, 1.0]</td>\n",
       "      <td>[陳志遇, 林玉華, 陳富榮, 陳威廷, 劉欣燕]</td>\n",
       "      <td>[陳志遇, 林玉華, 陳富榮, 陳威廷, 劉欣燕]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3076</td>\n",
       "      <td>[丁奕烜]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[李, 林女, 丁男, 丁奕烜, 李女]</td>\n",
       "      <td>[李, 丁奕烜, 林]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4685</td>\n",
       "      <td>[鄭聖儒]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[鄭聖儒]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[蔡, 鄭聖儒, 徐, 徐女, 鄭男]</td>\n",
       "      <td>[蔡, 徐, 鄭聖儒, 鄭, 徐女, 鄭男]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>855</td>\n",
       "      <td>[陳玟叡, 黃文鴻, 吳承霖]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[吳承霖, 蔡英俊, 陳玟叡, 黃文鴻]</td>\n",
       "      <td>[1.0, 0.87, 1.0, 1.0]</td>\n",
       "      <td>[吳男, 孫, 吳, 吳承霖, 黃男, 蔡英俊, 陳玟叡, 黃文鴻]</td>\n",
       "      <td>[吳男, 黃, 孫, 吳承霖, 黃男, 吳, 嘉檢, 蔡英俊, 台北, 陳玟叡, 黃文鴻]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1420</td>\n",
       "      <td>[余依珊, 孫凱倫]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[余依珊]</td>\n",
       "      <td>[0.74]</td>\n",
       "      <td>[余依珊, 余, 孫凱倫, 林]</td>\n",
       "      <td>[孫男, 林, 余, 余依珊, 孫凱倫]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3131</td>\n",
       "      <td>[胡原龍, 秦朝添]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[王海濤, 秦朝添, 胡原龍, 鈕承澤]</td>\n",
       "      <td>[0.99, 1.0, 1.0, 0.98]</td>\n",
       "      <td>[秦朝添, 胡原龍, 胡, 王海濤, 鈕承澤]</td>\n",
       "      <td>[秦朝添, 胡原龍, 胡, 王海濤, 胡稱, 國磐, 胡受訪, 鈕承澤]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2426</td>\n",
       "      <td>[陳瑞禮, 陳文南]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[陳文南, 陳瑞禮]</td>\n",
       "      <td>[1.0, 1.0]</td>\n",
       "      <td>[陳瑞禮, 陳, 陳文南]</td>\n",
       "      <td>[陳瑞禮, 陳, 陳文南]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>582</td>\n",
       "      <td>[阮文全]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[阮文全]</td>\n",
       "      <td>[0.99]</td>\n",
       "      <td>[阮文全, 阮, 鄭]</td>\n",
       "      <td>[阮, 阮文全, 鄭]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4780</td>\n",
       "      <td>[鄧超鴻, 道克明]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[道克明, 鄧、道, 鄧超鴻]</td>\n",
       "      <td>[0.89, 0.99, 0.96]</td>\n",
       "      <td>[道克明, 鄧、道, 鄧超鴻, 鄧男]</td>\n",
       "      <td>[鄧, 道克明, 鄧男, 鄧超鴻]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3130</td>\n",
       "      <td>[王益洲]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[王益洲]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[王, 李, 秦, 王益洲]</td>\n",
       "      <td>[李, 任, 王, 秦, 王益洲]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3210</td>\n",
       "      <td>[鄭俊宏]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[鄭俊宏]</td>\n",
       "      <td>[0.99]</td>\n",
       "      <td>[鄭, 鄭俊宏, 鄭男, 塗, 羅, 塗女, 羅男]</td>\n",
       "      <td>[鄭, 鄭俊宏, 鄭男, 塗, 羅, 塗女, 羅男]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>419</td>\n",
       "      <td>[陳世坤, 陳素娟, 祁興國]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[祁興國, 陳世坤, 陳素娟]</td>\n",
       "      <td>[1.0, 1.0, 1.0]</td>\n",
       "      <td>[祁興國, 陳素娟, 陳世坤]</td>\n",
       "      <td>[祁興國, 陳素娟, 陳世坤, 江]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>818</td>\n",
       "      <td>[李承孺, 詹國霆, 黃清政, Alan Lim, Mynus Lee]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[李承孺, 詹國霆, 黃清政]</td>\n",
       "      <td>[1.0, 1.0, 1.0]</td>\n",
       "      <td>[詹國霆, 李承孺, 黃清政]</td>\n",
       "      <td>[詹國霆, 李承孺, 黃清政]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4597</td>\n",
       "      <td>[宋芷妍, 王安石]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[王, 宋]</td>\n",
       "      <td>[葉男, 王, 葉, 王明知, 宋]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2145</td>\n",
       "      <td>[張智冠]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[張智冠, 張錦榮, 王柏舜]</td>\n",
       "      <td>[1.0, 0.98, 1.0]</td>\n",
       "      <td>[王燕美, 王柏舜, 張智冠, 張錦榮]</td>\n",
       "      <td>[陳榮聰, 王燕美, 王柏舜, 張錦榮, 張智冠]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4687</td>\n",
       "      <td>[謝淑美]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[謝淑美]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[謝女, 王, 謝淑美, 謝]</td>\n",
       "      <td>[王, 謝淑美, 謝]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4802</td>\n",
       "      <td>[林繼蘇, 徐詩彥]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[徐詩彥, 林繼蘇]</td>\n",
       "      <td>[1.0, 1.0]</td>\n",
       "      <td>[徐, 徐女, 林繼蘇, 林男, 徐詩彥]</td>\n",
       "      <td>[徐, 徐女, 林繼蘇, 林男, 徐詩彥]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4518</td>\n",
       "      <td>[劉威甫, 張桂銘]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[劉威甫]</td>\n",
       "      <td>[0.87]</td>\n",
       "      <td>[張桂銘, 劉威甫]</td>\n",
       "      <td>[周, 張桂銘, 劉威甫, 珍菌堂]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>326</td>\n",
       "      <td>[葉添洽]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[莊佳瑋, 葉添洽, 金裕晟, 陳信郎, 黃淑媛]</td>\n",
       "      <td>[0.95, 1.0, 1.0, 0.98, 0.99]</td>\n",
       "      <td>[黃淑媛, 莊佳瑋, 鄭, 金裕晟, 陳信郎, 杜, 陳, 葉添洽]</td>\n",
       "      <td>[莊佳瑋, 黃淑媛, 鄭, 金裕晟, 陳信郎, 杜, 陳, 葉添洽]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4310</td>\n",
       "      <td>[江盈均, 江志堅, 許志遠, 蔡世誠]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[江志堅, 江盈均, 蔡世誠, 許志遠]</td>\n",
       "      <td>[0.84, 0.84, 0.99, 0.99]</td>\n",
       "      <td>[江, 江志堅, 蔡世誠, 鍾, 許志遠, 江盈均]</td>\n",
       "      <td>[江志堅, 江男庭, 蔡世誠, 鍾, 許志遠, 江男, 鍾婦, 江盈均]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2656</td>\n",
       "      <td>[林致成]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[林致成, 陳富田]</td>\n",
       "      <td>[1.0, 1.0]</td>\n",
       "      <td>[林, 王, 林致成, 陳富田, 羅]</td>\n",
       "      <td>[王觀, 林, 王, 林致成, 陳富田, 羅]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>520</td>\n",
       "      <td>[蘇怡寧]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[蘇怡寧]</td>\n",
       "      <td>[0.94]</td>\n",
       "      <td>[蘇怡寧]</td>\n",
       "      <td>[禾馨, 蘇怡寧]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2548</td>\n",
       "      <td>[吳勝凱]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[吳勝凱]</td>\n",
       "      <td>[0.99]</td>\n",
       "      <td>[李男, 鄭, 吳勝凱, 吳, 鄭婦]</td>\n",
       "      <td>[李男, 鄭, 吳勝凱, 杰樂米, 鄭婦, 筱]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4137</td>\n",
       "      <td>[鍾增林, 曾國財]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[曾國財, 鍾增林]</td>\n",
       "      <td>[1.0, 1.0]</td>\n",
       "      <td>[鍾增林, 黃, 曾國財]</td>\n",
       "      <td>[鍾增林, 黃, 曾國財]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3691</td>\n",
       "      <td>[洪定緯, 馬怡如, 簡以珍, 林玉雀, 潘信興, 陳勇志]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[潘信興, 簡以珍, 陳勇志]</td>\n",
       "      <td>[0.98, 1.0, 1.0]</td>\n",
       "      <td>[潘信興, 陳勇志, 伯納德‧馬多夫, 勞勃狄尼諾, 簡以珍]</td>\n",
       "      <td>[潘信興, 陳勇志, 潘男, 陳, 洪定緯, 簡明, 簡以珍, 馬怡如, 三鑫, 林玉雀]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>280</td>\n",
       "      <td>[楊正平, 蔡思庭]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[楊正平, 蔡思庭]</td>\n",
       "      <td>[1.0, 1.0]</td>\n",
       "      <td>[楊, 楊正平, 蔡思庭]</td>\n",
       "      <td>[楊, 楊正平, 蔡思庭]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>398</td>\n",
       "      <td>[林嘉凌, 林茂樹, 陳國帥]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[林嘉凌, 林茂樹, 陳國帥]</td>\n",
       "      <td>[0.98, 0.99, 1.0]</td>\n",
       "      <td>[林嘉凌, 林茂樹, 陳國帥]</td>\n",
       "      <td>[楊, 紀, 林嘉凌, 陳國帥, 薔薔, 林茂樹, 廖, 陳, 宋]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3465</td>\n",
       "      <td>[房立勳]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[房立勳]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[房立勳]</td>\n",
       "      <td>[房立勳]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>166</td>\n",
       "      <td>[許正雄]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[楊國聰, 許正雄]</td>\n",
       "      <td>[0.99, 0.99]</td>\n",
       "      <td>[楊, 許, 楊國聰, 林, 吳, 許正雄, 劉]</td>\n",
       "      <td>[楊, 許, 楊國聰, 許處, 林, 許和, 吳, 許正雄, 劉]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4230</td>\n",
       "      <td>[楊仕豪, 楊仕銘, 尤嵩斌]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[尤嵩斌, 楊仕豪, 楊仕銘]</td>\n",
       "      <td>[1.0, 1.0, 1.0]</td>\n",
       "      <td>[楊, 楊仕銘, 楊仕豪, 尤嵩斌]</td>\n",
       "      <td>[楊, 楊仕銘, 楊仕豪, 尤嵩斌]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1250</td>\n",
       "      <td>[藍力凱, 許文豪]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[藍力凱, 許文豪, 陳美君, 陳靜慧]</td>\n",
       "      <td>[0.98, 0.99, 0.95, 0.99]</td>\n",
       "      <td>[蘇, 李, 胡, 許文豪, 王, 藍, 陳美君, 藍力凱, 陳靜慧, 黃, 陳]</td>\n",
       "      <td>[蘇, 李, 胡, 許文豪, 王, 陳美君, 藍力凱, 陳靜慧, 黃, 陳]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3226</td>\n",
       "      <td>[何壽川]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[何壽川]</td>\n",
       "      <td>[0.94]</td>\n",
       "      <td>[何壽川, 莊琇媛]</td>\n",
       "      <td>[莊琇媛, 何壽川]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3077</td>\n",
       "      <td>[黃文哲, 陳文君, 林黃財, 徐良吉]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[徐良吉, 林黃財, 陳文君, 黃文哲]</td>\n",
       "      <td>[0.99, 0.99, 0.99, 1.0]</td>\n",
       "      <td>[陳文君, 黃文哲, 徐良吉, 黃男, 林黃財]</td>\n",
       "      <td>[陳文君, 黃文哲, 徐良吉, 黃男, 林黃財]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3864</td>\n",
       "      <td>[黃郁文, 翁朝正, 翁定澤, 何文安]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[何文安, 尤泰盛, 翁定澤, 翁朝正, 黃郁文]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[黃郁文, 尤泰盛, 翁定澤, 何文安, 翁朝正]</td>\n",
       "      <td>[黃郁文, 尤泰盛, 翁定澤, 何文安, 翁朝正]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1285</td>\n",
       "      <td>[孔朝]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[孔朝]</td>\n",
       "      <td>[0.99]</td>\n",
       "      <td>[孔朝, 盧, 盧男]</td>\n",
       "      <td>[孔朝, 盧, 盧男]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1534</td>\n",
       "      <td>[王際平, 林西田, 陳建閣]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[林西田, 王際平, 陳建閣]</td>\n",
       "      <td>[0.91, 0.93, 1.0]</td>\n",
       "      <td>[林西田, 陳建閣, 王際平]</td>\n",
       "      <td>[瑞傑, 陳建閣, 王際平, 林西田]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3305</td>\n",
       "      <td>[吳宗憲, 林志建, 徐兆峰, 李宗原, 黃川禎, 沈珉, 邱彰信, 羅雅美, 張恒嘉]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[徐兆峰, 李宗原, 林志建]</td>\n",
       "      <td>[1.0, 1.0, 1.0]</td>\n",
       "      <td>[徐兆峰, 沈珉, 邱彰信, 林志建, 黃川禎, 羅雅美, 張恒嘉, 李宗原, 吳宗憲]</td>\n",
       "      <td>[徐兆峰, 沈珉, 邱彰信, 林志建, 羅雅美, 黃川禎, 張恒嘉, 李宗原, 吳宗憲]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2338</td>\n",
       "      <td>[吳承霖, 陳玟叡]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[吳承霖, 陳玟叡]</td>\n",
       "      <td>[1.0, 1.0]</td>\n",
       "      <td>[吳, 吳承霖, 陳玟叡]</td>\n",
       "      <td>[陳玟叡, 吳, 吳承霖, 吳再]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4724</td>\n",
       "      <td>[吳秋華, 廖麗櫻]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[吳秋華, 廖麗櫻]</td>\n",
       "      <td>[1.0, 0.98]</td>\n",
       "      <td>[吳秋華, 吳, 廖麗櫻, 廖]</td>\n",
       "      <td>[吳秋華, 吳, 廖麗櫻, 廖女]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1771</td>\n",
       "      <td>[趙藤雄, 趙信清, 李克毅]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[李克毅, 趙信清, 趙藤雄]</td>\n",
       "      <td>[1.0, 1.0, 1.0]</td>\n",
       "      <td>[趙信清, 李克毅, 趙藤雄]</td>\n",
       "      <td>[趙信清, 李克毅, 趙藤雄]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1842</td>\n",
       "      <td>[楊強蓉, 董子綺]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[徐乃麟, 楊強蓉, 董子綺]</td>\n",
       "      <td>[1.0, 1.0, 1.0]</td>\n",
       "      <td>[楊, 董, 許, 楊強蓉, 徐乃麟, 姚, 黃, 董子綺, 何]</td>\n",
       "      <td>[楊, 董向楊, 董, 董說楊, 楊強蓉, 徐乃麟, 許, 姚, 楊租, 牛哥, 董才, 楊...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>140</td>\n",
       "      <td>[吳宗憲, 張恒嘉, 邱彰信, 于堯, 黃川禎, 劉尊彰, 李宗原, 羅雅美, 沈珉, 白梓...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[于堯, 劉尊彰, 吳宗憲, 張恒嘉, 李宗原, 羅雅美, 邱彰信, 黃川禎]</td>\n",
       "      <td>[0.99, 1.0, 0.99, 0.99, 1.0, 0.95, 1.0, 1.0]</td>\n",
       "      <td>[劉尊彰, 于堯, 邱彰信, 蔡英文, 黃川禎, 吳, 羅雅美, 張, 張恒嘉, 李宗原, ...</td>\n",
       "      <td>[沈珉, 劉尊彰, 田佳宜, 于堯, 邱彰信, 白梓佑, 蔡英文, 黃川禎, 吳, 羅雅美,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>3676</td>\n",
       "      <td>[謝春發, 王博民, 歐兆賢, 張力方, 楊文虎, 王音之, 莊淑芬, 林奕如, 李智剛, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[楊宇晨, 楊文虎, 王音之, 黃呈熹]</td>\n",
       "      <td>[0.99, 1.0, 0.99, 1.0]</td>\n",
       "      <td>[楊, 黃呈熹, 楊文虎, 楊宇晨, 王音之, 黃]</td>\n",
       "      <td>[楊, 謝明瑋, 歐兆賢, 林奕如, 黃呈熹, 邱毅, 謝春發, 楊文虎, 王博民, 楊宇晨...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>3180</td>\n",
       "      <td>[吳美惠, 葉正良, 邱春茂, 黃裕源, 林正源, 張廣元, 薛義雄, 李俊諺, 劉宸誌]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[劉宸誌, 吳美惠, 張廣元, 李俊諺, 葉正良, 薛義雄, 邱春茂, 黃裕源]</td>\n",
       "      <td>[1.0, 0.99, 1.0, 0.98, 0.77, 0.79, 0.83, 1.0]</td>\n",
       "      <td>[黃裕源, 劉宸誌, 葉正良, 李俊諺, 邱春茂, 許, 薛義雄, 張廣元, 張, 林正源,...</td>\n",
       "      <td>[黃裕源, 劉宸誌, 葉正良, 李俊諺, 許, 邱春茂, 薛義雄, 張廣元, 張, 林正源,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2794</td>\n",
       "      <td>[周瑞慶, 黃子窈, 賴金鑫, 吳松麟, 簡麗珠, 黃雁宸, 林麗令, 陳國楨, 蔡尚苑, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[李金龍, 蔡豐益, 陳國楨, 陳進村]</td>\n",
       "      <td>[0.99, 0.99, 0.98, 0.99]</td>\n",
       "      <td>[李金龍, 蔡豐益, 陳進村, 陳國楨]</td>\n",
       "      <td>[李金龍, 黃子窈, 蔡尚苑, 賴金鑫, 夏子茵, 周瑞慶, 億圓富, 林麗令, 陳東豐, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1444</td>\n",
       "      <td>[黃世陽, 黃顯雄]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[黃世陽, 黃顯雄]</td>\n",
       "      <td>[0.97, 1.0]</td>\n",
       "      <td>[黃顯雄, 黃世陽]</td>\n",
       "      <td>[宣明智, 曹興誠, 黃顯雄, 黃世陽]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>547</td>\n",
       "      <td>[徐洪貴]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[徐洪貴]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[徐, 徐洪貴, 洪距]</td>\n",
       "      <td>[徐, 徐洪貴, 洪距]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1692</td>\n",
       "      <td>[簡志霖, 吳建宏, 黃國清, 黃弘毅, 洪琮鎰, 陳枻佐, 張俊宜, 陳榮元, 陳忠貴]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[張俊宜, 簡志霖, 陳忠貴, 陳榮元, 黃國清, 黃弘毅]</td>\n",
       "      <td>[0.95, 1.0, 0.94, 0.94, 0.94, 0.95]</td>\n",
       "      <td>[張俊宜, 黃弘毅, 陳榮元, 吳建宏, 洪琮鎰, 簡志霖, 陳枻佐, 周永明, 黃國清, ...</td>\n",
       "      <td>[洪琮鎰, 張俊宜, 黃弘毅, 陳枻佐, 陳榮元, 吳建宏, 簡志霖, 周永明, 黃國清, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>3477</td>\n",
       "      <td>[黃鈺蘋, 黃子愛, 顏雪藝, 呂翠峰]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[呂翠峰, 林金龍, 蕭薔, 顏雪藝, 黃鈺蘋]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[黃鈺蘋, 林金龍, 呂翠峰, 呂, 游, 蕭薔, 黃, 顏, 陳, 顏雪藝]</td>\n",
       "      <td>[黃鈺蘋, 蕭薔傳, 黃女, 林金龍, 呂翠峰, 呂, 張, 游, 柯氏, 顏各, 黃, 顏...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>712</td>\n",
       "      <td>[羅秋英, 陳斯婷]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[羅秋英, 陳建三, 陳斯婷]</td>\n",
       "      <td>[1.0, 0.94, 0.98]</td>\n",
       "      <td>[陳斯婷, 陳建三, 江男, 羅秋英]</td>\n",
       "      <td>[陳斯婷, 陳建三, 羅秋英, 張, 江男]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>4860</td>\n",
       "      <td>[陳清江]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[陳清江]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[陳清江, 金]</td>\n",
       "      <td>[陳清江, 金]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1390</td>\n",
       "      <td>[徐豪雄]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[徐豪雄]</td>\n",
       "      <td>[0.99]</td>\n",
       "      <td>[徐豪雄]</td>\n",
       "      <td>[徐豪雄]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>4162</td>\n",
       "      <td>[趙宏翰]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[柯博齡, 范家振, 謝慧中, 趙宏翰, 魏豪勇]</td>\n",
       "      <td>[0.96, 0.96, 0.97, 1.0, 0.96]</td>\n",
       "      <td>[阮, 柯博齡, 林, 范家振, 黃, 魏豪勇, 趙宏翰, 白, 謝慧中, 趙]</td>\n",
       "      <td>[阮, 林, 白, 范家振, 林浮, 魏豪勇, 趙宏翰, 黃, 趙, 謝慧中, 柯博齡]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1380</td>\n",
       "      <td>[連千毅, 鄭又仁]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[鄭又仁, 連千毅]</td>\n",
       "      <td>[鄭又仁, 連千毅]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2815</td>\n",
       "      <td>[楊善淵]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[楊善淵]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[朱啟仁, 楊善淵]</td>\n",
       "      <td>[朱啟仁, 楊善淵]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2476</td>\n",
       "      <td>[黃昱凱]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[莊琇媛]</td>\n",
       "      <td>[0.97]</td>\n",
       "      <td>[莊琇媛, 黃昱凱]</td>\n",
       "      <td>[莊琇媛, 黃昱凱]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>3508</td>\n",
       "      <td>[趙建銘, 趙玉柱, 蘇德建, 游世一]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>803</td>\n",
       "      <td>[戴家秀]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[戴家秀]</td>\n",
       "      <td>[0.97]</td>\n",
       "      <td>[戴男, 戴家秀]</td>\n",
       "      <td>[肥哥, 小戴, 劉男, 戴家秀, 劉]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>4483</td>\n",
       "      <td>[洪正義]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[洪正義]</td>\n",
       "      <td>[0.72]</td>\n",
       "      <td>[洪, 洪男, 洪正義]</td>\n",
       "      <td>[洪, 洪男, 洪正義]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>4027</td>\n",
       "      <td>[吳宗憲, 張恒嘉, 邱彰信, 徐兆峰, 祁明昕]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[吳宗憲, 張恒嘉, 徐兆峰, 邱彰信]</td>\n",
       "      <td>[1.0, 0.86, 0.89, 0.78]</td>\n",
       "      <td>[徐, 徐兆峰, 邱彰信, 張恒嘉, 祁明昕, 祁, 吳宗憲]</td>\n",
       "      <td>[徐, 徐兆峰, 邱彰信, 張恒嘉, 大衛杜夫, 祁明昕, 祁, 吳宗憲]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>38</td>\n",
       "      <td>[王桂霜, 李威儀, 藍秀琪]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[李威儀, 王桂霜, 藍秀琪]</td>\n",
       "      <td>[0.98, 0.97, 1.0]</td>\n",
       "      <td>[藍秀琪, 李, 李威儀, 王桂霜]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2106</td>\n",
       "      <td>[黃奕霖, 林佳葳, 余逸民, 葉文豪, 許鴻呈]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[余逸民, 林佳葳, 葉文豪, 許鴻呈, 黃奕霖]</td>\n",
       "      <td>[0.85, 0.86, 0.86, 0.82, 1.0]</td>\n",
       "      <td>[許, 許鴻呈, 余, 葉文豪, 林, 葉, 林佳葳, 余逸民, 黃奕霖]</td>\n",
       "      <td>[呂象吾, 許鴻呈, 黃國倫, 許, 林, 余, 葉文豪, 葉, 林佳葳, 余逸民, 黃奕霖]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2720</td>\n",
       "      <td>[王洪烈]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[王洪烈]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[王, 吳, 王洪烈]</td>\n",
       "      <td>[王, 吳, 王洪烈]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>4886</td>\n",
       "      <td>[邱世忠]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[邱世忠]</td>\n",
       "      <td>[0.99]</td>\n",
       "      <td>[邱世忠, 邱男, 張, 張男]</td>\n",
       "      <td>[邱世忠, 邱男未, 張男, 邱男, 張, 砲忠]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1209</td>\n",
       "      <td>[陳鏡如, 陳星佑]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[陳廷智, 陳星佑, 陳鏡如]</td>\n",
       "      <td>[1.0, 1.0, 1.0]</td>\n",
       "      <td>[陳星佑, 陳廷智, 陳鏡如]</td>\n",
       "      <td>[陳星佑, 陳廷智, 陳鏡如]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>4950</td>\n",
       "      <td>[紀雅玲]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[紀雅玲]</td>\n",
       "      <td>[0.96]</td>\n",
       "      <td>[林, 林女, 陳之漢, 林睿君, 紀雅玲]</td>\n",
       "      <td>[紀, 林女, 陳之漢, 林睿君, 紀雅玲, 紀女]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1515</td>\n",
       "      <td>[詹昭書]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[詹昭書]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[詹, 詹昭書, 張男]</td>\n",
       "      <td>[詹, 詹昭書, 張, 張男]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1156</td>\n",
       "      <td>[陳仕修, 徐仲榮]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[徐仲榮, 陳仕修, 黃國昌]</td>\n",
       "      <td>[0.99, 0.99, 0.85]</td>\n",
       "      <td>[徐, 陳, 蔡英文, 陳仕修, 徐仲榮, 黃國昌]</td>\n",
       "      <td>[陳, 徐, 如興, 蔡英文, 孫瑒, 陳仕修, 玖地, 興, 徐仲榮, 黃國昌]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1825</td>\n",
       "      <td>[張朝亮, 周俊誼]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[周俊誼, 張朝亮]</td>\n",
       "      <td>[0.99, 0.98]</td>\n",
       "      <td>[周俊誼, 張朝亮, 吳, 張, 周]</td>\n",
       "      <td>[周俊誼, 施, 王, 張朝亮, 高宅, 張]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>3564</td>\n",
       "      <td>[王春甡, 王柏森]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[江, 王, 范筱梵, 王柏森, 江智詮, 江男, 王春甡]</td>\n",
       "      <td>[江, 王, 范筱梵, 控告王, 王柏森, 王春甡, 江智詮, 江男]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1916</td>\n",
       "      <td>[李榮華]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[李榮華, 鄭徒]</td>\n",
       "      <td>[1.0, 0.98]</td>\n",
       "      <td>[李榮華, 李男, 李, 鄭, 鄭男, 鄭徒]</td>\n",
       "      <td>[李榮華, 李男, 鄭, 鄭男, 鄭徒刑, 李徒刑]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    news_id                                         label_name  aml_label  \\\n",
       "0      4056                                    [林霙璋, 蔡景德, 齊德清]          1   \n",
       "1      4101                          [陳志遇, 林玉華, 陳威廷, 陳富榮, 劉欣燕]          1   \n",
       "2      3076                                              [丁奕烜]          1   \n",
       "3      4685                                              [鄭聖儒]          1   \n",
       "4       855                                    [陳玟叡, 黃文鴻, 吳承霖]          1   \n",
       "5      1420                                         [余依珊, 孫凱倫]          1   \n",
       "6      3131                                         [胡原龍, 秦朝添]          1   \n",
       "7      2426                                         [陳瑞禮, 陳文南]          1   \n",
       "8       582                                              [阮文全]          1   \n",
       "9      4780                                         [鄧超鴻, 道克明]          1   \n",
       "10     3130                                              [王益洲]          1   \n",
       "11     3210                                              [鄭俊宏]          1   \n",
       "12      419                                    [陳世坤, 陳素娟, 祁興國]          1   \n",
       "13      818               [李承孺, 詹國霆, 黃清政, Alan Lim, Mynus Lee]          1   \n",
       "14     4597                                         [宋芷妍, 王安石]          1   \n",
       "15     2145                                              [張智冠]          1   \n",
       "16     4687                                              [謝淑美]          1   \n",
       "17     4802                                         [林繼蘇, 徐詩彥]          1   \n",
       "18     4518                                         [劉威甫, 張桂銘]          1   \n",
       "19      326                                              [葉添洽]          1   \n",
       "20     4310                               [江盈均, 江志堅, 許志遠, 蔡世誠]          1   \n",
       "21     2656                                              [林致成]          1   \n",
       "22      520                                              [蘇怡寧]          1   \n",
       "23     2548                                              [吳勝凱]          1   \n",
       "24     4137                                         [鍾增林, 曾國財]          1   \n",
       "25     3691                     [洪定緯, 馬怡如, 簡以珍, 林玉雀, 潘信興, 陳勇志]          1   \n",
       "26      280                                         [楊正平, 蔡思庭]          1   \n",
       "27      398                                    [林嘉凌, 林茂樹, 陳國帥]          1   \n",
       "28     3465                                              [房立勳]          1   \n",
       "29      166                                              [許正雄]          1   \n",
       "30     4230                                    [楊仕豪, 楊仕銘, 尤嵩斌]          1   \n",
       "31     1250                                         [藍力凱, 許文豪]          1   \n",
       "32     3226                                              [何壽川]          1   \n",
       "33     3077                               [黃文哲, 陳文君, 林黃財, 徐良吉]          1   \n",
       "34     3864                               [黃郁文, 翁朝正, 翁定澤, 何文安]          1   \n",
       "35     1285                                               [孔朝]          1   \n",
       "36     1534                                    [王際平, 林西田, 陳建閣]          1   \n",
       "37     3305       [吳宗憲, 林志建, 徐兆峰, 李宗原, 黃川禎, 沈珉, 邱彰信, 羅雅美, 張恒嘉]          1   \n",
       "38     2338                                         [吳承霖, 陳玟叡]          1   \n",
       "39     4724                                         [吳秋華, 廖麗櫻]          1   \n",
       "40     1771                                    [趙藤雄, 趙信清, 李克毅]          1   \n",
       "41     1842                                         [楊強蓉, 董子綺]          1   \n",
       "42      140  [吳宗憲, 張恒嘉, 邱彰信, 于堯, 黃川禎, 劉尊彰, 李宗原, 羅雅美, 沈珉, 白梓...          1   \n",
       "43     3676  [謝春發, 王博民, 歐兆賢, 張力方, 楊文虎, 王音之, 莊淑芬, 林奕如, 李智剛, ...          1   \n",
       "44     3180      [吳美惠, 葉正良, 邱春茂, 黃裕源, 林正源, 張廣元, 薛義雄, 李俊諺, 劉宸誌]          1   \n",
       "45     2794  [周瑞慶, 黃子窈, 賴金鑫, 吳松麟, 簡麗珠, 黃雁宸, 林麗令, 陳國楨, 蔡尚苑, ...          1   \n",
       "46     1444                                         [黃世陽, 黃顯雄]          1   \n",
       "47      547                                              [徐洪貴]          1   \n",
       "48     1692      [簡志霖, 吳建宏, 黃國清, 黃弘毅, 洪琮鎰, 陳枻佐, 張俊宜, 陳榮元, 陳忠貴]          1   \n",
       "49     3477                               [黃鈺蘋, 黃子愛, 顏雪藝, 呂翠峰]          1   \n",
       "50      712                                         [羅秋英, 陳斯婷]          1   \n",
       "51     4860                                              [陳清江]          1   \n",
       "52     1390                                              [徐豪雄]          1   \n",
       "53     4162                                              [趙宏翰]          1   \n",
       "54     1380                                         [連千毅, 鄭又仁]          1   \n",
       "55     2815                                              [楊善淵]          1   \n",
       "56     2476                                              [黃昱凱]          1   \n",
       "57     3508                               [趙建銘, 趙玉柱, 蘇德建, 游世一]          1   \n",
       "58      803                                              [戴家秀]          1   \n",
       "59     4483                                              [洪正義]          1   \n",
       "60     4027                          [吳宗憲, 張恒嘉, 邱彰信, 徐兆峰, 祁明昕]          1   \n",
       "61       38                                    [王桂霜, 李威儀, 藍秀琪]          1   \n",
       "62     2106                          [黃奕霖, 林佳葳, 余逸民, 葉文豪, 許鴻呈]          1   \n",
       "63     2720                                              [王洪烈]          1   \n",
       "64     4886                                              [邱世忠]          1   \n",
       "65     1209                                         [陳鏡如, 陳星佑]          1   \n",
       "66     4950                                              [紀雅玲]          1   \n",
       "67     1515                                              [詹昭書]          1   \n",
       "68     1156                                         [陳仕修, 徐仲榮]          1   \n",
       "69     1825                                         [張朝亮, 周俊誼]          1   \n",
       "70     3564                                         [王春甡, 王柏森]          1   \n",
       "71     1916                                              [李榮華]          1   \n",
       "\n",
       "    prediction                            Ner_prediction  \\\n",
       "0          1.0                                [蔡景德, 齊德清]   \n",
       "1          1.0                 [劉欣燕, 林玉華, 陳威廷, 陳富榮, 陳志遇]   \n",
       "2          1.0                                       NaN   \n",
       "3          1.0                                     [鄭聖儒]   \n",
       "4          1.0                      [吳承霖, 蔡英俊, 陳玟叡, 黃文鴻]   \n",
       "5          1.0                                     [余依珊]   \n",
       "6          1.0                      [王海濤, 秦朝添, 胡原龍, 鈕承澤]   \n",
       "7          1.0                                [陳文南, 陳瑞禮]   \n",
       "8          1.0                                     [阮文全]   \n",
       "9          1.0                           [道克明, 鄧、道, 鄧超鴻]   \n",
       "10         1.0                                     [王益洲]   \n",
       "11         1.0                                     [鄭俊宏]   \n",
       "12         1.0                           [祁興國, 陳世坤, 陳素娟]   \n",
       "13         1.0                           [李承孺, 詹國霆, 黃清政]   \n",
       "14         1.0                                       NaN   \n",
       "15         1.0                           [張智冠, 張錦榮, 王柏舜]   \n",
       "16         1.0                                     [謝淑美]   \n",
       "17         1.0                                [徐詩彥, 林繼蘇]   \n",
       "18         1.0                                     [劉威甫]   \n",
       "19         1.0                 [莊佳瑋, 葉添洽, 金裕晟, 陳信郎, 黃淑媛]   \n",
       "20         1.0                      [江志堅, 江盈均, 蔡世誠, 許志遠]   \n",
       "21         1.0                                [林致成, 陳富田]   \n",
       "22         1.0                                     [蘇怡寧]   \n",
       "23         1.0                                     [吳勝凱]   \n",
       "24         1.0                                [曾國財, 鍾增林]   \n",
       "25         1.0                           [潘信興, 簡以珍, 陳勇志]   \n",
       "26         1.0                                [楊正平, 蔡思庭]   \n",
       "27         1.0                           [林嘉凌, 林茂樹, 陳國帥]   \n",
       "28         1.0                                     [房立勳]   \n",
       "29         1.0                                [楊國聰, 許正雄]   \n",
       "30         1.0                           [尤嵩斌, 楊仕豪, 楊仕銘]   \n",
       "31         1.0                      [藍力凱, 許文豪, 陳美君, 陳靜慧]   \n",
       "32         1.0                                     [何壽川]   \n",
       "33         1.0                      [徐良吉, 林黃財, 陳文君, 黃文哲]   \n",
       "34         1.0                 [何文安, 尤泰盛, 翁定澤, 翁朝正, 黃郁文]   \n",
       "35         1.0                                      [孔朝]   \n",
       "36         1.0                           [林西田, 王際平, 陳建閣]   \n",
       "37         1.0                           [徐兆峰, 李宗原, 林志建]   \n",
       "38         1.0                                [吳承霖, 陳玟叡]   \n",
       "39         1.0                                [吳秋華, 廖麗櫻]   \n",
       "40         1.0                           [李克毅, 趙信清, 趙藤雄]   \n",
       "41         1.0                           [徐乃麟, 楊強蓉, 董子綺]   \n",
       "42         1.0   [于堯, 劉尊彰, 吳宗憲, 張恒嘉, 李宗原, 羅雅美, 邱彰信, 黃川禎]   \n",
       "43         1.0                      [楊宇晨, 楊文虎, 王音之, 黃呈熹]   \n",
       "44         1.0  [劉宸誌, 吳美惠, 張廣元, 李俊諺, 葉正良, 薛義雄, 邱春茂, 黃裕源]   \n",
       "45         1.0                      [李金龍, 蔡豐益, 陳國楨, 陳進村]   \n",
       "46         1.0                                [黃世陽, 黃顯雄]   \n",
       "47         1.0                                     [徐洪貴]   \n",
       "48         1.0            [張俊宜, 簡志霖, 陳忠貴, 陳榮元, 黃國清, 黃弘毅]   \n",
       "49         1.0                  [呂翠峰, 林金龍, 蕭薔, 顏雪藝, 黃鈺蘋]   \n",
       "50         1.0                           [羅秋英, 陳建三, 陳斯婷]   \n",
       "51         1.0                                     [陳清江]   \n",
       "52         1.0                                     [徐豪雄]   \n",
       "53         1.0                 [柯博齡, 范家振, 謝慧中, 趙宏翰, 魏豪勇]   \n",
       "54         1.0                                       NaN   \n",
       "55         1.0                                     [楊善淵]   \n",
       "56         1.0                                     [莊琇媛]   \n",
       "57         0.0                                       NaN   \n",
       "58         1.0                                     [戴家秀]   \n",
       "59         1.0                                     [洪正義]   \n",
       "60         1.0                      [吳宗憲, 張恒嘉, 徐兆峰, 邱彰信]   \n",
       "61         1.0                           [李威儀, 王桂霜, 藍秀琪]   \n",
       "62         1.0                 [余逸民, 林佳葳, 葉文豪, 許鴻呈, 黃奕霖]   \n",
       "63         1.0                                     [王洪烈]   \n",
       "64         1.0                                     [邱世忠]   \n",
       "65         1.0                           [陳廷智, 陳星佑, 陳鏡如]   \n",
       "66         1.0                                     [紀雅玲]   \n",
       "67         1.0                                     [詹昭書]   \n",
       "68         1.0                           [徐仲榮, 陳仕修, 黃國昌]   \n",
       "69         1.0                                [周俊誼, 張朝亮]   \n",
       "70         1.0                                       NaN   \n",
       "71         1.0                                 [李榮華, 鄭徒]   \n",
       "\n",
       "                                       name_score  \\\n",
       "0                                    [0.98, 0.97]   \n",
       "1                      [0.9, 1.0, 1.0, 0.99, 1.0]   \n",
       "2                                             NaN   \n",
       "3                                           [1.0]   \n",
       "4                           [1.0, 0.87, 1.0, 1.0]   \n",
       "5                                          [0.74]   \n",
       "6                          [0.99, 1.0, 1.0, 0.98]   \n",
       "7                                      [1.0, 1.0]   \n",
       "8                                          [0.99]   \n",
       "9                              [0.89, 0.99, 0.96]   \n",
       "10                                          [1.0]   \n",
       "11                                         [0.99]   \n",
       "12                                [1.0, 1.0, 1.0]   \n",
       "13                                [1.0, 1.0, 1.0]   \n",
       "14                                            NaN   \n",
       "15                               [1.0, 0.98, 1.0]   \n",
       "16                                          [1.0]   \n",
       "17                                     [1.0, 1.0]   \n",
       "18                                         [0.87]   \n",
       "19                   [0.95, 1.0, 1.0, 0.98, 0.99]   \n",
       "20                       [0.84, 0.84, 0.99, 0.99]   \n",
       "21                                     [1.0, 1.0]   \n",
       "22                                         [0.94]   \n",
       "23                                         [0.99]   \n",
       "24                                     [1.0, 1.0]   \n",
       "25                               [0.98, 1.0, 1.0]   \n",
       "26                                     [1.0, 1.0]   \n",
       "27                              [0.98, 0.99, 1.0]   \n",
       "28                                          [1.0]   \n",
       "29                                   [0.99, 0.99]   \n",
       "30                                [1.0, 1.0, 1.0]   \n",
       "31                       [0.98, 0.99, 0.95, 0.99]   \n",
       "32                                         [0.94]   \n",
       "33                        [0.99, 0.99, 0.99, 1.0]   \n",
       "34                      [1.0, 1.0, 1.0, 1.0, 1.0]   \n",
       "35                                         [0.99]   \n",
       "36                              [0.91, 0.93, 1.0]   \n",
       "37                                [1.0, 1.0, 1.0]   \n",
       "38                                     [1.0, 1.0]   \n",
       "39                                    [1.0, 0.98]   \n",
       "40                                [1.0, 1.0, 1.0]   \n",
       "41                                [1.0, 1.0, 1.0]   \n",
       "42   [0.99, 1.0, 0.99, 0.99, 1.0, 0.95, 1.0, 1.0]   \n",
       "43                         [0.99, 1.0, 0.99, 1.0]   \n",
       "44  [1.0, 0.99, 1.0, 0.98, 0.77, 0.79, 0.83, 1.0]   \n",
       "45                       [0.99, 0.99, 0.98, 0.99]   \n",
       "46                                    [0.97, 1.0]   \n",
       "47                                          [1.0]   \n",
       "48            [0.95, 1.0, 0.94, 0.94, 0.94, 0.95]   \n",
       "49                      [1.0, 1.0, 1.0, 1.0, 1.0]   \n",
       "50                              [1.0, 0.94, 0.98]   \n",
       "51                                          [1.0]   \n",
       "52                                         [0.99]   \n",
       "53                  [0.96, 0.96, 0.97, 1.0, 0.96]   \n",
       "54                                            NaN   \n",
       "55                                          [1.0]   \n",
       "56                                         [0.97]   \n",
       "57                                            NaN   \n",
       "58                                         [0.97]   \n",
       "59                                         [0.72]   \n",
       "60                        [1.0, 0.86, 0.89, 0.78]   \n",
       "61                              [0.98, 0.97, 1.0]   \n",
       "62                  [0.85, 0.86, 0.86, 0.82, 1.0]   \n",
       "63                                          [1.0]   \n",
       "64                                         [0.99]   \n",
       "65                                [1.0, 1.0, 1.0]   \n",
       "66                                         [0.96]   \n",
       "67                                          [1.0]   \n",
       "68                             [0.99, 0.99, 0.85]   \n",
       "69                                   [0.99, 0.98]   \n",
       "70                                            NaN   \n",
       "71                                    [1.0, 0.98]   \n",
       "\n",
       "                                              Ner_raw  \\\n",
       "0              [蔡, 蔡員, 林員, 齊德清, 林, 蔡景德, 齊員, 齊從輕, 林霙璋]   \n",
       "1                           [陳志遇, 林玉華, 陳富榮, 陳威廷, 劉欣燕]   \n",
       "2                                [李, 林女, 丁男, 丁奕烜, 李女]   \n",
       "3                                 [蔡, 鄭聖儒, 徐, 徐女, 鄭男]   \n",
       "4                  [吳男, 孫, 吳, 吳承霖, 黃男, 蔡英俊, 陳玟叡, 黃文鴻]   \n",
       "5                                    [余依珊, 余, 孫凱倫, 林]   \n",
       "6                             [秦朝添, 胡原龍, 胡, 王海濤, 鈕承澤]   \n",
       "7                                       [陳瑞禮, 陳, 陳文南]   \n",
       "8                                         [阮文全, 阮, 鄭]   \n",
       "9                                 [道克明, 鄧、道, 鄧超鴻, 鄧男]   \n",
       "10                                     [王, 李, 秦, 王益洲]   \n",
       "11                         [鄭, 鄭俊宏, 鄭男, 塗, 羅, 塗女, 羅男]   \n",
       "12                                    [祁興國, 陳素娟, 陳世坤]   \n",
       "13                                    [詹國霆, 李承孺, 黃清政]   \n",
       "14                                             [王, 宋]   \n",
       "15                               [王燕美, 王柏舜, 張智冠, 張錦榮]   \n",
       "16                                    [謝女, 王, 謝淑美, 謝]   \n",
       "17                              [徐, 徐女, 林繼蘇, 林男, 徐詩彥]   \n",
       "18                                         [張桂銘, 劉威甫]   \n",
       "19                 [黃淑媛, 莊佳瑋, 鄭, 金裕晟, 陳信郎, 杜, 陳, 葉添洽]   \n",
       "20                         [江, 江志堅, 蔡世誠, 鍾, 許志遠, 江盈均]   \n",
       "21                                [林, 王, 林致成, 陳富田, 羅]   \n",
       "22                                              [蘇怡寧]   \n",
       "23                                [李男, 鄭, 吳勝凱, 吳, 鄭婦]   \n",
       "24                                      [鍾增林, 黃, 曾國財]   \n",
       "25                    [潘信興, 陳勇志, 伯納德‧馬多夫, 勞勃狄尼諾, 簡以珍]   \n",
       "26                                      [楊, 楊正平, 蔡思庭]   \n",
       "27                                    [林嘉凌, 林茂樹, 陳國帥]   \n",
       "28                                              [房立勳]   \n",
       "29                          [楊, 許, 楊國聰, 林, 吳, 許正雄, 劉]   \n",
       "30                                 [楊, 楊仕銘, 楊仕豪, 尤嵩斌]   \n",
       "31          [蘇, 李, 胡, 許文豪, 王, 藍, 陳美君, 藍力凱, 陳靜慧, 黃, 陳]   \n",
       "32                                         [何壽川, 莊琇媛]   \n",
       "33                           [陳文君, 黃文哲, 徐良吉, 黃男, 林黃財]   \n",
       "34                          [黃郁文, 尤泰盛, 翁定澤, 何文安, 翁朝正]   \n",
       "35                                        [孔朝, 盧, 盧男]   \n",
       "36                                    [林西田, 陳建閣, 王際平]   \n",
       "37       [徐兆峰, 沈珉, 邱彰信, 林志建, 黃川禎, 羅雅美, 張恒嘉, 李宗原, 吳宗憲]   \n",
       "38                                      [吳, 吳承霖, 陳玟叡]   \n",
       "39                                   [吳秋華, 吳, 廖麗櫻, 廖]   \n",
       "40                                    [趙信清, 李克毅, 趙藤雄]   \n",
       "41                  [楊, 董, 許, 楊強蓉, 徐乃麟, 姚, 黃, 董子綺, 何]   \n",
       "42  [劉尊彰, 于堯, 邱彰信, 蔡英文, 黃川禎, 吳, 羅雅美, 張, 張恒嘉, 李宗原, ...   \n",
       "43                         [楊, 黃呈熹, 楊文虎, 楊宇晨, 王音之, 黃]   \n",
       "44  [黃裕源, 劉宸誌, 葉正良, 李俊諺, 邱春茂, 許, 薛義雄, 張廣元, 張, 林正源,...   \n",
       "45                               [李金龍, 蔡豐益, 陳進村, 陳國楨]   \n",
       "46                                         [黃顯雄, 黃世陽]   \n",
       "47                                       [徐, 徐洪貴, 洪距]   \n",
       "48  [張俊宜, 黃弘毅, 陳榮元, 吳建宏, 洪琮鎰, 簡志霖, 陳枻佐, 周永明, 黃國清, ...   \n",
       "49            [黃鈺蘋, 林金龍, 呂翠峰, 呂, 游, 蕭薔, 黃, 顏, 陳, 顏雪藝]   \n",
       "50                                [陳斯婷, 陳建三, 江男, 羅秋英]   \n",
       "51                                           [陳清江, 金]   \n",
       "52                                              [徐豪雄]   \n",
       "53           [阮, 柯博齡, 林, 范家振, 黃, 魏豪勇, 趙宏翰, 白, 謝慧中, 趙]   \n",
       "54                                         [鄭又仁, 連千毅]   \n",
       "55                                         [朱啟仁, 楊善淵]   \n",
       "56                                         [莊琇媛, 黃昱凱]   \n",
       "57                                                NaN   \n",
       "58                                          [戴男, 戴家秀]   \n",
       "59                                       [洪, 洪男, 洪正義]   \n",
       "60                    [徐, 徐兆峰, 邱彰信, 張恒嘉, 祁明昕, 祁, 吳宗憲]   \n",
       "61                                 [藍秀琪, 李, 李威儀, 王桂霜]   \n",
       "62              [許, 許鴻呈, 余, 葉文豪, 林, 葉, 林佳葳, 余逸民, 黃奕霖]   \n",
       "63                                        [王, 吳, 王洪烈]   \n",
       "64                                   [邱世忠, 邱男, 張, 張男]   \n",
       "65                                    [陳星佑, 陳廷智, 陳鏡如]   \n",
       "66                             [林, 林女, 陳之漢, 林睿君, 紀雅玲]   \n",
       "67                                       [詹, 詹昭書, 張男]   \n",
       "68                         [徐, 陳, 蔡英文, 陳仕修, 徐仲榮, 黃國昌]   \n",
       "69                                [周俊誼, 張朝亮, 吳, 張, 周]   \n",
       "70                     [江, 王, 范筱梵, 王柏森, 江智詮, 江男, 王春甡]   \n",
       "71                            [李榮華, 李男, 李, 鄭, 鄭男, 鄭徒]   \n",
       "\n",
       "                                             ckip_raw  \n",
       "0    [蔡, 蔡員, 齊德清, 除齊, 林, 齊員處, 齊員, 蔡景德, 林員處, 蔡員處, 林霙璋]  \n",
       "1                           [陳志遇, 林玉華, 陳富榮, 陳威廷, 劉欣燕]  \n",
       "2                                         [李, 丁奕烜, 林]  \n",
       "3                              [蔡, 徐, 鄭聖儒, 鄭, 徐女, 鄭男]  \n",
       "4       [吳男, 黃, 孫, 吳承霖, 黃男, 吳, 嘉檢, 蔡英俊, 台北, 陳玟叡, 黃文鴻]  \n",
       "5                                [孫男, 林, 余, 余依珊, 孫凱倫]  \n",
       "6                [秦朝添, 胡原龍, 胡, 王海濤, 胡稱, 國磐, 胡受訪, 鈕承澤]  \n",
       "7                                       [陳瑞禮, 陳, 陳文南]  \n",
       "8                                         [阮, 阮文全, 鄭]  \n",
       "9                                   [鄧, 道克明, 鄧男, 鄧超鴻]  \n",
       "10                                  [李, 任, 王, 秦, 王益洲]  \n",
       "11                         [鄭, 鄭俊宏, 鄭男, 塗, 羅, 塗女, 羅男]  \n",
       "12                                 [祁興國, 陳素娟, 陳世坤, 江]  \n",
       "13                                    [詹國霆, 李承孺, 黃清政]  \n",
       "14                                 [葉男, 王, 葉, 王明知, 宋]  \n",
       "15                          [陳榮聰, 王燕美, 王柏舜, 張錦榮, 張智冠]  \n",
       "16                                        [王, 謝淑美, 謝]  \n",
       "17                              [徐, 徐女, 林繼蘇, 林男, 徐詩彥]  \n",
       "18                                 [周, 張桂銘, 劉威甫, 珍菌堂]  \n",
       "19                 [莊佳瑋, 黃淑媛, 鄭, 金裕晟, 陳信郎, 杜, 陳, 葉添洽]  \n",
       "20               [江志堅, 江男庭, 蔡世誠, 鍾, 許志遠, 江男, 鍾婦, 江盈均]  \n",
       "21                            [王觀, 林, 王, 林致成, 陳富田, 羅]  \n",
       "22                                          [禾馨, 蘇怡寧]  \n",
       "23                           [李男, 鄭, 吳勝凱, 杰樂米, 鄭婦, 筱]  \n",
       "24                                      [鍾增林, 黃, 曾國財]  \n",
       "25      [潘信興, 陳勇志, 潘男, 陳, 洪定緯, 簡明, 簡以珍, 馬怡如, 三鑫, 林玉雀]  \n",
       "26                                      [楊, 楊正平, 蔡思庭]  \n",
       "27                 [楊, 紀, 林嘉凌, 陳國帥, 薔薔, 林茂樹, 廖, 陳, 宋]  \n",
       "28                                              [房立勳]  \n",
       "29                  [楊, 許, 楊國聰, 許處, 林, 許和, 吳, 許正雄, 劉]  \n",
       "30                                 [楊, 楊仕銘, 楊仕豪, 尤嵩斌]  \n",
       "31             [蘇, 李, 胡, 許文豪, 王, 陳美君, 藍力凱, 陳靜慧, 黃, 陳]  \n",
       "32                                         [莊琇媛, 何壽川]  \n",
       "33                           [陳文君, 黃文哲, 徐良吉, 黃男, 林黃財]  \n",
       "34                          [黃郁文, 尤泰盛, 翁定澤, 何文安, 翁朝正]  \n",
       "35                                        [孔朝, 盧, 盧男]  \n",
       "36                                [瑞傑, 陳建閣, 王際平, 林西田]  \n",
       "37       [徐兆峰, 沈珉, 邱彰信, 林志建, 羅雅美, 黃川禎, 張恒嘉, 李宗原, 吳宗憲]  \n",
       "38                                  [陳玟叡, 吳, 吳承霖, 吳再]  \n",
       "39                                  [吳秋華, 吳, 廖麗櫻, 廖女]  \n",
       "40                                    [趙信清, 李克毅, 趙藤雄]  \n",
       "41  [楊, 董向楊, 董, 董說楊, 楊強蓉, 徐乃麟, 許, 姚, 楊租, 牛哥, 董才, 楊...  \n",
       "42  [沈珉, 劉尊彰, 田佳宜, 于堯, 邱彰信, 白梓佑, 蔡英文, 黃川禎, 吳, 羅雅美,...  \n",
       "43  [楊, 謝明瑋, 歐兆賢, 林奕如, 黃呈熹, 邱毅, 謝春發, 楊文虎, 王博民, 楊宇晨...  \n",
       "44  [黃裕源, 劉宸誌, 葉正良, 李俊諺, 許, 邱春茂, 薛義雄, 張廣元, 張, 林正源,...  \n",
       "45  [李金龍, 黃子窈, 蔡尚苑, 賴金鑫, 夏子茵, 周瑞慶, 億圓富, 林麗令, 陳東豐, ...  \n",
       "46                               [宣明智, 曹興誠, 黃顯雄, 黃世陽]  \n",
       "47                                       [徐, 徐洪貴, 洪距]  \n",
       "48  [洪琮鎰, 張俊宜, 黃弘毅, 陳枻佐, 陳榮元, 吳建宏, 簡志霖, 周永明, 黃國清, ...  \n",
       "49  [黃鈺蘋, 蕭薔傳, 黃女, 林金龍, 呂翠峰, 呂, 張, 游, 柯氏, 顏各, 黃, 顏...  \n",
       "50                             [陳斯婷, 陳建三, 羅秋英, 張, 江男]  \n",
       "51                                           [陳清江, 金]  \n",
       "52                                              [徐豪雄]  \n",
       "53       [阮, 林, 白, 范家振, 林浮, 魏豪勇, 趙宏翰, 黃, 趙, 謝慧中, 柯博齡]  \n",
       "54                                         [鄭又仁, 連千毅]  \n",
       "55                                         [朱啟仁, 楊善淵]  \n",
       "56                                         [莊琇媛, 黃昱凱]  \n",
       "57                                                NaN  \n",
       "58                               [肥哥, 小戴, 劉男, 戴家秀, 劉]  \n",
       "59                                       [洪, 洪男, 洪正義]  \n",
       "60              [徐, 徐兆峰, 邱彰信, 張恒嘉, 大衛杜夫, 祁明昕, 祁, 吳宗憲]  \n",
       "61                                                NaN  \n",
       "62    [呂象吾, 許鴻呈, 黃國倫, 許, 林, 余, 葉文豪, 葉, 林佳葳, 余逸民, 黃奕霖]  \n",
       "63                                        [王, 吳, 王洪烈]  \n",
       "64                          [邱世忠, 邱男未, 張男, 邱男, 張, 砲忠]  \n",
       "65                                    [陳星佑, 陳廷智, 陳鏡如]  \n",
       "66                         [紀, 林女, 陳之漢, 林睿君, 紀雅玲, 紀女]  \n",
       "67                                    [詹, 詹昭書, 張, 張男]  \n",
       "68          [陳, 徐, 如興, 蔡英文, 孫瑒, 陳仕修, 玖地, 興, 徐仲榮, 黃國昌]  \n",
       "69                            [周俊誼, 施, 王, 張朝亮, 高宅, 張]  \n",
       "70                [江, 王, 范筱梵, 控告王, 王柏森, 王春甡, 江智詮, 江男]  \n",
       "71                         [李榮華, 李男, 鄭, 鄭男, 鄭徒刑, 李徒刑]  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
