{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ckiptagger import data_utils, construct_dictionary, WS, POS, NER\n",
    "import re\n",
    "data = pd.read_csv(r'C:\\Users\\Jasonhsu\\Desktop\\esun\\0611\\content_df_0612.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_id</th>\n",
       "      <th>url</th>\n",
       "      <th>context</th>\n",
       "      <th>name</th>\n",
       "      <th>raw_content</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://news.cnyes.com/news/id/4352432</td>\n",
       "      <td>0理財基金量化交易追求絕對報酬有效對抗牛熊市鉅亨網記者鄭心芸2019/07/05 22:35...</td>\n",
       "      <td>[]</td>\n",
       "      <td>熱搜：熱門行情最近搜尋基金老司機近年來投資市場波動越來越明顯，追求低波動、絕對報酬的量化交易...</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://udn.com/news/story/120775/4112519</td>\n",
       "      <td>10月13日晚間發生Uber Eats黃姓外送人員職災死亡案件 ### 省略內文 ### 北...</td>\n",
       "      <td>[]</td>\n",
       "      <td>10月13日晚間發生Uber Eats黃姓外送人員職災死亡案件，北市府勞動局認定業者未依職業...</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://www.mirrormedia.mg/story/20191008soc011/</td>\n",
       "      <td>2019.10.08 01:53【法拍有詭4】飯店遭管委會斷水斷電員工怒吼：生計何去何從？文...</td>\n",
       "      <td>[]</td>\n",
       "      <td>\\n      全部類別\\n    \\n      全部類別\\n    【法拍有詭1】3個月...</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://www.chinatimes.com/realtimenews/201909...</td>\n",
       "      <td>58歲林姓男子昨凌晨與朋友聚餐結束後 ### 省略內文 ### 而地點就距離林家僅30公尺。...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>404NotFound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>http://domestic.judicial.gov.tw/abbs/wkw/WHD9H...</td>\n",
       "      <td>例稿名稱：臺灣屏東地方法院公示催告公告發文日期：中華民國108年9月20日發文字號：屏院進家...</td>\n",
       "      <td>[]</td>\n",
       "      <td>例稿名稱：臺灣屏東地方法院公示催告公告\\n發文日期：中華民國108年9月20日\\n發文字號：...</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   news_id                                                url  \\\n",
       "0        1             https://news.cnyes.com/news/id/4352432   \n",
       "1        2          https://udn.com/news/story/120775/4112519   \n",
       "2        3   https://www.mirrormedia.mg/story/20191008soc011/   \n",
       "3        4  https://www.chinatimes.com/realtimenews/201909...   \n",
       "4        5  http://domestic.judicial.gov.tw/abbs/wkw/WHD9H...   \n",
       "\n",
       "                                             context name  \\\n",
       "0  0理財基金量化交易追求絕對報酬有效對抗牛熊市鉅亨網記者鄭心芸2019/07/05 22:35...   []   \n",
       "1  10月13日晚間發生Uber Eats黃姓外送人員職災死亡案件 ### 省略內文 ### 北...   []   \n",
       "2  2019.10.08 01:53【法拍有詭4】飯店遭管委會斷水斷電員工怒吼：生計何去何從？文...   []   \n",
       "3  58歲林姓男子昨凌晨與朋友聚餐結束後 ### 省略內文 ### 而地點就距離林家僅30公尺。...   []   \n",
       "4  例稿名稱：臺灣屏東地方法院公示催告公告發文日期：中華民國108年9月20日發文字號：屏院進家...   []   \n",
       "\n",
       "                                         raw_content       status  \n",
       "0  熱搜：熱門行情最近搜尋基金老司機近年來投資市場波動越來越明顯，追求低波動、絕對報酬的量化交易...           ok  \n",
       "1  10月13日晚間發生Uber Eats黃姓外送人員職災死亡案件，北市府勞動局認定業者未依職業...           ok  \n",
       "2  \\n      全部類別\\n    \\n      全部類別\\n    【法拍有詭1】3個月...           ok  \n",
       "3                                                NaN  404NotFound  \n",
       "4  例稿名稱：臺灣屏東地方法院公示催告公告\\n發文日期：中華民國108年9月20日\\n發文字號：...           ok  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[data[\"status\"]==\"ok\"].reset_index().drop([\"url\",\"context\",\"status\",\"index\"],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['aml_label'] = data['name'].apply(lambda x: 0 if x == '[]' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['raw_content']=data['raw_content'].apply(lambda x: max(x.split('    '), key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv('xxxxx.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version :  1.15.0\n",
      "tensorflow_hub version :  0.8.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from datetime import datetime\n",
    "import os\n",
    "print(\"tensorflow version : \", tf.__version__)\n",
    "print(\"tensorflow_hub version : \", hub.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization\n",
    "from bert import modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = r'C:\\Users\\Jasonhsu\\Desktop\\esun\\bert_classfication2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val =  train_test_split(data, test_size = 0.5, random_state = 2020)\n",
    "train.to_csv('train.csv',index=False)\n",
    "val.to_csv('val.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2249\n",
      "1     178\n",
      "Name: aml_label, dtype: int64\n",
      "0    2275\n",
      "1     153\n",
      "Name: aml_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train['aml_label'].value_counts())\n",
    "print(val['aml_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_COLUMN = 'raw_content'\n",
    "LABEL_COLUMN = 'aml_label'\n",
    "label_list = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid= None,\n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "val_InputExamples = val.apply(lambda x: bert.run_classifier.InputExample(guid= None, \n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_chinese_L-12_H-768_A-12/1\"\n",
    "\n",
    "def create_tokenizer_from_hub_module():\n",
    "\n",
    "    with tf.Graph().as_default():\n",
    "        bert_module = hub.Module(BERT_MODEL_HUB)\n",
    "        tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "        with tf.Session() as sess:\n",
    "            vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],tokenization_info[\"do_lower_case\"]])\n",
    "      \n",
    "    return bert.tokenization.FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "tokenizer = create_tokenizer_from_hub_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = 256\n",
    "#轉換token為bert輸入\n",
    "train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "\n",
    "val_features = bert.run_classifier.convert_examples_to_features(val_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
    "                 num_labels):\n",
    "  \n",
    "    bert_module = hub.Module(BERT_MODEL_HUB,trainable=True)\n",
    "    bert_inputs = dict(input_ids=input_ids,input_mask=input_mask,segment_ids=segment_ids)\n",
    "    bert_outputs = bert_module(inputs=bert_inputs,signature=\"tokens\",as_dict=True)\n",
    "\n",
    "    output_layer = bert_outputs[\"pooled_output\"]\n",
    "\n",
    "    hidden_size = output_layer.shape[-1].value\n",
    "\n",
    "    output_weights = tf.get_variable(\"output_weights\", [num_labels, hidden_size],initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "    output_bias = tf.get_variable(\"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "\n",
    "    with tf.variable_scope(\"loss\"):\n",
    "\n",
    "        output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
    "\n",
    "        logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
    "        logits = tf.nn.bias_add(logits, output_bias)\n",
    "        log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "\n",
    "        one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "\n",
    "        predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
    "\n",
    "    if is_predicting:\n",
    "        return (predicted_labels, log_probs)\n",
    "\n",
    "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "    loss = tf.reduce_mean(per_example_loss)\n",
    "    return (loss, predicted_labels, log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_builder(num_labels, learning_rate, num_train_steps,num_warmup_steps):\n",
    "    def model_fn(features, labels, mode, params):\n",
    "\n",
    "        input_ids = features[\"input_ids\"]\n",
    "        input_mask = features[\"input_mask\"]\n",
    "        segment_ids = features[\"segment_ids\"]\n",
    "        label_ids = features[\"label_ids\"]\n",
    "\n",
    "        is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
    "    \n",
    "        if not is_predicting:\n",
    "            (loss, predicted_labels, log_probs) = create_model(is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "            train_op = bert.optimization.create_optimizer(loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
    "\n",
    "            def metric_fn(label_ids, predicted_labels):\n",
    "                accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
    "                true_pos = tf.metrics.true_positives(label_ids,predicted_labels)\n",
    "                true_neg = tf.metrics.true_negatives(label_ids,predicted_labels)   \n",
    "                false_pos = tf.metrics.false_positives(label_ids,predicted_labels)  \n",
    "                false_neg = tf.metrics.false_negatives(label_ids,predicted_labels)\n",
    "        \n",
    "                return {\n",
    "                    \"eval_accuracy\": accuracy,\n",
    "                    \"true_positives\": true_pos,\n",
    "                    \"true_negatives\": true_neg,\n",
    "                    \"false_positives\": false_pos,\n",
    "                    \"false_negatives\": false_neg\n",
    "                    }\n",
    "\n",
    "            eval_metrics = metric_fn(label_ids, predicted_labels)\n",
    "\n",
    "            if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "                return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                  loss=loss,\n",
    "                  train_op=train_op)\n",
    "            else:\n",
    "                return tf.estimator.EstimatorSpec(mode=mode,loss=loss,eval_metric_ops=eval_metrics)\n",
    "        else:\n",
    "            (predicted_labels, log_probs) = create_model(is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "            predictions = {\n",
    "            'probabilities': log_probs,\n",
    "            'labels': predicted_labels\n",
    "            }\n",
    "            return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "    return model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_TRAIN_EPOCHS = 5.0\n",
    "# Warmup is a period of time where the learning rate is small and gradually increases--usually helps training.\n",
    "WARMUP_PROPORTION = 0.1\n",
    "# Model configs\n",
    "SAVE_CHECKPOINTS_STEPS = 300\n",
    "SAVE_SUMMARY_STEPS = 100\n",
    "\n",
    "# Compute train and warmup steps from batch size\n",
    "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
    "\n",
    "# Specify output directory and number of checkpoint steps to save\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=OUTPUT_DIR,\n",
    "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
    "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n",
    "\n",
    "# Specify output directory and number of checkpoint steps to save\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=OUTPUT_DIR,\n",
    "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
    "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fn = model_fn_builder(\n",
    "  num_labels=len(label_list),\n",
    "  learning_rate=LEARNING_RATE,\n",
    "  num_train_steps=num_train_steps,\n",
    "  num_warmup_steps=num_warmup_steps)\n",
    "\n",
    "estimator = tf.estimator.Estimator(\n",
    "  model_fn=model_fn,\n",
    "  config=run_config,\n",
    "  params={\"batch_size\": BATCH_SIZE})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_fn = bert.run_classifier.input_fn_builder(\n",
    "    features=train_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=True,\n",
    "    drop_remainder=False)\n",
    "\n",
    "val_input_fn = run_classifier.input_fn_builder(\n",
    "    features=val_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=False,\n",
    "    drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Training!\n",
      "Training took time  0:00:00.006755\n"
     ]
    }
   ],
   "source": [
    "print(f'Beginning Training!')\n",
    "current_time = datetime.now()\n",
    "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "print(\"Training took time \", datetime.now() - current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jasonhsu\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_accuracy': 0.99011534,\n",
       " 'false_negatives': 20.0,\n",
       " 'false_positives': 4.0,\n",
       " 'loss': 0.061410517,\n",
       " 'true_negatives': 2271.0,\n",
       " 'true_positives': 133.0,\n",
       " 'global_step': 1516}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.evaluate(input_fn=val_input_fn, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPrediction(in_sentences):\n",
    "    labels = ['non_aml', 'aml']\n",
    "    input_examples = [run_classifier.InputExample(guid=\"\", text_a = x, text_b = None, label = 0) for x in in_sentences] \n",
    "    input_features = run_classifier.convert_examples_to_features(input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "    predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n",
    "    predictions = estimator.predict(predict_input_fn)\n",
    "    return [(sentence, labels[prediction['labels']]) for sentence, prediction in zip(in_sentences, predictions)]\n",
    "#   return [(sentence, prediction['probabilities'],prediction['labels'], labels[prediction['labels']]) for sentence, prediction in zip(in_sentences, predictions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentence(sentence):\n",
    "    split_data=[x for x in re.split(',|。|，',sentence) if x]\n",
    "    sentence_3=[]\n",
    "    seq=''\n",
    "    for i in range(0,len(split_data)-1,3):\n",
    "        try:\n",
    "            sentence_3.append(seq.join((split_data[i],',',split_data[i+1],',',split_data[i+2])))\n",
    "        except:\n",
    "            try:\n",
    "                sentence_3.append(seq.join((split_data[i],',',split_data[i+1])))\n",
    "            except:\n",
    "                sentence_3.append(split_data[i])\n",
    "    return sentence_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['split_sentence'] = data['raw_content'].apply(lambda x: split_sentence(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = WS(\"./data\")\n",
    "pos = POS(\"./data\")\n",
    "ner = NER(\"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_name_list(into_list):\n",
    "    name_list=[]\n",
    "    for i in into_list:\n",
    "        if i[2]=='PERSON':\n",
    "            name_list.append(i[3])\n",
    "    return name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_sentence_list = ner(ws(data['split_sentence'][0]), pos(ws(data['split_sentence'][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['張堯勇'],\n",
       " [],\n",
       " [],\n",
       " ['詹姆斯 · 西蒙斯 ', 'James Simons'],\n",
       " ['索羅斯', '巴菲特'],\n",
       " [],\n",
       " ['張堯勇'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['張堯勇'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['張堯勇'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['8 兆', '張堯勇'],\n",
       " []]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x:create_name_list(x),entity_sentence_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['get_name']=data['split_sentence'].apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'10月13日晚間發生Uber Eats黃姓外送人員職災死亡案件，北市府勞動局認定業者未依職業安全衛生法第37條第2項第1款規定於8小時內向勞動檢查機構通報，開罰Uber Eats 30萬元。\n",
      "\r\n",
      "台北市勞動局表示，經勞動檢查發現，Uber Eats在台灣有稅籍登記（境外電商登記），但無公司登記，透過委任或服務合作備忘錄方式，分別與香港商比錫茲有限公司、易得汽車貨運股份有限公司簽訂合作契約，易得公司再與外送員以電腦平台方式簽訂合約，而合約內容卻由Uber Eats提供，且外送員之工資亦由Uber Eats直接支付，故勞動局認定Uber Eats為外送員之實質雇主。\n",
      "\r\n",
      "北市勞動局職安科科長康水順表示，職安衛部份已完成檢查，經訪談筆錄及取得的文件認定該名罹災勞工與Uber Eats具有僱傭關係，故依職業安全衛生法第37條第2項第1款，雇主應於8小時內通報，但至今無收到任何通報記錄；另外送員於發生職災死亡後，Uber Eats知悉事故的發生卻未通報，屬明知法令卻仍違法。\n",
      "\r\n",
      "北市勞動局長賴香伶表示，由於平台業者標榜食物外送之快捷性，卻罔顧外送員行車安全，更以送達時間計算外送員工作獎金，致外送員為達平台業者規定，執行外送業務時於道路上高速行駛及穿梭於車陣，徒增行車事故風險。勞動局已事先向業者宣導法令，考量Uber Eats違法行為嚴重影響公共秩序，受責難程度高，依行政罰法、職業安全衛生法裁處罰鍰30萬元。\n",
      "\r\n",
      "勞動局職安科表示，今日先針對職災通報部分裁處作成決議，後續業者違反勞基法的部分，將根據違法部分另行開罰。除針Uber Eats黃姓外送人員職災死亡卻未依法通報案件開罰業者30萬元，北市政府今日下午也跨局處召開「外送人員保障專案會議」。圖／台北市勞動局提供\n",
      "                    外送員車禍又一樁！Uber Eats林姓外送員與柯姓女駕駛發生碰撞，林男身體擦傷，送醫後無礙。近日外送平台崛起，路上可見...                  \n",
      "                    新北市府交通局今天表示，將規劃機車卸貨停車區域，並開放外送員臨時停靠家長接送區，公有停車場也提供機車免費停車時段，方便機...                  \n",
      "                    近來外送產業爭議不斷，台北市政府警察局今邀集交通局及Uber eats、Foodpanda、Lalamove等6家外送平...                  \n",
      "                    現在外送競爭激烈，路上隨處可見外送員奔波送餐，為了能多搶單多賺點錢，有些外送員不惜會搶快違規，也因此近來外送員事故頻頻。有網友在臉書上PO出一張照片，一名外送員疑似跨越雙黃線逆向停等紅綠燈，讓原PO看了感嘆「錢要賺生命也要顧啊」。不過照片一PO出來，卻有人質疑原PO開車時為何還能使用手機拍照，網友留言引起兩派不同看法激辯。                  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "'\n",
      "10月(Nd)　13日(Nd)　晚間(Nd)　發生(VJ)　Uber Eats(FW)　黃姓(Nb)　外送(VD)　人員(Na)　職災(Na)　死亡(VH)　案件(Na)　，(COMMACATEGORY)　北市府(Nc)　勞動局(Nc)　認定(VE)　業者(Na)　未(D)　依(P)　職業(Na)　安全(VH)　衛生(Na)　法(Na)　第37(Neu)　條(Nf)　第2(Neu)　項(Nf)　第1(Neu)　款(Nf)　規定(Na)　於(P)　8(Neu)　小時(Na)　內(Ng)　向(P)　勞動(VC)　檢查(VE)　機構(Na)　通報(VE)　，(COMMACATEGORY)　開罰(VC)　Uber (FW)　Eats (FW)　30萬(Neu)　元(Nf)　。(PERIODCATEGORY)　\n",
      "\r\n",
      "(WHITESPACE)　台北市(Nc)　勞動局(Nc)　表示(VE)　，(COMMACATEGORY)　經(P)　勞動(VC)　檢查(VE)　發現(VE)　，(COMMACATEGORY)　Uber Eats(FW)　在(P)　台灣(Nc)　有(V_2)　稅籍(Na)　登記(VC)　（(PARENTHESISCATEGORY)　境(Na)　外(Ncd)　電商(Na)　登記(VC)　）(PARENTHESISCATEGORY)　，(COMMACATEGORY)　但(Cbb)　無(VJ)　公司(Nc)　登記(VC)　，(COMMACATEGORY)　透過(P)　委任(VF)　或(Caa)　服務(VC)　合作(VH)　備忘錄(Na)　方式(Na)　，(COMMACATEGORY)　分別(D)　與(P)　香港商(Na)　比錫茲(Nb)　有限公司(Nc)　、(PAUSECATEGORY)　易得(Nb)　汽車(Na)　貨運(Na)　股份(Na)　有限公司(Nc)　簽訂(VC)　合作(VH)　契約(Na)　，(COMMACATEGORY)　易得(VH)　公司(Nc)　再(D)　與(P)　外送員(Na)　以(P)　電腦(Na)　平台(Na)　方式(Na)　簽訂(VC)　合約(Na)　，(COMMACATEGORY)　而(Cbb)　合約(Na)　內容(Na)　卻(D)　由(P)　Uber (FW)　Eats(FW)　提供(VD)　，(COMMACATEGORY)　且(Cbb)　外送員(Na)　之(DE)　工資(Na)　亦(D)　由(P)　Uber Eats(FW)　直接(VH)　支付(VD)　，(COMMACATEGORY)　故(Cbb)　勞動局(Nc)　認定(VE)　Uber (FW)　Eats(FW)　為(VG)　外送員(Na)　之(DE)　實質(Na)　雇主(Na)　。(PERIODCATEGORY)　\n",
      "\r\n",
      "(WHITESPACE)　北市(Nc)　勞動局(Nc)　職安科(Nc)　科長(Na)　康水順(Nb)　表示(VE)　，職(Na)　安衛(Na)　部份(Neqa)　已(D)　完成(VC)　檢查(VE)　，(COMMACATEGORY)　經(P)　訪談(VC)　筆錄(Na)　及(Caa)　取得(VC)　的(DE)　文件(Na)　認定(VE)　該(Nes)　名(Nf)　罹災(VH)　勞工(Na)　與(Caa)　Uber Eats(FW)　具有(VJ)　僱傭(VC)　關係(Na)　，(COMMACATEGORY)　故(Cbb)　依(P)　職業(Na)　安全(VH)　衛生(Na)　法(Na)　第37(Neu)　條(Nf)　第2(Neu)　項(Nf)　第1(Neu)　款(Nf)　，(COMMACATEGORY)　雇主(Na)　應(D)　於(P)　8(Neu)　小時(Na)　內(Ng)　通報(VE)　，(COMMACATEGORY)　但(Cbb)　至今(D)　無(D)　收到(VC)　任何(Neqa)　通報(VE)　記錄(Na)　；(SEMICOLONCATEGORY)　另外(Cbb)　送員(VB)　於(P)　發生(VJ)　職災(Na)　死亡(VH)　後(Ng)　，(COMMACATEGORY)　Uber Eats(FW)　知悉(VK)　事故(Na)　的(DE)　發生(VJ)　卻(D)　未(D)　通報(VE)　，(COMMACATEGORY)　屬(VG)　明知(VK)　法令(Na)　卻(D)　仍(D)　違法(VA)　。(PERIODCATEGORY)　\n",
      "\r\n",
      "(WHITESPACE)　北市(Nc)　勞動局長(Na)　賴香伶(Nb)　表示(VE)　，(COMMACATEGORY)　由於(Cbb)　平台(Na)　業者(Na)　標榜(VE)　食物(Na)　外(Ncd)　送(VD)　之(DE)　快捷性(Na)　，(COMMACATEGORY)　卻(D)　罔顧(VJ)　外送員(Na)　行車(VA)　安全(VH)　，(COMMACATEGORY)　更(Dfa)　以(P)　送達(VD)　時間(Na)　計算(VC)　外(Ng)　送員(VA)　工作(Na)　獎金(Na)　，(COMMACATEGORY)　致(Cbb)　外送員(Na)　為(P)　達(VJ)　平台(Na)　業者(Na)　規定(VE)　，(COMMACATEGORY)　執行(VC)　外送(VD)　業務(Na)　時(Ng)　於(P)　道路(Na)　上(Ncd)　高速(VH)　行駛(VA)　及(Caa)　穿梭(VA)　於(P)　車陣(Na)　，(COMMACATEGORY)　徒(D)　增(VJ)　行車(VA)　事故(Na)　風險(Na)　。(PERIODCATEGORY)　勞動局(Nc)　已(D)　事先(D)　向(P)　業者(Na)　宣導(VC)　法令(Na)　，(COMMACATEGORY)　考量(VE)　Uber Eats(FW)　違法(VA)　行為(Na)　嚴重(VH)　影響(VC)　公共(A)　秩序(Na)　，(COMMACATEGORY)　受(VJ)　責難(Na)　程度(Na)　高(VH)　，(COMMACATEGORY)　依(P)　行政(Na)　罰法(Na)　、(PAUSECATEGORY)　職業(Na)　安全(VH)　衛生(Na)　法(Na)　裁處(VC)　罰鍰(Na)　30萬(Neu)　元(Nf)　。(PERIODCATEGORY)　\n",
      "\r\n",
      "(WHITESPACE)　勞動局(Nc)　職安科(Nc)　表示(VE)　，(COMMACATEGORY)　今日(Nd)　先(D)　針對(P)　職災(Na)　通報(VE)　部分(Neqa)　裁處(VC)　作成(VG)　決議(Na)　，(COMMACATEGORY)　後續(A)　業者(Na)　違反(VJ)　勞基法(Na)　的(DE)　部分(Neqa)　，(COMMACATEGORY)　將(D)　根據(P)　違法(VA)　部分(Neqa)　另行(D)　開罰(VC)　。(PERIODCATEGORY)　除針(Na)　Uber Eats(FW)　黃姓(Nb)　外送(VD)　人員(Na)　職災(Na)　死亡(VH)　卻(D)　未(D)　依法(D)　通報(VE)　案件(Na)　開罰(VC)　業者(Na)　30萬(Neu)　元(Nf)　，(COMMACATEGORY)　北市(Nc)　政府(Na)　今日(Nd)　下午(Nd)　也(D)　跨(VC)　局(Nc)　處(Nc)　召開(VC)　「(PARENTHESISCATEGORY)　外送(VD)　人員(Na)　保障(VC)　專案(Na)　會議(Na)　」(PARENTHESISCATEGORY)　。(PERIODCATEGORY)　圖(Na)　／(FW)　台北市(Nc)　勞動局(Nc)　提供(VD)　\n",
      "                    (WHITESPACE)　外送員(Na)　車禍(Na)　又(D)　一(Neu)　樁(Nf)　！Uber Eats(FW)　林姓(Nb)　外送員(Na)　與(Caa)　柯姓(Nb)　女(Na)　駕駛(Na)　發生(VJ)　碰撞(VA)　，(COMMACATEGORY)　林男(Nb)　身體(Na)　擦傷(VC)　，(COMMACATEGORY)　送醫(VB)　後(Ng)　無礙(VH)　。(PERIODCATEGORY)　近日(Nd)　外送(VD)　平台(Na)　崛起(VH)　，(COMMACATEGORY)　路(Na)　上(Ncd)　可(D)　見(VE)　.(PERIODCATEGORY)　.(PERIODCATEGORY)　.(PERIODCATEGORY)　                  \n",
      "                    (WHITESPACE)　新北市府(Nc)　交通局(Nc)　今天(Nd)　表示(VE)　，(COMMACATEGORY)　將(D)　規劃(VC)　機車(Na)　卸貨(VA)　停車(VA)　區域(Nc)　，(COMMACATEGORY)　並(Cbb)　開放(VC)　外送員(Na)　臨時(Nd)　停靠(VC)　家長(Na)　接送區(Nc)　，(COMMACATEGORY)　公有(A)　停車場(Nc)　也(D)　提供(VD)　機車(Na)　免費(VH)　停車(VA)　時段(Na)　，(COMMACATEGORY)　方便機(Na)　.(PERIODCATEGORY)　.(PERIODCATEGORY)　.(PERIODCATEGORY)　                  \n",
      "                    (WHITESPACE)　近來(D)　外送(VD)　產業(Na)　爭議(Na)　不斷(VH)　，(COMMACATEGORY)　台北市(Nc)　政府(Na)　警察局(Nc)　今(Nd)　邀集(VC)　交通局(Nc)　及(Caa)　Uber eats(FW)　、(PAUSECATEGORY)　Foodpanda(FW)　、(PAUSECATEGORY)　Lalamove(FW)　等(Cab)　6(Neu)　家(Nc)　外(Ncd)　送(VD)　平(VH)　.(PERIODCATEGORY)　.(PERIODCATEGORY)　.(PERIODCATEGORY)　                  \n",
      "                    (WHITESPACE)　現在(Nd)　外送(VD)　競爭(Na)　激烈(VH)　，(COMMACATEGORY)　路(Na)　上(Ng)　隨處(D)　可(D)　見(VE)　外送員(Na)　奔波(VA)　送餐(VA)　，(COMMACATEGORY)　為了(P)　能(D)　多(D)　搶單(VA)　多(D)　賺(VC)　點(Nf)　錢(Na)　，(COMMACATEGORY)　有(V_2)　些(Nf)　外送員(Na)　不惜(VL)　會(D)　搶快(VA)　違規(VA)　，(COMMACATEGORY)　也(D)　因此(Cbb)　近來(D)　外送員(Na)　事故(Na)　頻頻(VH)　。(PERIODCATEGORY)　有(V_2)　網友(Na)　在(P)　臉書(Na)　上(Ncd)　PO(FW)　出(VC)　一(Neu)　張(Nf)　照片(Na)　，(COMMACATEGORY)　一(Neu)　名(Nf)　外送員(Na)　疑似(VG)　跨越(VCL)　雙黃線(Na)　逆向(D)　停(VHC)　等(Cab)　紅綠燈(Na)　，(COMMACATEGORY)　讓(VL)　原(A)　PO(FW)　看(VC)　了(Di)　感嘆(VE)　「(PARENTHESISCATEGORY)　錢(Na)　要(D)　賺(VC)　生命(Na)　也(D)　要(D)　顧(VK)　啊(T)　」(PARENTHESISCATEGORY)　。(PERIODCATEGORY)　不過(Cbb)　照片(Na)　一(Neu)　PO(FW)　出來(VA)　，(COMMACATEGORY)　卻(D)　有(V_2)　人(Na)　質疑(VE)　原(A)　PO(FW)　開車(VA)　時(Ng)　為何(D)　還(D)　能(D)　使用(VC)　手機(Na)　拍照(VB)　，(COMMACATEGORY)　網友(Na)　留言(Na)　引起(VC)　兩(Neu)　派(Nf)　不同(VH)　看法(Na)　激辯(Na)　。(PERIODCATEGORY)　                  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(WHITESPACE)　\n",
      "(0, 6, 'DATE', '10月13日')\n",
      "(6, 8, 'TIME', '晚間')\n",
      "(10, 19, 'ORG', 'Uber Eats')\n",
      "(19, 20, 'PERSON', '黃')\n",
      "(32, 38, 'ORG', '北市府勞動局')\n",
      "(51, 54, 'ORDINAL', '第37')\n",
      "(55, 57, 'ORDINAL', '第2')\n",
      "(58, 60, 'ORDINAL', '第1')\n",
      "(64, 67, 'TIME', '8小時')\n",
      "(90, 94, 'MONEY', '30萬元')\n",
      "(99, 104, 'ORG', '北市勞動局')\n",
      "(115, 124, 'ORG', 'Uber Eats')\n",
      "(125, 127, 'GPE', '台灣')\n",
      "(166, 176, 'ORG', '香港商比錫茲有限公司')\n",
      "(177, 189, 'ORG', '易得汽車貨運股份有限公司')\n",
      "(196, 200, 'ORG', '易得公司')\n",
      "(245, 254, 'ORG', 'Uber Eats')\n",
      "(265, 274, 'ORG', 'Uber Eats')\n",
      "(297, 300, 'PERSON', '康水順')\n",
      "(334, 343, 'ORG', 'Uber Eats')\n",
      "(356, 359, 'LAW', '衛生法')\n",
      "(359, 362, 'ORDINAL', '第37')\n",
      "(363, 365, 'ORDINAL', '第2')\n",
      "(366, 368, 'ORDINAL', '第1')\n",
      "(374, 377, 'TIME', '8小時')\n",
      "(407, 416, 'ORG', 'Uber Eats')\n",
      "(447, 450, 'PERSON', '賴香伶')\n",
      "(541, 544, 'ORG', '勞動局')\n",
      "(557, 566, 'ORG', 'Uber Eats')\n",
      "(603, 607, 'MONEY', '30萬元')\n",
      "(620, 622, 'DATE', '今日')\n",
      "(644, 647, 'LAW', '勞基法')\n",
      "(674, 675, 'PERSON', '黃')\n",
      "(696, 700, 'MONEY', '30萬元')\n",
      "(701, 703, 'GPE', '北市')\n",
      "(703, 705, 'ORG', '政府')\n",
      "(705, 707, 'DATE', '今日')\n",
      "(707, 709, 'TIME', '下午')\n",
      "(730, 736, 'ORG', '台北市勞動局')\n",
      "(777, 778, 'PERSON', '林')\n",
      "(783, 784, 'PERSON', '柯')\n",
      "(793, 795, 'PERSON', '林男')\n",
      "(861, 868, 'ORG', '新北市府交通局')\n",
      "(868, 870, 'DATE', '今天')\n",
      "(974, 982, 'ORG', '台北市政府警察局')\n",
      "(985, 988, 'ORG', '交通局')\n",
      "(999, 1008, 'PERSON', 'Foodpanda')\n",
      "(1009, 1017, 'PERSON', 'Lalamove')\n",
      "(1018, 1019, 'CARDINAL', '6')\n",
      "(1135, 1136, 'CARDINAL', '一')\n",
      "(1140, 1141, 'CARDINAL', '一')\n",
      "(1218, 1219, 'CARDINAL', '兩')\n"
     ]
    }
   ],
   "source": [
    "def print_word_pos_sentence(word_sentence, pos_sentence):\n",
    "    assert len(word_sentence) == len(pos_sentence)\n",
    "    for word, pos in zip(word_sentence, pos_sentence):\n",
    "        print(f\"{word}({pos})\", end=\"\\u3000\")\n",
    "    print()\n",
    "    return\n",
    "    \n",
    "for i, sentence in enumerate(sentence_list):\n",
    "    print()\n",
    "    print(f\"'{sentence}'\")\n",
    "    print_word_pos_sentence(word_sentence_list[i],  pos_sentence_list[i])\n",
    "    for entity in sorted(entity_sentence_list[i]):\n",
    "        print(entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "隨機測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'熱搜：熱門行情最近搜尋基金老司機近年來投資市場波動越來越明顯，追求低波動、絕對報酬的量化交易備受注目。專家表示，採用量化交易策略投資台股，不管是處於多頭或是空頭市場，績效及波動度均可領跑大盤，甚至比國內投資台股的股票型基金及 ETF 的波動率還低，表現也更為穩定。大數據時代來臨，風行歐美 50 年的量化交易儼然成為顯學，台灣亦開始重視此一趨勢發展，也因此，中華機率統計學會及台北科技大學管理學院攜手主辦，並由元大期貨、摩根亞太量化交易等公司擔任協辦單位，今  日舉辦「時間序列與量化交易研討會」，就目前熱門的量化交易、智能投資等相關議題進行研討。越來越多的基金公司重視量化交易，全球規模較大的避險基金多採行量化交易，包括橋水基金 、AQR 資產管理公司、曼氏集團 、文藝復興科技  等全球知名避險基金。摩根亞太集團董事長張堯勇指出，避險基金規模約為 5 兆美元，採取量化交易的基金規模約 1 兆美元，比重佔了 20%，代表量化交易的操作績效好，才會有那麼高的比重。量化交易的操作績效不亞於價值投資及技術投資，被譽為數學天才、最賺錢的基金經理人，文藝復興對沖基金創始人詹姆斯 · 西蒙斯  所管理的大獎章  基金，便是典型的量化交易，績效表現優異，不僅勝過索羅斯的量子基金，也打敗了股神巴菲特的價值投資。近年來台灣也逐漸重視量化交易，摩根亞太量化交易公司今年開始將量化交易引進台股投資，是國內首家推出量化交易策略的公司，初期對象鎖定法人機構，進行私募投資。張堯勇表示，數學不只是一門學科，更是一項扭轉乾坤、轉敗為勝的競爭利器，量化交易就是將數學運用在股市投資，透過複雜、精密的推理計算，打敗股市。他指出，目前全球利率水平 50 位於年來新低，美國十年期公債殖利率只有 2%，日本及一些歐洲國家甚至是負利率。歷史極低利率帶導致無風險及低風險工具的投資報酬率太低（例如：銀行存款、政府公債及投資等級公司債），無法對抗通貨膨脹及支付負債，所以資產配置必須增加較高風險的投資，如股票、高收益公司債或新興市場債券，但是這些投資工具波動很大，而且很容易產生虧損！他表示，長期來說，股市絕對是好的投資，報酬率也不差，但是如何選股是一門學問。目前全球 60 個主要股市交易所，總市值 70 兆美元，而台灣上市上櫃市值 35 兆台幣，面對全球及台灣最大的股市金礦，投資人應該善用「量化交易」這個超級挖礦機，以程式選股來掏金。張堯勇指出，量化投資具有低波動、絕對報酬、優於大盤的三大特點，摩根亞太量化交易模擬台股近 8 年來的績效，結果顯示，運用量化交易的年化報酬率及波動度均優於台股上市櫃指數，以 2011 年金融海嘯及 2018 年中美貿易戰為例，台股上市、上櫃指數均是負報酬，不過，摩根量化交易卻是正報酬，而且波動度也比較低。此外，由於台灣四大政府基金操作績效不彰，不少金融機構也面臨投資虧損問題，亦可透過量化交易提高投資報酬率。張堯勇指出，郵儲、勞退、勞保、及退撫等四大基金，總資產高達 10 兆台幣，但過去 10 年的投資報酬率不到 3%，去年虧損 120 億，面臨提早破產的風險！另外台灣保險公司的總資產高達 26 兆台幣，過去賣出去的保單利率高達 4-6%，但是去年的資產報酬率卻只不到 0.4%，而且去年綜合損益虧損高達 5,000 億！金管會連下三道金牌：所有保險公司今年不準發放現金股利、部分保險公司必須儘快舉辦現金增資、以後賣的保單利率必須下降。另外台灣全體商業銀行也有高達 43 兆的總資產 43 兆，但是其資產報酬率僅只有 0.7%。以上將近 80 兆台幣的資金，張堯勇指出，若將 10% 投資於股市，投資金額高達 8 兆，報酬率每增加 1%，就有 800 億元的獲利，對於台灣的國家財政或金融機構的獲利，都有非常巨大的助益。'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['raw_content'].str.replace('\\(.*?\\)', '')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] 繼 員 林 站 1 名 旅 客 落 軌 遭 自 強 號 列 車 撞 上 後 ， 台 鐵 剛 剛 又 發 生 一 起 事 故 。 [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] 繼 員 林 站 1 名 旅 客 落 軌 遭 自 強 號 列 車 撞 上 後 ， 台 鐵 剛 剛 又 發 生 一 起 事 故 。 [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 5262 1519 3360 4991 122 1399 3180 2145 5862 6724 6901 5632 2485 5998 1154 6722 3058 677 2527 8024 1378 7136 1190 1190 1348 4634 4495 671 6629 752 3125 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 5262 1519 3360 4991 122 1399 3180 2145 5862 6724 6901 5632 2485 5998 1154 6722 3058 677 2527 8024 1378 7136 1190 1190 1348 4634 4495 671 6629 752 3125 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] 留 美 蔡 姓 少 校 涉 嫌 提 供 郵 局 帳 戶 等 資 料 ， 給 予 詐 欺 集 團 行 騙 近 30 萬 元 ， 被 屏 東 地 院 依 詐 欺 罪 ， 判 處 有 期 徒 刑 5 月 ， 案 經 上 訴 高 雄 高 分 院 後 ， 宣 告 緩 刑 3 年 定 讞 ， 緩 刑 期 間 交 付 保 護 管 束 ， 並 賠 償 被 害 人 共 15 萬 元 。 [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] 留 美 蔡 姓 少 校 涉 嫌 提 供 郵 局 帳 戶 等 資 料 ， 給 予 詐 欺 集 團 行 騙 近 30 萬 元 ， 被 屏 東 地 院 依 詐 欺 罪 ， 判 處 有 期 徒 刑 5 月 ， 案 經 上 訴 高 雄 高 分 院 後 ， 宣 告 緩 刑 3 年 定 讞 ， 緩 刑 期 間 交 付 保 護 管 束 ， 並 賠 償 被 害 人 共 15 萬 元 。 [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 4522 5401 5918 1998 2208 3413 3868 2066 2990 897 6960 2229 2379 2786 5023 6536 3160 8024 5183 750 6266 3619 7415 1757 6121 7700 6818 8114 5857 1039 8024 6158 2242 3346 1765 7368 898 6266 3619 5389 8024 1161 5993 3300 3309 2530 1152 126 3299 8024 3428 5195 677 6260 7770 7413 7770 1146 7368 2527 8024 2146 1440 5227 1152 124 2399 2137 6368 8024 5227 1152 3309 7279 769 802 924 6362 5052 3338 8024 699 6543 1030 6158 2154 782 1066 8115 5857 1039 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 4522 5401 5918 1998 2208 3413 3868 2066 2990 897 6960 2229 2379 2786 5023 6536 3160 8024 5183 750 6266 3619 7415 1757 6121 7700 6818 8114 5857 1039 8024 6158 2242 3346 1765 7368 898 6266 3619 5389 8024 1161 5993 3300 3309 2530 1152 126 3299 8024 3428 5195 677 6260 7770 7413 7770 1146 7368 2527 8024 2146 1440 5227 1152 124 2399 2137 6368 8024 5227 1152 3309 7279 769 802 924 6362 5052 3338 8024 699 6543 1030 6158 2154 782 1066 8115 5857 1039 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Jasonhsu\\Desktop\\esun\\bert_classfication2\\model.ckpt-1495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Jasonhsu\\Desktop\\esun\\bert_classfication2\\model.ckpt-1495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "tests = getPrediction([\n",
    "    '繼員林站1名旅客落軌遭自強號列車撞上後，台鐵剛剛又發生一起事故。',\n",
    "    '留美蔡姓少校涉嫌提供郵局帳戶等資料，給予詐欺集團行騙近30萬元，被屏東地院依詐欺罪，判處有期徒刑5月，案經上訴高雄高分院後，宣告緩刑3年定讞，緩刑期間交付保護管束，並賠償被害人共15萬元。'\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] 專 案 小 組 認 定 國 安 局 少 校 吳 宗 憲 、 張 恒 嘉 與 華 航 空 品 處 前 副 總 邱 彰 信 、 協 理 于 堯 、 代 理 組 長 黃 川 禎 等 人 涉 犯 貪 汙 治 罪 條 例 ， [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] 專 案 小 組 認 定 國 安 局 少 校 吳 宗 憲 、 張 恒 嘉 與 華 航 空 品 處 前 副 總 邱 彰 信 、 協 理 于 堯 、 代 理 組 長 黃 川 禎 等 人 涉 犯 貪 汙 治 罪 條 例 ， [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2201 3428 2207 5175 6291 2137 1751 2128 2229 2208 3413 1425 2134 2740 510 2484 2608 1649 5645 5836 5661 4958 1501 5993 1184 1199 5244 6937 2511 928 510 1295 4415 754 1839 510 807 4415 5175 7269 7941 2335 4885 5023 782 3868 4306 6517 3732 3780 5389 3454 891 8024 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2201 3428 2207 5175 6291 2137 1751 2128 2229 2208 3413 1425 2134 2740 510 2484 2608 1649 5645 5836 5661 4958 1501 5993 1184 1199 5244 6937 2511 928 510 1295 4415 754 1839 510 807 4415 5175 7269 7941 2335 4885 5023 782 3868 4306 6517 3732 3780 5389 3454 891 8024 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] 另 買 菸 大 戶 上 士 駕 駛 劉 尊 彰 、 民 間 人 士 李 宗 原 等 人 涉 違 反 稅 捐 稽 徵 法 ， 依 法 起 訴 。 其 餘 單 純 團 購 人 員 則 另 簽 分 偵 辦 。 [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] 另 買 菸 大 戶 上 士 駕 駛 劉 尊 彰 、 民 間 人 士 李 宗 原 等 人 涉 違 反 稅 捐 稽 徵 法 ， 依 法 起 訴 。 其 餘 單 純 團 購 人 員 則 另 簽 分 偵 辦 。 [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1369 6525 5839 1920 2786 677 1894 7690 7691 1208 2203 2511 510 3696 7279 782 1894 3330 2134 1333 5023 782 3868 6889 1353 4922 2935 4942 2547 3791 8024 898 3791 6629 6260 511 1071 7626 1606 5155 1757 6554 782 1519 1179 1369 5087 1146 980 6794 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1369 6525 5839 1920 2786 677 1894 7690 7691 1208 2203 2511 510 3696 7279 782 1894 3330 2134 1333 5023 782 3868 6889 1353 4922 2935 4942 2547 3791 8024 898 3791 6629 6260 511 1071 7626 1606 5155 1757 6554 782 1519 1179 1369 5087 1146 980 6794 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] 7 月 22 日 ， 總 統 蔡 英 文 結 束 12 天 「 自 由 民 主 永 續 之 旅 」 返 台 ， 調 查 局 以 行 政 檢 查 方 式 ， [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] 7 月 22 日 ， 總 統 蔡 英 文 結 束 12 天 「 自 由 民 主 永 續 之 旅 」 返 台 ， 調 查 局 以 行 政 檢 查 方 式 ， [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 128 3299 8130 3189 8024 5244 5186 5918 5739 3152 5178 3338 8110 1921 519 5632 4507 3696 712 3719 5265 722 3180 520 6819 1378 8024 6310 3389 2229 809 6121 3124 3596 3389 3175 2466 8024 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 128 3299 8130 3189 8024 5244 5186 5918 5739 3152 5178 3338 8110 1921 519 5632 4507 3696 712 3719 5265 722 3180 520 6819 1378 8024 6310 3389 2229 809 6121 3124 3596 3389 3175 2466 8024 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] 攔 查 國 安 局 官 員 隨 團 走 私 980 ##0 條 菸 ， 金 額 高 達 64 ##5 萬 元 ， 創 桃 園 機 場 夾 帶 走 私 菸 最 大 數 量 紀 錄 。 [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] 攔 查 國 安 局 官 員 隨 團 走 私 980 ##0 條 菸 ， 金 額 高 達 64 ##5 萬 元 ， 創 桃 園 機 場 夾 帶 走 私 菸 最 大 數 量 紀 錄 。 [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 3105 3389 1751 2128 2229 2135 1519 7401 1757 6624 4900 10536 8129 3454 5839 8024 7032 7540 7770 6888 8308 8157 5857 1039 8024 1201 3425 1754 3582 1842 1933 2380 6624 4900 5839 3297 1920 3149 7030 5145 7087 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 3105 3389 1751 2128 2229 2135 1519 7401 1757 6624 4900 10536 8129 3454 5839 8024 7032 7540 7770 6888 8308 8157 5857 1039 8024 1201 3425 1754 3582 1842 1933 2380 6624 4900 5839 3297 1920 3149 7030 5145 7087 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Jasonhsu\\Desktop\\esun\\bert_classfication2\\model.ckpt-1495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Jasonhsu\\Desktop\\esun\\bert_classfication2\\model.ckpt-1495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('專案小組認定國安局少校吳宗憲、張恒嘉與華航空品處前副總邱彰信、協理于堯、代理組長黃川禎等人涉犯貪汙治罪條例，',\n",
       "  array([-8.4189816e+00, -2.2063205e-04], dtype=float32),\n",
       "  1,\n",
       "  'aml'),\n",
       " ('另買菸大戶上士駕駛劉尊彰、民間人士李宗原等人涉違反稅捐稽徵法，依法起訴。其餘單純團購人員則另簽分偵辦。',\n",
       "  array([-6.3539352e+00, -1.7414418e-03], dtype=float32),\n",
       "  1,\n",
       "  'aml'),\n",
       " ('7月22日，總統蔡英文結束12天「自由民主永續之旅」返台，調查局以行政檢查方式，',\n",
       "  array([-7.700623e-05, -9.471053e+00], dtype=float32),\n",
       "  0,\n",
       "  'non_aml'),\n",
       " ('攔查國安局官員隨團走私9800條菸，金額高達645萬元，創桃園機場夾帶走私菸最大數量紀錄。',\n",
       "  array([-9.255009e+00, -9.560128e-05], dtype=float32),\n",
       "  1,\n",
       "  'aml')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getPrediction(['專案小組認定國安局少校吳宗憲、張恒嘉與華航空品處前副總邱彰信、協理于堯、代理組長黃川禎等人涉犯貪汙治罪條例，',\n",
    "               '另買菸大戶上士駕駛劉尊彰、民間人士李宗原等人涉違反稅捐稽徵法，依法起訴。其餘單純團購人員則另簽分偵辦。',\n",
    "               '7月22日，總統蔡英文結束12天「自由民主永續之旅」返台，調查局以行政檢查方式，',\n",
    "              '攔查國安局官員隨團走私9800條菸，金額高達645萬元，'\n",
    "              '創桃園機場夾帶走私菸最大數量紀錄。'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('繼員林站1名旅客落軌遭自強號列車撞上後，台鐵剛剛又發生一起事故。',\n",
       "  array([-6.413254e-05, -9.654260e+00], dtype=float32),\n",
       "  0,\n",
       "  'non_aml'),\n",
       " ('留美蔡姓少校涉嫌提供郵局帳戶等資料，給予詐欺集團行騙近30萬元，被屏東地院依詐欺罪，判處有期徒刑5月，案經上訴高雄高分院後，宣告緩刑3年定讞，緩刑期間交付保護管束，並賠償被害人共15萬元。',\n",
       "  array([-8.8697138e+00, -1.4053787e-04], dtype=float32),\n",
       "  1,\n",
       "  'aml')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "批次測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['raw_content'].str.replace('\\（.*?\\）', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] 將 近 九 十 四 萬 的 同 意 票 ， 讓 韓 國 瑜 成 為 台 灣 自 治 史 上 首 位 被 罷 免 的 市 長 ， 從 風 光 的 立 委 到 退 隱 政 壇 、 從 賣 菜 郎 到 藍 營 救 世 主 、 創 下 韓 流 奇 蹟 ， 短 短 一 年 半 三 次 選 舉 ， 把 他 推 向 政 治 生 命 高 峰 也 一 舉 跌 落 谷 底 ， 韓 國 瑜 的 政 治 人 生 暴 起 又 暴 落 ， 轟 轟 烈 烈 ， 寫 下 台 灣 政 壇 傳 奇 。 挽 袖 的 藍 襯 衫 、 接 地 氣 的 庶 民 語 言 與 肢 體 動 作 創 造 了 「 韓 流 」 ， 打 破 綠 營 在 港 都 執 政 20 年 的 高 牆 ， 翻 轉 藍 綠 執 政 版 圖 ， 成 為 政 壇 耀 眼 的 明 星 。 而 面 臨 總 統 大 選 後 罷 韓 的 明 流 暗 湧 ， 失 去 的 民 心 有 如 慧 星 般 急 速 隕 落 ， 失 去 了 高 雄 市 長 的 韓 國 瑜 ， 政 壇 之 路 是 否 還 有 序 曲 ？ [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] 將 近 九 十 四 萬 的 同 意 票 ， 讓 韓 國 瑜 成 為 台 灣 自 治 史 上 首 位 被 罷 免 的 市 長 ， 從 風 光 的 立 委 到 退 隱 政 壇 、 從 賣 菜 郎 到 藍 營 救 世 主 、 創 下 韓 流 奇 蹟 ， 短 短 一 年 半 三 次 選 舉 ， 把 他 推 向 政 治 生 命 高 峰 也 一 舉 跌 落 谷 底 ， 韓 國 瑜 的 政 治 人 生 暴 起 又 暴 落 ， 轟 轟 烈 烈 ， 寫 下 台 灣 政 壇 傳 奇 。 挽 袖 的 藍 襯 衫 、 接 地 氣 的 庶 民 語 言 與 肢 體 動 作 創 造 了 「 韓 流 」 ， 打 破 綠 營 在 港 都 執 政 20 年 的 高 牆 ， 翻 轉 藍 綠 執 政 版 圖 ， 成 為 政 壇 耀 眼 的 明 星 。 而 面 臨 總 統 大 選 後 罷 韓 的 明 流 暗 湧 ， 失 去 的 民 心 有 如 慧 星 般 急 速 隕 落 ， 失 去 了 高 雄 市 長 的 韓 國 瑜 ， 政 壇 之 路 是 否 還 有 序 曲 ？ [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2200 6818 736 1282 1724 5857 4638 1398 2692 4873 8024 6366 7502 1751 4447 2768 4158 1378 4124 5632 3780 1380 677 7674 855 6158 5394 1048 4638 2356 7269 8024 2537 7591 1045 4638 4989 1999 1168 6842 7403 3124 1883 510 2537 6546 5831 6947 1168 5965 4245 3131 686 712 510 1201 678 7502 3837 1936 6695 8024 4764 4764 671 2399 1288 676 3613 6908 5647 8024 2828 800 2972 1403 3124 3780 4495 1462 7770 2292 738 671 5647 6649 5862 6484 2419 8024 7502 1751 4447 4638 3124 3780 782 4495 3274 6629 1348 3274 5862 8024 6755 6755 4164 4164 8024 2183 678 1378 4124 3124 1883 1001 1936 511 2924 6153 4638 5965 6203 6136 510 2970 1765 3706 4638 2433 3696 6295 6241 5645 5501 7768 1240 868 1201 6863 749 519 7502 3837 520 8024 2802 4788 5199 4245 1762 3949 6963 1822 3124 8113 2399 4638 7770 4274 8024 5436 6752 5965 5199 1822 3124 4276 1756 8024 2768 4158 3124 1883 5438 4706 4638 3209 3215 511 5445 7481 5631 5244 5186 1920 6908 2527 5394 7502 4638 3209 3837 3266 3963 8024 1927 1343 4638 3696 2552 3300 1963 2716 3215 5663 2593 6862 7393 5862 8024 1927 1343 749 7770 7413 2356 7269 4638 7502 1751 4447 8024 3124 1883 722 6662 3221 1415 6917 3300 2415 3289 8043 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2200 6818 736 1282 1724 5857 4638 1398 2692 4873 8024 6366 7502 1751 4447 2768 4158 1378 4124 5632 3780 1380 677 7674 855 6158 5394 1048 4638 2356 7269 8024 2537 7591 1045 4638 4989 1999 1168 6842 7403 3124 1883 510 2537 6546 5831 6947 1168 5965 4245 3131 686 712 510 1201 678 7502 3837 1936 6695 8024 4764 4764 671 2399 1288 676 3613 6908 5647 8024 2828 800 2972 1403 3124 3780 4495 1462 7770 2292 738 671 5647 6649 5862 6484 2419 8024 7502 1751 4447 4638 3124 3780 782 4495 3274 6629 1348 3274 5862 8024 6755 6755 4164 4164 8024 2183 678 1378 4124 3124 1883 1001 1936 511 2924 6153 4638 5965 6203 6136 510 2970 1765 3706 4638 2433 3696 6295 6241 5645 5501 7768 1240 868 1201 6863 749 519 7502 3837 520 8024 2802 4788 5199 4245 1762 3949 6963 1822 3124 8113 2399 4638 7770 4274 8024 5436 6752 5965 5199 1822 3124 4276 1756 8024 2768 4158 3124 1883 5438 4706 4638 3209 3215 511 5445 7481 5631 5244 5186 1920 6908 2527 5394 7502 4638 3209 3837 3266 3963 8024 1927 1343 4638 3696 2552 3300 1963 2716 3215 5663 2593 6862 7393 5862 8024 1927 1343 749 7770 7413 2356 7269 4638 7502 1751 4447 8024 3124 1883 722 6662 3221 1415 6917 3300 2415 3289 8043 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] 在 非 裔 美 人 佛 洛 伊 德 遭 警 方 不 當 暴 力 致 死 後 ， 美 國 福 斯 新 聞 的 一 個 節 目 5 日 用 圖 表 指 美 國 非 裔 人 士 遭 受 暴 力 時 ， 股 市 竟 會 大 漲 ， 此 舉 引 發 嘩 然 。 福 斯 新 聞 對 此 事 發 表 聲 明 ， 對 未 顧 慮 他 人 感 受 致 歉 。 《 法 新 社 》 7 日 報 導 ， 福 斯 新 聞 的 節 目 「 拜 爾 特 別 報 導 」 播 出 一 張 圖 表 ， 顯 示 美 國 非 裔 人 士 受 到 暴 力 ， 引 發 社 會 關 注 後 ， 股 市 呈 現 走 高 情 形 。 圖 表 中 顯 示 ， 在 佛 洛 伊 德 喪 命 後 ， 標 準 普 爾 500 指 數 大 漲 3 . 4 % 、 民 權 領 袖 馬 丁 ・ 路 德 ・ 金 恩 遇 刺 後 ， 標 普 500 上 漲 2 . 9 % 、 涉 毆 打 非 裔 青 年 金 恩 的 警 察 被 無 罪 釋 放 ， 以 及 非 裔 少 年 布 朗 遭 警 方 擊 斃 後 ， 標 普 500 的 漲 幅 都 是 1 . 2 % 。 伊 利 諾 伊 州 [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] 在 非 裔 美 人 佛 洛 伊 德 遭 警 方 不 當 暴 力 致 死 後 ， 美 國 福 斯 新 聞 的 一 個 節 目 5 日 用 圖 表 指 美 國 非 裔 人 士 遭 受 暴 力 時 ， 股 市 竟 會 大 漲 ， 此 舉 引 發 嘩 然 。 福 斯 新 聞 對 此 事 發 表 聲 明 ， 對 未 顧 慮 他 人 感 受 致 歉 。 《 法 新 社 》 7 日 報 導 ， 福 斯 新 聞 的 節 目 「 拜 爾 特 別 報 導 」 播 出 一 張 圖 表 ， 顯 示 美 國 非 裔 人 士 受 到 暴 力 ， 引 發 社 會 關 注 後 ， 股 市 呈 現 走 高 情 形 。 圖 表 中 顯 示 ， 在 佛 洛 伊 德 喪 命 後 ， 標 準 普 爾 500 指 數 大 漲 3 . 4 % 、 民 權 領 袖 馬 丁 ・ 路 德 ・ 金 恩 遇 刺 後 ， 標 普 500 上 漲 2 . 9 % 、 涉 毆 打 非 裔 青 年 金 恩 的 警 察 被 無 罪 釋 放 ， 以 及 非 裔 少 年 布 朗 遭 警 方 擊 斃 後 ， 標 普 500 的 漲 幅 都 是 1 . 2 % 。 伊 利 諾 伊 州 [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1762 7478 6167 5401 782 867 3821 823 2548 6901 6356 3175 679 4534 3274 1213 5636 3647 2527 8024 5401 1751 4886 3172 3173 5472 4638 671 943 5059 4680 126 3189 4500 1756 6134 2900 5401 1751 7478 6167 782 1894 6901 1358 3274 1213 3229 8024 5500 2356 4994 3298 1920 4039 8024 3634 5647 2471 4634 1666 4197 511 4886 3172 3173 5472 2205 3634 752 4634 6134 5476 3209 8024 2205 3313 7547 2719 800 782 2697 1358 5636 3624 511 517 3791 3173 4852 518 128 3189 1841 2206 8024 4886 3172 3173 5472 4638 5059 4680 519 2876 4273 4294 1162 1841 2206 520 3064 1139 671 2484 1756 6134 8024 7549 4850 5401 1751 7478 6167 782 1894 1358 1168 3274 1213 8024 2471 4634 4852 3298 7302 3800 2527 8024 5500 2356 1439 4412 6624 7770 2658 2501 511 1756 6134 704 7549 4850 8024 1762 867 3821 823 2548 1603 1462 2527 8024 3560 3976 3249 4273 8195 2900 3149 1920 4039 124 119 125 110 510 3696 3609 7526 6153 7679 672 644 6662 2548 644 7032 2617 6878 1173 2527 8024 3560 3249 8195 677 4039 123 119 130 110 510 3868 3676 2802 7478 6167 7471 2399 7032 2617 4638 6356 2175 6158 4192 5389 7026 3123 8024 809 1350 7478 6167 2208 2399 2357 3306 6901 6356 3175 3080 3151 2527 8024 3560 3249 8195 4638 4039 2388 6963 3221 122 119 123 110 511 823 1164 6330 823 2336 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1762 7478 6167 5401 782 867 3821 823 2548 6901 6356 3175 679 4534 3274 1213 5636 3647 2527 8024 5401 1751 4886 3172 3173 5472 4638 671 943 5059 4680 126 3189 4500 1756 6134 2900 5401 1751 7478 6167 782 1894 6901 1358 3274 1213 3229 8024 5500 2356 4994 3298 1920 4039 8024 3634 5647 2471 4634 1666 4197 511 4886 3172 3173 5472 2205 3634 752 4634 6134 5476 3209 8024 2205 3313 7547 2719 800 782 2697 1358 5636 3624 511 517 3791 3173 4852 518 128 3189 1841 2206 8024 4886 3172 3173 5472 4638 5059 4680 519 2876 4273 4294 1162 1841 2206 520 3064 1139 671 2484 1756 6134 8024 7549 4850 5401 1751 7478 6167 782 1894 1358 1168 3274 1213 8024 2471 4634 4852 3298 7302 3800 2527 8024 5500 2356 1439 4412 6624 7770 2658 2501 511 1756 6134 704 7549 4850 8024 1762 867 3821 823 2548 1603 1462 2527 8024 3560 3976 3249 4273 8195 2900 3149 1920 4039 124 119 125 110 510 3696 3609 7526 6153 7679 672 644 6662 2548 644 7032 2617 6878 1173 2527 8024 3560 3249 8195 677 4039 123 119 130 110 510 3868 3676 2802 7478 6167 7471 2399 7032 2617 4638 6356 2175 6158 4192 5389 7026 3123 8024 809 1350 7478 6167 2208 2399 2357 3306 6901 6356 3175 3080 3151 2527 8024 3560 3249 8195 4638 4039 2388 6963 3221 122 119 123 110 511 823 1164 6330 823 2336 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] 高 雄 市 議 長 許 崑 源 昨 晚 近 9 時 ， 從 住 家 17 樓 墜 樓 身 亡 ， 由 於 墜 樓 原 因 不 明 ， 引 起 各 界 議 論 紛 紛 。 家 屬 今 天 發 表 3 點 聲 明 ， 呼 籲 各 界 不 要 以 訛 傳 訛 ， 尊 重 往 生 者 為 大 ， 家 屬 對 不 實 言 論 將 保 留 法 律 追 訴 權 。 市 議 員 宋 立 彬 代 表 許 崑 源 家 屬 ， 發 布 三 點 聲 明 ， 首 先 家 屬 對 外 界 的 關 切 表 達 感 謝 ， 但 針 對 部 分 媒 體 不 實 報 導 與 網 路 傳 言 表 示 譴 責 ， 強 調 均 為 子 虛 烏 有 ， 請 勿 以 訛 傳 訛 ， 家 屬 將 保 留 法 律 追 訴 權 。 「 請 勿 再 消 費 許 崑 源 ， 並 請 尊 重 往 生 者 為 大 」 ， 高 雄 市 議 會 將 籌 組 治 喪 委 員 會 ， 全 力 協 助 家 屬 處 理 後 。 許 崑 源 住 家 出 事 地 點 ， 今 早 有 不 少 民 眾 前 往 現 場 獻 花 並 點 燭 光 表 示 追 悼 ， 受 訪 民 眾 說 [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] 高 雄 市 議 長 許 崑 源 昨 晚 近 9 時 ， 從 住 家 17 樓 墜 樓 身 亡 ， 由 於 墜 樓 原 因 不 明 ， 引 起 各 界 議 論 紛 紛 。 家 屬 今 天 發 表 3 點 聲 明 ， 呼 籲 各 界 不 要 以 訛 傳 訛 ， 尊 重 往 生 者 為 大 ， 家 屬 對 不 實 言 論 將 保 留 法 律 追 訴 權 。 市 議 員 宋 立 彬 代 表 許 崑 源 家 屬 ， 發 布 三 點 聲 明 ， 首 先 家 屬 對 外 界 的 關 切 表 達 感 謝 ， 但 針 對 部 分 媒 體 不 實 報 導 與 網 路 傳 言 表 示 譴 責 ， 強 調 均 為 子 虛 烏 有 ， 請 勿 以 訛 傳 訛 ， 家 屬 將 保 留 法 律 追 訴 權 。 「 請 勿 再 消 費 許 崑 源 ， 並 請 尊 重 往 生 者 為 大 」 ， 高 雄 市 議 會 將 籌 組 治 喪 委 員 會 ， 全 力 協 助 家 屬 處 理 後 。 許 崑 源 住 家 出 事 地 點 ， 今 早 有 不 少 民 眾 前 往 現 場 獻 花 並 點 燭 光 表 示 追 悼 ， 受 訪 民 眾 說 [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 7770 7413 2356 6359 7269 6258 2302 3975 3219 3241 6818 130 3229 8024 2537 857 2157 8126 3559 1871 3559 6716 767 8024 4507 3176 1871 3559 1333 1728 679 3209 8024 2471 6629 1392 4518 6359 6316 5160 5160 511 2157 2253 791 1921 4634 6134 124 7953 5476 3209 8024 1461 5100 1392 4518 679 6206 809 6251 1001 6251 8024 2203 7028 2518 4495 5442 4158 1920 8024 2157 2253 2205 679 2179 6241 6316 2200 924 4522 3791 2526 6841 6260 3609 511 2356 6359 1519 2129 4989 2509 807 6134 6258 2302 3975 2157 2253 8024 4634 2357 676 7953 5476 3209 8024 7674 1044 2157 2253 2205 1912 4518 4638 7302 1147 6134 6888 2697 6342 8024 852 7036 2205 6956 1146 2054 7768 679 2179 1841 2206 5645 5206 6662 1001 6241 6134 4850 6361 6519 8024 2485 6310 1772 4158 2094 5995 4166 3300 8024 6313 1257 809 6251 1001 6251 8024 2157 2253 2200 924 4522 3791 2526 6841 6260 3609 511 519 6313 1257 1086 3867 6527 6258 2302 3975 8024 699 6313 2203 7028 2518 4495 5442 4158 1920 520 8024 7770 7413 2356 6359 3298 2200 5092 5175 3780 1603 1999 1519 3298 8024 1059 1213 1295 1221 2157 2253 5993 4415 2527 511 6258 2302 3975 857 2157 1139 752 1765 7953 8024 791 3193 3300 679 2208 3696 4707 1184 2518 4412 1842 4368 5709 699 7953 4249 1045 6134 4850 6841 2656 8024 1358 6256 3696 4707 6303 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 7770 7413 2356 6359 7269 6258 2302 3975 3219 3241 6818 130 3229 8024 2537 857 2157 8126 3559 1871 3559 6716 767 8024 4507 3176 1871 3559 1333 1728 679 3209 8024 2471 6629 1392 4518 6359 6316 5160 5160 511 2157 2253 791 1921 4634 6134 124 7953 5476 3209 8024 1461 5100 1392 4518 679 6206 809 6251 1001 6251 8024 2203 7028 2518 4495 5442 4158 1920 8024 2157 2253 2205 679 2179 6241 6316 2200 924 4522 3791 2526 6841 6260 3609 511 2356 6359 1519 2129 4989 2509 807 6134 6258 2302 3975 2157 2253 8024 4634 2357 676 7953 5476 3209 8024 7674 1044 2157 2253 2205 1912 4518 4638 7302 1147 6134 6888 2697 6342 8024 852 7036 2205 6956 1146 2054 7768 679 2179 1841 2206 5645 5206 6662 1001 6241 6134 4850 6361 6519 8024 2485 6310 1772 4158 2094 5995 4166 3300 8024 6313 1257 809 6251 1001 6251 8024 2157 2253 2200 924 4522 3791 2526 6841 6260 3609 511 519 6313 1257 1086 3867 6527 6258 2302 3975 8024 699 6313 2203 7028 2518 4495 5442 4158 1920 520 8024 7770 7413 2356 6359 3298 2200 5092 5175 3780 1603 1999 1519 3298 8024 1059 1213 1295 1221 2157 2253 5993 4415 2527 511 6258 2302 3975 857 2157 1139 752 1765 7953 8024 791 3193 3300 679 2208 3696 4707 1184 2518 4412 1842 4368 5709 699 7953 4249 1045 6134 4850 6841 2656 8024 1358 6256 3696 4707 6303 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] [UNK] 搶 走 人 類 飯 碗 的 橋 段 ， 如 今 在 微 軟 裡 真 實 上 演 。 這 間 科 技 巨 頭 近 期 決 定 以 [UNK] 取 代 [UNK] 網 站 的 新 聞 編 輯 團 隊 ， 預 計 將 在 6 月 底 進 行 裁 員 ， 導 致 至 少 數 十 名 外 包 員 工 因 此 失 去 工 作 。 目 前 微 軟 [UNK] 網 站 上 的 新 聞 ， 主 要 是 由 編 輯 團 隊 整 理 其 他 媒 體 報 導 ， 重 新 挑 選 首 圖 及 下 標 後 編 整 而 成 ， 但 現 在 微 軟 認 為 [UNK] 能 夠 勝 任 這 份 工 作 。 綜 合 各 家 媒 體 報 導 ， 英 美 兩 國 共 有 近 80 名 外 包 員 工 受 到 影 響 。 對 於 這 個 消 息 ， 微 軟 僅 表 示 ， 「 如 同 所 有 企 業 ， 我 們 會 定 期 評 估 業 務 情 形 ， 這 有 可 能 令 公 司 增 加 對 特 定 領 域 的 投 資 ， 或 者 導 致 人 員 的 重 新 安 排 。 」 並 澄 清 這 些 決 定 並 非 歸 咎 於 在 美 國 肆 虐 的 新 冠 狀 病 毒 （ [UNK] [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] [UNK] 搶 走 人 類 飯 碗 的 橋 段 ， 如 今 在 微 軟 裡 真 實 上 演 。 這 間 科 技 巨 頭 近 期 決 定 以 [UNK] 取 代 [UNK] 網 站 的 新 聞 編 輯 團 隊 ， 預 計 將 在 6 月 底 進 行 裁 員 ， 導 致 至 少 數 十 名 外 包 員 工 因 此 失 去 工 作 。 目 前 微 軟 [UNK] 網 站 上 的 新 聞 ， 主 要 是 由 編 輯 團 隊 整 理 其 他 媒 體 報 導 ， 重 新 挑 選 首 圖 及 下 標 後 編 整 而 成 ， 但 現 在 微 軟 認 為 [UNK] 能 夠 勝 任 這 份 工 作 。 綜 合 各 家 媒 體 報 導 ， 英 美 兩 國 共 有 近 80 名 外 包 員 工 受 到 影 響 。 對 於 這 個 消 息 ， 微 軟 僅 表 示 ， 「 如 同 所 有 企 業 ， 我 們 會 定 期 評 估 業 務 情 形 ， 這 有 可 能 令 公 司 增 加 對 特 定 領 域 的 投 資 ， 或 者 導 致 人 員 的 重 新 安 排 。 」 並 澄 清 這 些 決 定 並 非 歸 咎 於 在 美 國 肆 虐 的 新 冠 狀 病 毒 （ [UNK] [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 100 3024 6624 782 7546 7613 4813 4638 3578 3667 8024 1963 791 1762 2544 6727 6174 4696 2179 677 4028 511 6857 7279 4906 2825 2342 7531 6818 3309 3748 2137 809 100 1357 807 100 5206 4991 4638 3173 5472 5226 6744 1757 7386 8024 7521 6243 2200 1762 127 3299 2419 6868 6121 6161 1519 8024 2206 5636 5635 2208 3149 1282 1399 1912 1259 1519 2339 1728 3634 1927 1343 2339 868 511 4680 1184 2544 6727 100 5206 4991 677 4638 3173 5472 8024 712 6206 3221 4507 5226 6744 1757 7386 3146 4415 1071 800 2054 7768 1841 2206 8024 7028 3173 2904 6908 7674 1756 1350 678 3560 2527 5226 3146 5445 2768 8024 852 4412 1762 2544 6727 6291 4158 100 5543 1917 1245 818 6857 819 2339 868 511 5198 1394 1392 2157 2054 7768 1841 2206 8024 5739 5401 1060 1751 1066 3300 6818 8188 1399 1912 1259 1519 2339 1358 1168 2512 7513 511 2205 3176 6857 943 3867 2622 8024 2544 6727 1006 6134 4850 8024 519 1963 1398 2792 3300 821 3511 8024 2769 947 3298 2137 3309 6268 844 3511 1243 2658 2501 8024 6857 3300 1377 5543 808 1062 1385 1872 1217 2205 4294 2137 7526 1818 4638 2832 6536 8024 2772 5442 2206 5636 782 1519 4638 7028 3173 2128 2961 511 520 699 4067 3926 6857 763 3748 2137 699 7478 3645 1470 3176 1762 5401 1751 5487 5990 4638 3173 1094 4311 4567 3681 8020 100 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 100 3024 6624 782 7546 7613 4813 4638 3578 3667 8024 1963 791 1762 2544 6727 6174 4696 2179 677 4028 511 6857 7279 4906 2825 2342 7531 6818 3309 3748 2137 809 100 1357 807 100 5206 4991 4638 3173 5472 5226 6744 1757 7386 8024 7521 6243 2200 1762 127 3299 2419 6868 6121 6161 1519 8024 2206 5636 5635 2208 3149 1282 1399 1912 1259 1519 2339 1728 3634 1927 1343 2339 868 511 4680 1184 2544 6727 100 5206 4991 677 4638 3173 5472 8024 712 6206 3221 4507 5226 6744 1757 7386 3146 4415 1071 800 2054 7768 1841 2206 8024 7028 3173 2904 6908 7674 1756 1350 678 3560 2527 5226 3146 5445 2768 8024 852 4412 1762 2544 6727 6291 4158 100 5543 1917 1245 818 6857 819 2339 868 511 5198 1394 1392 2157 2054 7768 1841 2206 8024 5739 5401 1060 1751 1066 3300 6818 8188 1399 1912 1259 1519 2339 1358 1168 2512 7513 511 2205 3176 6857 943 3867 2622 8024 2544 6727 1006 6134 4850 8024 519 1963 1398 2792 3300 821 3511 8024 2769 947 3298 2137 3309 6268 844 3511 1243 2658 2501 8024 6857 3300 1377 5543 808 1062 1385 1872 1217 2205 4294 2137 7526 1818 4638 2832 6536 8024 2772 5442 2206 5636 782 1519 4638 7028 3173 2128 2961 511 520 699 4067 3926 6857 763 3748 2137 699 7478 3645 1470 3176 1762 5401 1751 5487 5990 4638 3173 1094 4311 4567 3681 8020 100 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] 本 名 黃 照 岡 的 黃 琪 涉 冒 名 詐 騙 車 商 招 待 試 車 、 騙 券 商 給 優 惠 手 續 費 ， 一 審 法 院 今 天 審 酌 他 助 長 社 會 詐 欺 犯 罪 歪 風 、 否 認 犯 罪 等 ， 依 詐 欺 累 犯 等 罪 ， 判 他 1 年 2 月 徒 刑 ， 可 上 訴 。 判 決 指 出 ， 黃 琪 假 冒 銀 行 投 資 教 父 宋 學 仁 助 理 的 名 義 ， 於 民 國 105 年 7 月 間 致 電 凱 基 商 業 銀 行 董 事 長 室 ， 並 留 下 連 絡 電 話 ； 凱 基 銀 行 董 事 長 魏 寶 生 回 電 後 ， 指 示 秘 書 轉 知 凱 基 證 券 協 助 辦 理 開 戶 ， 凱 基 證 券 職 員 因 誤 認 是 貴 賓 而 同 意 給 手 續 費 優 惠 ， 黃 琪 因 股 票 交 易 ， 而 獲 得 手 續 費 價 差 的 不 法 利 益 新 台 幣 1 萬 95 ##75 元 。 判 決 指 出 ， 105 年 7 月 間 ， 黃 琪 假 冒 國 泰 集 團 千 金 蔡 佳 玲 的 名 義 ， 以 購 車 為 由 致 電 台 灣 奧 迪 汽 車 [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] 本 名 黃 照 岡 的 黃 琪 涉 冒 名 詐 騙 車 商 招 待 試 車 、 騙 券 商 給 優 惠 手 續 費 ， 一 審 法 院 今 天 審 酌 他 助 長 社 會 詐 欺 犯 罪 歪 風 、 否 認 犯 罪 等 ， 依 詐 欺 累 犯 等 罪 ， 判 他 1 年 2 月 徒 刑 ， 可 上 訴 。 判 決 指 出 ， 黃 琪 假 冒 銀 行 投 資 教 父 宋 學 仁 助 理 的 名 義 ， 於 民 國 105 年 7 月 間 致 電 凱 基 商 業 銀 行 董 事 長 室 ， 並 留 下 連 絡 電 話 ； 凱 基 銀 行 董 事 長 魏 寶 生 回 電 後 ， 指 示 秘 書 轉 知 凱 基 證 券 協 助 辦 理 開 戶 ， 凱 基 證 券 職 員 因 誤 認 是 貴 賓 而 同 意 給 手 續 費 優 惠 ， 黃 琪 因 股 票 交 易 ， 而 獲 得 手 續 費 價 差 的 不 法 利 益 新 台 幣 1 萬 95 ##75 元 。 判 決 指 出 ， 105 年 7 月 間 ， 黃 琪 假 冒 國 泰 集 團 千 金 蔡 佳 玲 的 名 義 ， 以 購 車 為 由 致 電 台 灣 奧 迪 汽 車 [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 3315 1399 7941 4212 2271 4638 7941 4427 3868 1088 1399 6266 7700 6722 1555 2875 2521 6275 6722 510 7700 1171 1555 5183 1032 2669 2797 5265 6527 8024 671 2182 3791 7368 791 1921 2182 6980 800 1221 7269 4852 3298 6266 3619 4306 5389 3639 7591 510 1415 6291 4306 5389 5023 8024 898 6266 3619 5168 4306 5023 5389 8024 1161 800 122 2399 123 3299 2530 1152 8024 1377 677 6260 511 1161 3748 2900 1139 8024 7941 4427 969 1088 7065 6121 2832 6536 3136 4266 2129 2119 785 1221 4415 4638 1399 5412 8024 3176 3696 1751 8423 2399 128 3299 7279 5636 7442 1134 1825 1555 3511 7065 6121 5869 752 7269 2147 8024 699 4522 678 6865 5181 7442 6282 8039 1134 1825 7065 6121 5869 752 7269 7794 2188 4495 1726 7442 2527 8024 2900 4850 4908 3292 6752 4761 1134 1825 6349 1171 1295 1221 6794 4415 7274 2786 8024 1134 1825 6349 1171 5480 1519 1728 6299 6291 3221 6523 6540 5445 1398 2692 5183 2797 5265 6527 1032 2669 8024 7941 4427 1728 5500 4873 769 3211 8024 5445 4363 2533 2797 5265 6527 1019 2345 4638 679 3791 1164 4660 3173 1378 2395 122 5857 8287 9183 1039 511 1161 3748 2900 1139 8024 8423 2399 128 3299 7279 8024 7941 4427 969 1088 1751 3805 7415 1757 1283 7032 5918 881 4386 4638 1399 5412 8024 809 6554 6722 4158 4507 5636 7442 1378 4124 1953 6832 3749 6722 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 3315 1399 7941 4212 2271 4638 7941 4427 3868 1088 1399 6266 7700 6722 1555 2875 2521 6275 6722 510 7700 1171 1555 5183 1032 2669 2797 5265 6527 8024 671 2182 3791 7368 791 1921 2182 6980 800 1221 7269 4852 3298 6266 3619 4306 5389 3639 7591 510 1415 6291 4306 5389 5023 8024 898 6266 3619 5168 4306 5023 5389 8024 1161 800 122 2399 123 3299 2530 1152 8024 1377 677 6260 511 1161 3748 2900 1139 8024 7941 4427 969 1088 7065 6121 2832 6536 3136 4266 2129 2119 785 1221 4415 4638 1399 5412 8024 3176 3696 1751 8423 2399 128 3299 7279 5636 7442 1134 1825 1555 3511 7065 6121 5869 752 7269 2147 8024 699 4522 678 6865 5181 7442 6282 8039 1134 1825 7065 6121 5869 752 7269 7794 2188 4495 1726 7442 2527 8024 2900 4850 4908 3292 6752 4761 1134 1825 6349 1171 1295 1221 6794 4415 7274 2786 8024 1134 1825 6349 1171 5480 1519 1728 6299 6291 3221 6523 6540 5445 1398 2692 5183 2797 5265 6527 1032 2669 8024 7941 4427 1728 5500 4873 769 3211 8024 5445 4363 2533 2797 5265 6527 1019 2345 4638 679 3791 1164 4660 3173 1378 2395 122 5857 8287 9183 1039 511 1161 3748 2900 1139 8024 8423 2399 128 3299 7279 8024 7941 4427 969 1088 1751 3805 7415 1757 1283 7032 5918 881 4386 4638 1399 5412 8024 809 6554 6722 4158 4507 5636 7442 1378 4124 1953 6832 3749 6722 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Jasonhsu\\Desktop\\esun\\bert_classfication2\\model.ckpt-1495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Jasonhsu\\Desktop\\esun\\bert_classfication2\\model.ckpt-1495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference took time  0:00:03.498000\n"
     ]
    }
   ],
   "source": [
    "pred_sentences = list(test['content'])\n",
    "test_start_time = datetime.now()\n",
    "predictions = getPrediction(pred_sentences)\n",
    "print(\"Inference took time \", datetime.now() - test_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('將近九十四萬的同意票，讓韓國瑜成為台灣自治史上首位被罷免的市長，從風光的立委到退隱政壇、從賣菜郎到藍營救世主、創下韓流奇蹟，短短一年半三次選舉，把他推向政治生命高峰也一舉跌落谷底，韓國瑜的政治人生暴起又暴落，轟轟烈烈，寫下台灣政壇傳奇。挽袖的藍襯衫、接地氣的庶民語言與肢體動作創造了「韓流」，打破綠營在港都執政20年的高牆，翻轉藍綠執政版圖，成為政壇耀眼的明星。而面臨總統大選後罷韓的明流暗湧，失去的民心有如慧星般急速隕落，失去了高雄市長的韓國瑜，政壇之路是否還有序曲？', array([-3.5404533e-05, -1.0249677e+01], dtype=float32), 0, 'non_aml')\n",
      "('在非裔美人佛洛伊德遭警方不當暴力致死後，美國福斯新聞的一個節目5日用圖表指美國非裔人士遭受暴力時，股市竟會大漲，此舉引發嘩然。福斯新聞對此事發表聲明，對未顧慮他人感受致歉。《法新社》7日報導，福斯新聞的節目「拜爾特別報導」播出一張圖表，顯示美國非裔人士受到暴力，引發社會關注後，股市呈現走高情形。圖表中顯示，在佛洛伊德喪命後，標準普爾500指數大漲3.4%、民權領袖馬丁・路德・金恩遇刺後，標普500上漲2.9%、涉毆打非裔青年金恩的警察被無罪釋放，以及非裔少年布朗遭警方擊斃後，標普500的漲幅都是1.2%。伊利諾伊州聯邦眾議員拉什針對福斯新聞的行為甚為不滿，他痛批 :「這張圖表清楚地表明，福斯新聞並不在乎黑人的性命。」共和黨全國委員會前主席斯蒂爾也在推特上發文 :「這就是福斯新聞悼念黑人死亡的方式——用股市上漲多少來呈現。」福斯新聞6日晚間發表聲明表示，引發爭議的圖表原本是用來說明市場對歷史性時刻如何反應，不應該在沒有完整脈絡的情況下在電視上播出。福斯新聞說 :「我們對這張圖表未顧及他人感受致歉，並認真看待此事。」', array([-4.577532e-05, -9.992626e+00], dtype=float32), 0, 'non_aml')\n",
      "('高雄市議長許崑源昨晚近9時，從住家17樓墜樓身亡，由於墜樓原因不明，引起各界議論紛紛。家屬今天發表3點聲明，呼籲各界不要以訛傳訛，尊重往生者為大，家屬對不實言論將保留法律追訴權。市議員宋立彬代表許崑源家屬，發布三點聲明，首先家屬對外界的關切表達感謝，但針對部分媒體不實報導與網路傳言表示譴責，強調均為子虛烏有，請勿以訛傳訛，家屬將保留法律追訴權。「請勿再消費許崑源，並請尊重往生者為大」，高雄市議會將籌組治喪委員會，全力協助家屬處理後。許崑源住家出事地點，今早有不少民眾前往現場獻花並點燭光表示追悼，受訪民眾說，得知許崑源意外身亡心裡很難過、很捨不得、一夜沒睡，許崑源是很有義氣的人，很喜歡幫助別人，稍晚也會去殯儀館致意。', array([-3.8742270e-05, -1.0159835e+01], dtype=float32), 0, 'non_aml')\n",
      "('AI搶走人類飯碗的橋段，如今在微軟裡真實上演。這間科技巨頭近期決定以AI取代MSN網站的新聞編輯團隊，預計將在6月底進行裁員，導致至少數十名外包員工因此失去工作。目前微軟MSN網站上的新聞，主要是由編輯團隊整理其他媒體報導，重新挑選首圖及下標後編整而成，但現在微軟認為AI能夠勝任這份工作。綜合各家媒體報導，英美兩國共有近80名外包員工受到影響。對於這個消息，微軟僅表示，「如同所有企業，我們會定期評估業務情形，這有可能令公司增加對特定領域的投資，或者導致人員的重新安排。」並澄清這些決定並非歸咎於在美國肆虐的新冠狀病毒（COVID-19，俗稱武漢肺炎）疫情。有員工在得知裁員消息後自嘲，「我花了大量時間閱讀關於AI及自動化取代工作的新聞，而現在AI就在這裡搶走了我的工作。」', array([-3.7311813e-05, -1.0196099e+01], dtype=float32), 0, 'non_aml')\n",
      "('本名黃照岡的黃琪涉冒名詐騙車商招待試車、騙券商給優惠手續費，一審法院今天審酌他助長社會詐欺犯罪歪風、否認犯罪等，依詐欺累犯等罪，判他1年2月徒刑，可上訴。判決指出，黃琪假冒銀行投資教父宋學仁助理的名義，於民國105年7月間致電凱基商業銀行董事長室，並留下連絡電話；凱基銀行董事長魏寶生回電後，指示秘書轉知凱基證券協助辦理開戶，凱基證券職員因誤認是貴賓而同意給手續費優惠，黃琪因股票交易，而獲得手續費價差的不法利益新台幣1萬9575元。判決指出，105年7月間，黃琪假冒國泰集團千金蔡佳玲的名義，以購車為由致電台灣奧迪汽車公司，要求安排「Audi A8」車款試乘，並以電子信箱寄件人「國泰金控-Fendi Tsai」，寄信給奧迪公司行銷處長聯繫購車事宜，使對方誤認是蔡女本人，因此轉知經銷商（太古國際汽車公司）經理協助提供貴賓購車及試車服務。判決指出，太古公司職員在105年8月1日晚間8時許提供「Audi A8」車款給黃琪使用，直至同年月12日下午5時才把車子歸還，因而獲得無償使用車輛共計10天20小時的不法利益2萬5590元。此外，黃琪為承租新北市板橋區的房屋，未經周姓前男友同意，於105年8月間，擅自冒用周男名義，在房屋租賃契約書簽名，再交付房東。一審台北地院合議庭審酌，黃琪犯行過程等為社會不良示範，助長社會詐欺犯罪歪風，危害正常交易秩序，不宜輕縱，且黃琪犯後否認犯行，辯稱凱基證券、奧迪公司未受到任何損害等語，在審理程序中還提出偽造的授權書企圖脫罪，沒有任何反省。合議庭認定，黃琪構成2個詐欺罪，5年內再犯罪，為累犯加重其刑，判他應執行1年2月徒刑，不法利益4萬5165元追繳沒收；另構成偽造文書罪，判刑4月，得易科罰金，全案可上訴。（編輯：李亨山）1090519', array([-8.774424e+00, -1.546025e-04], dtype=float32), 1, 'aml')\n",
      "('台中地檢署在2017年，偵辦位於歐洲小國拉脫維亞內，由台灣人組成的3個跨境詐欺集團機房，將110人台灣騙徒押解回台受審，歷經2年餘，中檢順藤摸瓜，查獲3機房的幕後藏鏡人（老闆、金主），竟是擁有藍寶堅尼跑車、9戶豪宅預購屋的男子黃重嘉，他與弟弟、妹妹全都是騙徒，另一金主則是經營無二洋蔥紅酒，以擁有勞斯萊斯座車聞名台中市，還將勞斯萊斯車禍理賠金捐出賑災的「大善人」朱振岳，他還派人到看守所會見羈押的手下，警告施壓手下不要供出朱男，中檢今天依加重詐欺罪、組織犯罪防制條例，將兩人與手下幹部共11人起訴。起訴書指出，中檢與刑事警察局在2017年，發現一群台灣人，跑到波羅的海三小國之一的拉脫維亞，設置2個詐欺機房，跨國向中國、澳門人詐騙，從2017年3月至8月，不到半年時間，不法所得共達近3億元台幣，吸引具黑道背景，剛結束匈牙利詐欺機房的劉姓男子與陳姓男子的興趣，2人在該國成立第3個詐欺機房，中檢於當年8月間，將3機房的110名台灣人押解回台灣受審，一審全部判決有罪，劉、陳兩人還重判13年，並宣告強制工作3年。檢察官黃嘉生說，檢方認為這110人之外，還有在拉脫維亞警方動手拘捕前，就先回台灣的幹部，以及幕後藏鏡人（金主、老闆），在台灣尚未緝獲，遂由取回的證據，以及被羈押等候受審的騙徒口中，終於查出這2處機房，幕後主使者是34歲的黃重嘉（羈押中），以及外號「象董」、「象哥」，經營無二洋蔥紅酒的42歲男子朱振岳（在逃），朱男是中市名人，其勞斯萊斯座車曾在中市發生車禍而轟動一時，他把車禍賠償金捐出，在2017年捐出，救濟莫蘭蒂颱風的受災戶，被稱之為「大善人」。另檢察官吃驚的是，黃重嘉得知拉脫維亞的機房被查獲，他擔心手上的贓款，也會被檢警扣押，趕緊向建商，買9戶「雙橡園」豪宅預售屋，預售屋比較便宜，當時總價是1億8946萬元，並已繳款3216萬元，但並非登記自己名下，而是登記於幹部的胞姊或胞妹等人名下，這9戶預售屋都已被中檢查扣，中檢還查扣他名下的藍寶堅尼跑車，拍賣得款1200萬元，黃男事發後潛逃到菲律賓，因護照被註銷，菲律賓警方逮捕他，將他遣返台灣後，法院裁定羈押。至於另一機房，中檢發現藏鏡人是「大善人」朱振岳，但他屢傳不到，檢方發現，他的手下騙徒，從拉脫維亞被遣返台灣，羈押於看守所，朱男竟派人到看守所會面，警告被羈押的手下，「不要再有後續動作（供詞），如果還是這樣說（指說出案情內幕），未來出來（出獄），路也不好走」，中檢認定他威脅共犯，更顯示他是幕後金主。中檢今天將上述兩人，依加重詐欺罪與組織犯罪防制條例起訴，另一併起訴的人，是兩機房的漏網之魚，包括黃男的手下幹部、弟弟黃軒樺（29歲）等3人，以及朱男的手下幹部6人，總計11人。', array([-9.295708e+00, -9.178694e-05], dtype=float32), 1, 'aml')\n",
      "('反洗錢傳統上是立足于金融係統對犯罪分子掩飾、隱瞞犯罪所得進行預防和打擊的工作體係，但隨著國際國內形勢的發展，反洗錢已經超出了預防和打擊洗錢犯罪的范疇，在完善國家治理、維護金融安全和促進改革開放中發揮著日益重要的作用。中央全面深化改革領導小組第三十四次會議審議通過《關于完善反洗錢、反恐怖融資、反逃稅監管體制機制的意見》（以下簡稱《三反意見》），明確指出反洗錢是建設中國特色社會主義法治體係和現代金融監管體係的重要內容，是推進國家治理體係和治理能力現代化、維護經濟社會安全穩定的重要保障，是參與全球治理體係、擴大金融業雙向開放的重要手段。自2007年《反洗錢法》實施以來，我國反洗錢制度體係建設取得重要進展，工作成效明顯，與國際通行標準基本保持一致。但同時也要看到，相關領域仍然存在一些突出矛盾和問題，主要是法律制度尚不夠完善、協調合作機制仍不夠順暢、打擊洗錢犯罪尚不夠有力、反洗錢義務機構履職能力不足等，需要我們不斷加強反洗錢制度體係建設，推進我國反洗錢事業向縱深發展。', array([-4.8636208e-05, -9.9319611e+00], dtype=float32), 0, 'non_aml')\n",
      "(\"前國際田徑總會(IAAF)主席狄亞克(Lamine Diack)8日將在法國巴黎受審。狄亞克被控在俄羅斯禁藥醜聞中，收受賄賂以及洗錢。檢察官指出，狄亞克向使用禁藥的運動員索賄345萬歐元(約389萬美元)，掩護他們可以繼續參加比賽，包括2012年的倫敦奧運。在7日過87歲生日的狄亞克否認不法。律師則表示，對狄亞克的指控毫無根據。狄亞克在1999年至2015年間擔任IAAF主席。IAAF已經改名為「世界田徑總會」(World Athletics)。來自塞內加爾的狄亞克曾是體育界最具影響力的人之一，目前在巴黎接受軟禁，如果被定罪，恐怕將面臨最高10年徒刑。狄亞克案的審判原定今年1月展開，但因為他的兒子、也是同案被告馬薩塔(Massata Diack)提出新證詞而延後。塞內加爾政府拒絕引渡馬薩塔。曾擔任IAAF行銷顧問的馬薩塔也被控洗錢、貪污、背信，將遭到缺席審判。此案的被告還包括狄亞克在IAAF的律師席斯(Habib Cisse)、主管IAAF禁藥檢測的多勒(Gabriel Dolle)，以及俄羅斯體育協會主席巴拉尼特契夫(Valentin Balakhnitchev)，以及俄羅斯田徑教練麥尼可夫(Alexei Melnikov)。他們都被控在當時隱瞞使用禁藥的醜聞。法國國家金融檢察署(French National Financial Prosecutor's Office，PNF)調查人員形容，在狄亞克的領導下，世界田徑界已形成一個貪污網絡。另外，狄亞克還有另案在身。他被控巴西的賄賂，以協助里約熱內盧(Rio de Janeiro)獲選為2016年奧運主辦城市。\", array([-6.1350856e+00, -2.1678535e-03], dtype=float32), 1, 'aml')\n",
      "('提到內衣品牌，Victoria’s Secret（維多利亞的秘密）一定無人不知，據BBC報導，受新型冠狀病毒疫情影響，維多利亞的秘密英國分部，近日宣布破產，進入破產管理程序。不過Victoria’s Secret沒落其實已早有先兆。Victoria’s Secret在英國的20多家店鋪面臨關閉的困境，所有維秘中層、基層員工下崗失業，高層試圖尋找新買家，向商舖業主尋求協商租金。同時在北美近20間旗艦店店鋪都處於休業狀態，看來難逃結業命運。不過，除了疫情影響，其實Victoria’s Secret的醜聞早已令品牌名聲跌到谷底，去年的內衣騷也停辦了。Victoria’s Secret每年舉辦的「維密騷」更是時尚界最受期待的年度節目之一，把内衣騷變成年度盛宴。「天使」們紛紛換上最新內衣系列，展現美好身材，再請來一群當紅明星演唱，表面風光，遮蓋的真相卻很醜陋。「維秘天使」有著天使面孔、魔鬼身材的她們可能是很多女生的羨慕對象，可是她們卻活在「地獄」。包括多位前維秘模特在內，今年年頭有超過100名模特聯合署名公開信，這封信由模特聯盟和反性侵活動聯盟 Time’s Up 合作簽署，她們鼓氣勇氣的原因是紐約時報的一篇揭露報導《天使在地獄》。根據對維秘 30 多名現任和前任高層、員工、承包商和模特的採訪，再加上部分公開披露的法庭文件，紐約時報發現在維秘內部，兩名有權勢的人主導了一種根深蒂固的厭女症、欺凌和騷擾文化。其中 Ed Razek 曾試圖親吻模特，讓她們坐在他腿上。在 2018 年大秀之前，他甚至摸向了某名模特的胯部。他曾對模特兒們說：「作為時尚帝國的掌權者，我可以把你捧上神壇，也能讓你重重跌落。」但許多模特不敢作聲因為會面臨報復，前模特 Andi Muise 在2007年拒絕了 Razek 的示好後，近十幾年再也沒有機會走上維秘的 T 台。再加上老闆 Wexner 也曾多次發表貶低女性的言論，令人咋舌。', array([-3.7907834e-05, -1.0180010e+01], dtype=float32), 0, 'non_aml')\n",
      "('全美大學錄取舞弊案最後一名家長日前認罪，來自賓州安布勒(Ambler)的一名生物企業前CEO，2017年用5萬元賄賂喬治城大學(Georgetown University)的網球教練，使其女兒被列入招生目標，順利進入該校。61歲的Robert Repella是生物企業Harmony Biosciences的前首席執行官，他通過視頻會議向聯邦法官Allison Burroughs認罪，稱所有罪行都由其一人承擔，他的女兒對此並不知情，「我對自己的行為承擔所有責任；我的家人，尤其是我的女兒對此毫不知情。」他的代理律師Robert A. Fisher表示，Repella的女兒不像其他賄賂受益者，她本身就是一名在全美有排名的高中網球運動員，並在大一時加入校隊，此後因更換專業而退出。大學調查也顯示，該學生符合該校的學術和運動招生標準。受賄教練Gordon Ernst在2017年因隊員招募過程備受質疑而被迫辭職，他去年遭到受賄指控。Repella則是全美大學錄取舞弊案第55名被告，也是這起影響力廣泛案件中最後一名認罪的家長；他面臨10個月監禁和4萬元罰金。聯邦司法部去年3月宣布偵破美國最大規模的大學錄取舞弊案，對超過50名大學教練及富有的家長控罪，通過權錢交易使子女進入包括史丹福、耶魯等名校；一個中國家庭甚至付出650萬元換取女兒進入耶魯大學。', array([-4.9501843 , -0.00710733], dtype=float32), 1, 'aml')\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(predictions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 2428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 2428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: news_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: news_id\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] 熱 搜 ： 熱 門 行 情 最 近 搜 尋 基 金 老 司 機 ◆ 盤 勢 分 析 其 實 大 多 數 的 人 都 猜 的 到 ， 川 習 會 不 會 有 什 麼 事 情 。 大 國 之 間 的 交 手 都 是 這 樣 的 ， 或 是 說 大 國 之 間 做 事 情 是 會 給 對 方 留 餘 地 的 ， 不 會 讓 人 沒 了 面 子 又 沒 了 裡 子 ， 所 以 大 多 數 的 人 也 能 猜 到 川 習 會 不 會 有 事 。 差 別 只 在 於 如 果 你 是 個 體 投 資 人 ， 你 可 以 冒 險 或 說 勇 於 在 會 前 下 單 卡 位 ， 但 如 果 你 是 操 盤 人 、 分 析 師 ， 那 麼 可 能 就 得 多 考 慮 一 點 風 險 ， 如 此 而 已 。 但 就 長 線 而 言 ， 本 來 就 應 該 持 續 看 多 才 對 。 筆 者 之 前 已 說 過 ， 美 元 有 做 頭 疑 慮 ， 歐 洲 可 能 降 息 、 亞 洲 也 不 升 息 ， 那 麼 美 元 的 強 就 會 顯 得 明 顯 。 如 此 一 來 怎 麼 對 美 國 有 利 ？ 特 別 是 川 普 大 [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] 熱 搜 ： 熱 門 行 情 最 近 搜 尋 基 金 老 司 機 ◆ 盤 勢 分 析 其 實 大 多 數 的 人 都 猜 的 到 ， 川 習 會 不 會 有 什 麼 事 情 。 大 國 之 間 的 交 手 都 是 這 樣 的 ， 或 是 說 大 國 之 間 做 事 情 是 會 給 對 方 留 餘 地 的 ， 不 會 讓 人 沒 了 面 子 又 沒 了 裡 子 ， 所 以 大 多 數 的 人 也 能 猜 到 川 習 會 不 會 有 事 。 差 別 只 在 於 如 果 你 是 個 體 投 資 人 ， 你 可 以 冒 險 或 說 勇 於 在 會 前 下 單 卡 位 ， 但 如 果 你 是 操 盤 人 、 分 析 師 ， 那 麼 可 能 就 得 多 考 慮 一 點 風 險 ， 如 此 而 已 。 但 就 長 線 而 言 ， 本 來 就 應 該 持 續 看 多 才 對 。 筆 者 之 前 已 說 過 ， 美 元 有 做 頭 疑 慮 ， 歐 洲 可 能 降 息 、 亞 洲 也 不 升 息 ， 那 麼 美 元 的 強 就 會 顯 得 明 顯 。 如 此 一 來 怎 麼 對 美 國 有 利 ？ 特 別 是 川 普 大 [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 4229 3017 8038 4229 7271 6121 2658 3297 6818 3017 2204 1825 7032 5439 1385 3582 470 4676 1248 1146 3358 1071 2179 1920 1914 3149 4638 782 6963 4339 4638 1168 8024 2335 5424 3298 679 3298 3300 784 7938 752 2658 511 1920 1751 722 7279 4638 769 2797 6963 3221 6857 3564 4638 8024 2772 3221 6303 1920 1751 722 7279 976 752 2658 3221 3298 5183 2205 3175 4522 7626 1765 4638 8024 679 3298 6366 782 3760 749 7481 2094 1348 3760 749 6174 2094 8024 2792 809 1920 1914 3149 4638 782 738 5543 4339 1168 2335 5424 3298 679 3298 3300 752 511 2345 1162 1372 1762 3176 1963 3362 872 3221 943 7768 2832 6536 782 8024 872 1377 809 1088 7402 2772 6303 1235 3176 1762 3298 1184 678 1606 1305 855 8024 852 1963 3362 872 3221 3082 4676 782 510 1146 3358 2374 8024 6929 7938 1377 5543 2218 2533 1914 5440 2719 671 7953 7591 7402 8024 1963 3634 5445 2347 511 852 2218 7269 5221 5445 6241 8024 3315 889 2218 2746 6283 2898 5265 4692 1914 2798 2205 511 5022 5442 722 1184 2347 6303 6882 8024 5401 1039 3300 976 7531 4542 2719 8024 3627 3828 1377 5543 7360 2622 510 765 3828 738 679 1285 2622 8024 6929 7938 5401 1039 4638 2485 2218 3298 7549 2533 3209 7549 511 1963 3634 671 889 2582 7938 2205 5401 1751 3300 1164 8043 4294 1162 3221 2335 3249 1920 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 4229 3017 8038 4229 7271 6121 2658 3297 6818 3017 2204 1825 7032 5439 1385 3582 470 4676 1248 1146 3358 1071 2179 1920 1914 3149 4638 782 6963 4339 4638 1168 8024 2335 5424 3298 679 3298 3300 784 7938 752 2658 511 1920 1751 722 7279 4638 769 2797 6963 3221 6857 3564 4638 8024 2772 3221 6303 1920 1751 722 7279 976 752 2658 3221 3298 5183 2205 3175 4522 7626 1765 4638 8024 679 3298 6366 782 3760 749 7481 2094 1348 3760 749 6174 2094 8024 2792 809 1920 1914 3149 4638 782 738 5543 4339 1168 2335 5424 3298 679 3298 3300 752 511 2345 1162 1372 1762 3176 1963 3362 872 3221 943 7768 2832 6536 782 8024 872 1377 809 1088 7402 2772 6303 1235 3176 1762 3298 1184 678 1606 1305 855 8024 852 1963 3362 872 3221 3082 4676 782 510 1146 3358 2374 8024 6929 7938 1377 5543 2218 2533 1914 5440 2719 671 7953 7591 7402 8024 1963 3634 5445 2347 511 852 2218 7269 5221 5445 6241 8024 3315 889 2218 2746 6283 2898 5265 4692 1914 2798 2205 511 5022 5442 722 1184 2347 6303 6882 8024 5401 1039 3300 976 7531 4542 2719 8024 3627 3828 1377 5543 7360 2622 510 765 3828 738 679 1285 2622 8024 6929 7938 5401 1039 4638 2485 2218 3298 7549 2533 3209 7549 511 1963 3634 671 889 2582 7938 2205 5401 1751 3300 1164 8043 4294 1162 3221 2335 3249 1920 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: news_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: news_id\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] 半 導 體 通 路 商 安 馳 （ 352 ##8 ） 昨 （ 16 ） 日 宣 布 ， 接 獲 日 商 [UNK] 旗 下 駿 日 通 知 ， 所 提 公 開 收 購 期 間 已 於 15 日 屆 滿 ， 實 際 成 交 約 3 . 27 萬 張 。 依 照 安 馳 目 前 股 本 來 計 算 ， 駿 日 砸 下 13 . 44 億 元 ， 拿 下 五 成 股 權 。 據 了 解 ， 安 馳 在 駿 日 入 主 之 後 ， 應 會 繼 續 維 持 在 台 灣 資 本 市 場 掛 牌 。 安 馳 董 事 會 今 年 剛 完 成 改 選 四 席 董 事 與 三 席 獨 董 ， 日 前 二 名 獨 董 與 二 名 董 事 請 辭 ， 已 擬 於 10 月 初 召 開 股 臨 會 以 補 選 董 事 。 外 界 預 期 ， 在 駿 日 成 為 安 馳 最 大 股 東 之 後 ， 應 可 取 得 一 定 董 事 席 次 。 駿 日 今 年 5 月 初 通 知 對 安 馳 展 開 公 開 收 購 ， 每 股 收 購 價 格 為 41 元 ， 預 計 最 低 收 購 35 ％ 股 權 ， 最 高 達 五 成 股 權 。 原 定 公 開 收 購 [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] 半 導 體 通 路 商 安 馳 （ 352 ##8 ） 昨 （ 16 ） 日 宣 布 ， 接 獲 日 商 [UNK] 旗 下 駿 日 通 知 ， 所 提 公 開 收 購 期 間 已 於 15 日 屆 滿 ， 實 際 成 交 約 3 . 27 萬 張 。 依 照 安 馳 目 前 股 本 來 計 算 ， 駿 日 砸 下 13 . 44 億 元 ， 拿 下 五 成 股 權 。 據 了 解 ， 安 馳 在 駿 日 入 主 之 後 ， 應 會 繼 續 維 持 在 台 灣 資 本 市 場 掛 牌 。 安 馳 董 事 會 今 年 剛 完 成 改 選 四 席 董 事 與 三 席 獨 董 ， 日 前 二 名 獨 董 與 二 名 董 事 請 辭 ， 已 擬 於 10 月 初 召 開 股 臨 會 以 補 選 董 事 。 外 界 預 期 ， 在 駿 日 成 為 安 馳 最 大 股 東 之 後 ， 應 可 取 得 一 定 董 事 席 次 。 駿 日 今 年 5 月 初 通 知 對 安 馳 展 開 公 開 收 購 ， 每 股 收 購 價 格 為 41 元 ， 預 計 最 低 收 購 35 ％ 股 權 ， 最 高 達 五 成 股 權 。 原 定 公 開 收 購 [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1288 2206 7768 6858 6662 1555 2128 7682 8020 12091 8156 8021 3219 8020 8121 8021 3189 2146 2357 8024 2970 4363 3189 1555 100 3186 678 7695 3189 6858 4761 8024 2792 2990 1062 7274 3119 6554 3309 7279 2347 3176 8115 3189 2234 4021 8024 2179 7396 2768 769 5147 124 119 8149 5857 2484 511 898 4212 2128 7682 4680 1184 5500 3315 889 6243 5050 8024 7695 3189 4790 678 8124 119 8252 1023 1039 8024 2897 678 758 2768 5500 3609 511 3087 749 6237 8024 2128 7682 1762 7695 3189 1057 712 722 2527 8024 2746 3298 5262 5265 5204 2898 1762 1378 4124 6536 3315 2356 1842 2965 4277 511 2128 7682 5869 752 3298 791 2399 1190 2130 2768 3121 6908 1724 2375 5869 752 5645 676 2375 4360 5869 8024 3189 1184 753 1399 4360 5869 5645 753 1399 5869 752 6313 6798 8024 2347 3093 3176 8108 3299 1159 1374 7274 5500 5631 3298 809 6171 6908 5869 752 511 1912 4518 7521 3309 8024 1762 7695 3189 2768 4158 2128 7682 3297 1920 5500 3346 722 2527 8024 2746 1377 1357 2533 671 2137 5869 752 2375 3613 511 7695 3189 791 2399 126 3299 1159 6858 4761 2205 2128 7682 2245 7274 1062 7274 3119 6554 8024 3680 5500 3119 6554 1019 3419 4158 8245 1039 8024 7521 6243 3297 856 3119 6554 8198 8017 5500 3609 8024 3297 7770 6888 758 2768 5500 3609 511 1333 2137 1062 7274 3119 6554 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1288 2206 7768 6858 6662 1555 2128 7682 8020 12091 8156 8021 3219 8020 8121 8021 3189 2146 2357 8024 2970 4363 3189 1555 100 3186 678 7695 3189 6858 4761 8024 2792 2990 1062 7274 3119 6554 3309 7279 2347 3176 8115 3189 2234 4021 8024 2179 7396 2768 769 5147 124 119 8149 5857 2484 511 898 4212 2128 7682 4680 1184 5500 3315 889 6243 5050 8024 7695 3189 4790 678 8124 119 8252 1023 1039 8024 2897 678 758 2768 5500 3609 511 3087 749 6237 8024 2128 7682 1762 7695 3189 1057 712 722 2527 8024 2746 3298 5262 5265 5204 2898 1762 1378 4124 6536 3315 2356 1842 2965 4277 511 2128 7682 5869 752 3298 791 2399 1190 2130 2768 3121 6908 1724 2375 5869 752 5645 676 2375 4360 5869 8024 3189 1184 753 1399 4360 5869 5645 753 1399 5869 752 6313 6798 8024 2347 3093 3176 8108 3299 1159 1374 7274 5500 5631 3298 809 6171 6908 5869 752 511 1912 4518 7521 3309 8024 1762 7695 3189 2768 4158 2128 7682 3297 1920 5500 3346 722 2527 8024 2746 1377 1357 2533 671 2137 5869 752 2375 3613 511 7695 3189 791 2399 126 3299 1159 6858 4761 2205 2128 7682 2245 7274 1062 7274 3119 6554 8024 3680 5500 3119 6554 1019 3419 4158 8245 1039 8024 7521 6243 3297 856 3119 6554 8198 8017 5500 3609 8024 3297 7770 6888 758 2768 5500 3609 511 1333 2137 1062 7274 3119 6554 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: news_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: news_id\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] [UNK] _ show ( [UNK] . [UNK] . [UNK] . [UNK] ( ' content _ master ##head ' , [UNK] . [UNK] . [UNK] ( ) , [UNK] . [UNK] . [UNK] ( ) , [UNK] . [UNK] . [UNK] ( ) ) ) ; 東 網 電 視 救 援 人 員 在 場 協 助 。 （ 中 時 電 子 報 圖 片 ） 南 投 縣 南 投 市 南 崗 工 業 區 環 偉 公 司 周 四 （ 10 日 ） 下 午 發 生 工 業 安 全 事 故 ， 3 名 男 工 人 在 吊 臂 車 上 搭 建 鐵 架 時 ， 不 慎 從 20 多 米 高 處 墮 下 身 亡 ， 其 中 一 人 頭 顱 爆 開 ， 腦 漿 散 滿 一 地 。 南 投 縣 消 防 局 接 獲 報 案 後 ， 立 即 派 遣 3 個 消 防 分 隊 前 往 救 援 ， 其 中 55 歲 及 約 63 歲 的 傷 者 ， 送 院 後 宣 告 不 治 ， 另 1 名 工 人 當 場 身 亡 。 消 防 局 表 示 ， 現 場 疑 似 吊 車 勾 到 天 車 ， 導 致 3 名 工 人 從 高 處 墮 下 。 3 名 死 者 都 是 彰 化 縣 民 眾 ， 並 非 外 籍 移 工 。 南 投 縣 社 會 [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] [UNK] _ show ( [UNK] . [UNK] . [UNK] . [UNK] ( ' content _ master ##head ' , [UNK] . [UNK] . [UNK] ( ) , [UNK] . [UNK] . [UNK] ( ) , [UNK] . [UNK] . [UNK] ( ) ) ) ; 東 網 電 視 救 援 人 員 在 場 協 助 。 （ 中 時 電 子 報 圖 片 ） 南 投 縣 南 投 市 南 崗 工 業 區 環 偉 公 司 周 四 （ 10 日 ） 下 午 發 生 工 業 安 全 事 故 ， 3 名 男 工 人 在 吊 臂 車 上 搭 建 鐵 架 時 ， 不 慎 從 20 多 米 高 處 墮 下 身 亡 ， 其 中 一 人 頭 顱 爆 開 ， 腦 漿 散 滿 一 地 。 南 投 縣 消 防 局 接 獲 報 案 後 ， 立 即 派 遣 3 個 消 防 分 隊 前 往 救 援 ， 其 中 55 歲 及 約 63 歲 的 傷 者 ， 送 院 後 宣 告 不 治 ， 另 1 名 工 人 當 場 身 亡 。 消 防 局 表 示 ， 現 場 疑 似 吊 車 勾 到 天 車 ， 導 致 3 名 工 人 從 高 處 墮 下 。 3 名 死 者 都 是 彰 化 縣 民 眾 ， 並 非 外 籍 移 工 。 南 投 縣 社 會 [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 100 142 8658 113 100 119 100 119 100 119 100 113 112 9432 142 9261 11795 112 117 100 119 100 119 100 113 114 117 100 119 100 119 100 113 114 117 100 119 100 119 100 113 114 114 114 132 3346 5206 7442 6213 3131 3001 782 1519 1762 1842 1295 1221 511 8020 704 3229 7442 2094 1841 1756 4275 8021 1298 2832 5238 1298 2832 2356 1298 2305 2339 3511 1281 4472 971 1062 1385 1453 1724 8020 8108 3189 8021 678 1286 4634 4495 2339 3511 2128 1059 752 3125 8024 124 1399 4511 2339 782 1762 1396 5619 6722 677 3022 2456 7136 3373 3229 8024 679 2708 2537 8113 1914 5101 7770 5993 1876 678 6716 767 8024 1071 704 671 782 7531 7550 4255 7274 8024 5582 4043 3141 4021 671 1765 511 1298 2832 5238 3867 7344 2229 2970 4363 1841 3428 2527 8024 4989 1315 3836 6897 124 943 3867 7344 1146 7386 1184 2518 3131 3001 8024 1071 704 8222 3641 1350 5147 8381 3641 4638 1003 5442 8024 6843 7368 2527 2146 1440 679 3780 8024 1369 122 1399 2339 782 4534 1842 6716 767 511 3867 7344 2229 6134 4850 8024 4412 1842 4542 849 1396 6722 1256 1168 1921 6722 8024 2206 5636 124 1399 2339 782 2537 7770 5993 1876 678 511 124 1399 3647 5442 6963 3221 2511 1265 5238 3696 4707 8024 699 7478 1912 5093 4919 2339 511 1298 2832 5238 4852 3298 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 100 142 8658 113 100 119 100 119 100 119 100 113 112 9432 142 9261 11795 112 117 100 119 100 119 100 113 114 117 100 119 100 119 100 113 114 117 100 119 100 119 100 113 114 114 114 132 3346 5206 7442 6213 3131 3001 782 1519 1762 1842 1295 1221 511 8020 704 3229 7442 2094 1841 1756 4275 8021 1298 2832 5238 1298 2832 2356 1298 2305 2339 3511 1281 4472 971 1062 1385 1453 1724 8020 8108 3189 8021 678 1286 4634 4495 2339 3511 2128 1059 752 3125 8024 124 1399 4511 2339 782 1762 1396 5619 6722 677 3022 2456 7136 3373 3229 8024 679 2708 2537 8113 1914 5101 7770 5993 1876 678 6716 767 8024 1071 704 671 782 7531 7550 4255 7274 8024 5582 4043 3141 4021 671 1765 511 1298 2832 5238 3867 7344 2229 2970 4363 1841 3428 2527 8024 4989 1315 3836 6897 124 943 3867 7344 1146 7386 1184 2518 3131 3001 8024 1071 704 8222 3641 1350 5147 8381 3641 4638 1003 5442 8024 6843 7368 2527 2146 1440 679 3780 8024 1369 122 1399 2339 782 4534 1842 6716 767 511 3867 7344 2229 6134 4850 8024 4412 1842 4542 849 1396 6722 1256 1168 1921 6722 8024 2206 5636 124 1399 2339 782 2537 7770 5993 1876 678 511 124 1399 3647 5442 6963 3221 2511 1265 5238 3696 4707 8024 699 7478 1912 5093 4919 2339 511 1298 2832 5238 4852 3298 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: news_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: news_id\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] 為 達 最 佳 瀏 覽 效 果 ， 建 議 使 用 [UNK] 、 [UNK] 或 [UNK] [UNK] 的 瀏 覽 器 。 爆 男 子 謊 稱 集 資 投 資 可 獲 報 酬 ， 卻 到 澳 門 賭 場 賠 光 金 錢 ， 彰 化 地 院 依 違 反 銀 行 法 ， 判 處 男 子 有 期 徒 刑 4 年 。 （ 資 料 照 ， 記 者 陳 冠 備 攝 ） 〔 記 者 陳 冠 備 ／ 彰 化 報 導 〕 男 子 章 世 坦 經 常 出 沒 羽 球 場 ， 向 球 友 們 吹 噓 他 有 專 業 投 資 團 隊 可 操 作 金 融 工 具 獲 利 ， 每 月 能 給 予 4 % ～10 ％ 的 報 酬 ， 李 姓 球 友 不 疑 有 他 ， 先 提 供 30 萬 元 給 章 男 進 行 投 資 ， 並 說 服 李 父 等 人 集 資 250 萬 元 投 資 ， 但 章 男 拿 錢 後 卻 到 澳 門 賭 博 ， 導 致 資 金 賠 光 光 。 彰 化 地 院 審 理 認 為 ， 章 男 向 不 特 定 多 數 人 收 受 款 項 ， 並 約 定 返 還 本 金 等 行 為 ， 依 違 犯 銀 行 法 收 受 銀 行 業 務 罪 ， 判 處 [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] 為 達 最 佳 瀏 覽 效 果 ， 建 議 使 用 [UNK] 、 [UNK] 或 [UNK] [UNK] 的 瀏 覽 器 。 爆 男 子 謊 稱 集 資 投 資 可 獲 報 酬 ， 卻 到 澳 門 賭 場 賠 光 金 錢 ， 彰 化 地 院 依 違 反 銀 行 法 ， 判 處 男 子 有 期 徒 刑 4 年 。 （ 資 料 照 ， 記 者 陳 冠 備 攝 ） 〔 記 者 陳 冠 備 ／ 彰 化 報 導 〕 男 子 章 世 坦 經 常 出 沒 羽 球 場 ， 向 球 友 們 吹 噓 他 有 專 業 投 資 團 隊 可 操 作 金 融 工 具 獲 利 ， 每 月 能 給 予 4 % ～10 ％ 的 報 酬 ， 李 姓 球 友 不 疑 有 他 ， 先 提 供 30 萬 元 給 章 男 進 行 投 資 ， 並 說 服 李 父 等 人 集 資 250 萬 元 投 資 ， 但 章 男 拿 錢 後 卻 到 澳 門 賭 博 ， 導 致 資 金 賠 光 光 。 彰 化 地 院 審 理 認 為 ， 章 男 向 不 特 定 多 數 人 收 受 款 項 ， 並 約 定 返 還 本 金 等 行 為 ， 依 違 犯 銀 行 法 收 受 銀 行 業 務 罪 ， 判 處 [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 4158 6888 3297 881 4104 6222 3126 3362 8024 2456 6359 886 4500 100 510 100 2772 100 100 4638 4104 6222 1690 511 4255 4511 2094 6335 4935 7415 6536 2832 6536 1377 4363 1841 6992 8024 1320 1168 4078 7271 6551 1842 6543 1045 7032 7092 8024 2511 1265 1765 7368 898 6889 1353 7065 6121 3791 8024 1161 5993 4511 2094 3300 3309 2530 1152 125 2399 511 8020 6536 3160 4212 8024 6250 5442 7376 1094 991 3109 8021 526 6250 5442 7376 1094 991 8027 2511 1265 1841 2206 527 4511 2094 4995 686 1788 5195 2382 1139 3760 5417 4413 1842 8024 1403 4413 1351 947 1430 1682 800 3300 2201 3511 2832 6536 1757 7386 1377 3082 868 7032 6084 2339 1072 4363 1164 8024 3680 3299 5543 5183 750 125 110 11115 8017 4638 1841 6992 8024 3330 1998 4413 1351 679 4542 3300 800 8024 1044 2990 897 8114 5857 1039 5183 4995 4511 6868 6121 2832 6536 8024 699 6303 3302 3330 4266 5023 782 7415 6536 8401 5857 1039 2832 6536 8024 852 4995 4511 2897 7092 2527 1320 1168 4078 7271 6551 1300 8024 2206 5636 6536 7032 6543 1045 1045 511 2511 1265 1765 7368 2182 4415 6291 4158 8024 4995 4511 1403 679 4294 2137 1914 3149 782 3119 1358 3621 7517 8024 699 5147 2137 6819 6917 3315 7032 5023 6121 4158 8024 898 6889 4306 7065 6121 3791 3119 1358 7065 6121 3511 1243 5389 8024 1161 5993 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 4158 6888 3297 881 4104 6222 3126 3362 8024 2456 6359 886 4500 100 510 100 2772 100 100 4638 4104 6222 1690 511 4255 4511 2094 6335 4935 7415 6536 2832 6536 1377 4363 1841 6992 8024 1320 1168 4078 7271 6551 1842 6543 1045 7032 7092 8024 2511 1265 1765 7368 898 6889 1353 7065 6121 3791 8024 1161 5993 4511 2094 3300 3309 2530 1152 125 2399 511 8020 6536 3160 4212 8024 6250 5442 7376 1094 991 3109 8021 526 6250 5442 7376 1094 991 8027 2511 1265 1841 2206 527 4511 2094 4995 686 1788 5195 2382 1139 3760 5417 4413 1842 8024 1403 4413 1351 947 1430 1682 800 3300 2201 3511 2832 6536 1757 7386 1377 3082 868 7032 6084 2339 1072 4363 1164 8024 3680 3299 5543 5183 750 125 110 11115 8017 4638 1841 6992 8024 3330 1998 4413 1351 679 4542 3300 800 8024 1044 2990 897 8114 5857 1039 5183 4995 4511 6868 6121 2832 6536 8024 699 6303 3302 3330 4266 5023 782 7415 6536 8401 5857 1039 2832 6536 8024 852 4995 4511 2897 7092 2527 1320 1168 4078 7271 6551 1300 8024 2206 5636 6536 7032 6543 1045 1045 511 2511 1265 1765 7368 2182 4415 6291 4158 8024 4995 4511 1403 679 4294 2137 1914 3149 782 3119 1358 3621 7517 8024 699 5147 2137 6819 6917 3315 7032 5023 6121 4158 8024 898 6889 4306 7065 6121 3791 3119 1358 7065 6121 3511 1243 5389 8024 1161 5993 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: news_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: news_id\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] 00 : 13 國 際 | 川 普 再 譙 聯 準 會 ： 我 搞 經 濟 比 他 們 厲 害 00 : 10 生 活 | 威 力 彩 頭 獎 槓 龜 上 看 7 . 9 億 元 00 : 07 生 活 | 大 甲 媽 祖 遶 境 泰 山 油 品 花 車 共 襄 盛 舉 23 : 36 國 際 | 疫 情 後 川 普 首 度 辦 造 勢 竟 選 在 種 族 大 屠 殺 地 點 23 : 18 國 際 | 美 新 冠 確 診 數 又 飆 財 長 ： 不 能 再 次 關 閉 經 濟 23 : 07 兩 岸 | 與 梅 克 爾 視 訊 會 晤 李 克 強 ： 中 德 共 同 維 護 產 業 鏈 安 全 華 為 創 辦 人 任 正 非 接 受 英 國 媒 體 訪 問 時 表 示 ， 他 相 信 英 國 不 會 拒 絕 華 為 參 與 建 設 [UNK] 網 路 。 此 外 ， 他 也 堅 稱 ， 華 為 設 備 並 沒 有 安 裝 「 後 門 」 程 式 。 任 正 非 接 受 英 國 天 空 新 聞 （ [UNK] [UNK] ） 訪 問 時 指 出 ， 英 國 首 相 強 森 （ [UNK] [UNK] ） 是 一 名 果 斷 且 有 能 力 的 人 ， 他 上 任 [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] 00 : 13 國 際 | 川 普 再 譙 聯 準 會 ： 我 搞 經 濟 比 他 們 厲 害 00 : 10 生 活 | 威 力 彩 頭 獎 槓 龜 上 看 7 . 9 億 元 00 : 07 生 活 | 大 甲 媽 祖 遶 境 泰 山 油 品 花 車 共 襄 盛 舉 23 : 36 國 際 | 疫 情 後 川 普 首 度 辦 造 勢 竟 選 在 種 族 大 屠 殺 地 點 23 : 18 國 際 | 美 新 冠 確 診 數 又 飆 財 長 ： 不 能 再 次 關 閉 經 濟 23 : 07 兩 岸 | 與 梅 克 爾 視 訊 會 晤 李 克 強 ： 中 德 共 同 維 護 產 業 鏈 安 全 華 為 創 辦 人 任 正 非 接 受 英 國 媒 體 訪 問 時 表 示 ， 他 相 信 英 國 不 會 拒 絕 華 為 參 與 建 設 [UNK] 網 路 。 此 外 ， 他 也 堅 稱 ， 華 為 設 備 並 沒 有 安 裝 「 後 門 」 程 式 。 任 正 非 接 受 英 國 天 空 新 聞 （ [UNK] [UNK] ） 訪 問 時 指 出 ， 英 國 首 相 強 森 （ [UNK] [UNK] ） 是 一 名 果 斷 且 有 能 力 的 人 ， 他 上 任 [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 8136 131 8124 1751 7396 170 2335 3249 1086 6353 5474 3976 3298 8038 2769 3018 5195 4089 3683 800 947 1341 2154 8136 131 8108 4495 3833 170 2014 1213 2506 7531 4354 3544 7990 677 4692 128 119 130 1023 1039 8136 131 8155 4495 3833 170 1920 4508 2061 4862 6906 1862 3805 2255 3779 1501 5709 6722 1066 6198 4670 5647 8133 131 8216 1751 7396 170 4554 2658 2527 2335 3249 7674 2428 6794 6863 1248 4994 6908 1762 4934 3184 1920 2248 3669 1765 7953 8133 131 8123 1751 7396 170 5401 3173 1094 4825 6262 3149 1348 7598 6512 7269 8038 679 5543 1086 3613 7302 7273 5195 4089 8133 131 8155 1060 2279 170 5645 3449 1046 4273 6213 6244 3298 3245 3330 1046 2485 8038 704 2548 1066 1398 5204 6362 4496 3511 7122 2128 1059 5836 4158 1201 6794 782 818 3633 7478 2970 1358 5739 1751 2054 7768 6256 1558 3229 6134 4850 8024 800 4685 928 5739 1751 679 3298 2867 5179 5836 4158 1347 5645 2456 6257 100 5206 6662 511 3634 1912 8024 800 738 1830 4935 8024 5836 4158 6257 991 699 3760 3300 2128 6172 519 2527 7271 520 4923 2466 511 818 3633 7478 2970 1358 5739 1751 1921 4958 3173 5472 8020 100 100 8021 6256 1558 3229 2900 1139 8024 5739 1751 7674 4685 2485 3481 8020 100 100 8021 3221 671 1399 3362 3174 684 3300 5543 1213 4638 782 8024 800 677 818 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 8136 131 8124 1751 7396 170 2335 3249 1086 6353 5474 3976 3298 8038 2769 3018 5195 4089 3683 800 947 1341 2154 8136 131 8108 4495 3833 170 2014 1213 2506 7531 4354 3544 7990 677 4692 128 119 130 1023 1039 8136 131 8155 4495 3833 170 1920 4508 2061 4862 6906 1862 3805 2255 3779 1501 5709 6722 1066 6198 4670 5647 8133 131 8216 1751 7396 170 4554 2658 2527 2335 3249 7674 2428 6794 6863 1248 4994 6908 1762 4934 3184 1920 2248 3669 1765 7953 8133 131 8123 1751 7396 170 5401 3173 1094 4825 6262 3149 1348 7598 6512 7269 8038 679 5543 1086 3613 7302 7273 5195 4089 8133 131 8155 1060 2279 170 5645 3449 1046 4273 6213 6244 3298 3245 3330 1046 2485 8038 704 2548 1066 1398 5204 6362 4496 3511 7122 2128 1059 5836 4158 1201 6794 782 818 3633 7478 2970 1358 5739 1751 2054 7768 6256 1558 3229 6134 4850 8024 800 4685 928 5739 1751 679 3298 2867 5179 5836 4158 1347 5645 2456 6257 100 5206 6662 511 3634 1912 8024 800 738 1830 4935 8024 5836 4158 6257 991 699 3760 3300 2128 6172 519 2527 7271 520 4923 2466 511 818 3633 7478 2970 1358 5739 1751 1921 4958 3173 5472 8020 100 100 8021 6256 1558 3229 2900 1139 8024 5739 1751 7674 4685 2485 3481 8020 100 100 8021 3221 671 1399 3362 3174 684 3300 5543 1213 4638 782 8024 800 677 818 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Jasonhsu\\Desktop\\esun\\bert_classfication2\\model.ckpt-1516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Jasonhsu\\Desktop\\esun\\bert_classfication2\\model.ckpt-1516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predictions = getPrediction(val['raw_content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(predictions, columns = ['content','vct','pred','pred_disc']).to_excel('pred_bert.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "ws = WS(\"./data\", disable_cuda=False)\n",
    "pos = POS(\"./data\", disable_cuda=False)\n",
    "ner = NER(\"./data\", disable_cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ws\n",
    "del pos\n",
    "del ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
